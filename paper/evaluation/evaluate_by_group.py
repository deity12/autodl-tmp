# -*- coding: utf-8 -*-
"""
åˆ†ç»„è¯„ä¼°è„šæœ¬ï¼šæŒ‰æ³¢åŠ¨ç‡åˆ†ç»„è¯„ä¼° Full Model vs No Quantum æ¨¡å‹çš„è¡¨ç°
========================================================================
åŠŸèƒ½ï¼š
    æŒ‰ç…§æ³¢åŠ¨ç‡åˆ†ä½æ•°å°†æµ‹è¯•é›†åˆ†ä¸ºä½ã€ä¸­ã€é«˜ä¸‰ç»„ï¼Œåˆ†åˆ«è¯„ä¼°ä¸¤ä¸ªæ¨¡å‹çš„è¡¨ç°ã€‚
    è¿™å¯ä»¥éªŒè¯é‡å­æ¨¡å—æ˜¯å¦åœ¨é«˜æ³¢åŠ¨åœºæ™¯ä¸‹ï¼ˆè®ºæ–‡çš„æ ¸å¿ƒè®ºç‚¹ï¼‰è¡¨ç°æ›´å¥½ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python evaluate_by_group.py

è¾“å‡ºï¼š
    - æ§åˆ¶å°è¾“å‡ºï¼šå„ç»„çš„MSEã€RÂ²ã€æ–¹å‘å‡†ç¡®ç‡ç­‰æŒ‡æ ‡å¯¹æ¯”
    - å¸®åŠ©éªŒè¯è®ºæ–‡æ ¸å¿ƒè®ºç‚¹ï¼šé‡å­æ¨¡å—æ“…é•¿æ•æ‰é«˜æ³¢åŠ¨/æ··æ²Œç‰¹å¾
"""

import torch
import numpy as np
import pandas as pd
import os
import sys
from torch.utils.data import DataLoader
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ================= 1. ç¯å¢ƒä¸è·¯å¾„é…ç½® =================
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„

# è·¯å¾„é…ç½®
GRAPH_PATH = os.path.join(parent_dir, 'data', 'processed', 'Graph_Adjacency.npy')
CSV_PATH = os.path.join(parent_dir, 'data', 'processed', 'Final_Model_Data.csv')
OUTPUT_DIR = os.path.join(parent_dir, 'outputs')
CHECKPOINT_DIR = os.path.join(OUTPUT_DIR, 'checkpoints')
RESULTS_DIR = os.path.join(OUTPUT_DIR, 'results')

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
if not os.path.exists(CSV_PATH):
    print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° {CSV_PATH}")
    exit(1)

try:
    from dataProcessed.dataset import FinancialDataset
    from models.gnn_model import QL_MATCC_GNN_Model
    print("âœ… æˆåŠŸå¯¼å…¥åŸºç¡€æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    exit(1)

# é…ç½®
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# ================= 2. è¾…åŠ©å‡½æ•°ï¼šåŠ è½½æ¨¡å‹å¹¶è·å–é¢„æµ‹ç»“æœ =================
def get_predictions(model_name, use_quantum=True, use_matcc=True, use_market_guidance=True):
    """
    åŠ è½½æŒ‡å®šæ¨¡å‹å¹¶åœ¨æµ‹è¯•é›†ä¸Šè·å–é¢„æµ‹ç»“æœ
    
    å‚æ•°:
        model_name: æ¨¡å‹åç§°ï¼ˆå¦‚ "full_model" æˆ– "no_quantum"ï¼‰
        use_quantum: æ˜¯å¦ä½¿ç”¨é‡å­æ¨¡å—ï¼ˆéœ€è¦ä¸ä¿å­˜æ—¶çš„é…ç½®ä¸€è‡´ï¼‰
        use_matcc: æ˜¯å¦ä½¿ç”¨MATCC
        use_market_guidance: æ˜¯å¦ä½¿ç”¨å¸‚åœºå¼•å¯¼
    
    è¿”å›:
        (predictions, labels, volatilities): é¢„æµ‹å€¼ã€çœŸå®å€¼ã€æ³¢åŠ¨ç‡çš„numpyæ•°ç»„
    """
    # å°è¯•å¤šä¸ªå¯èƒ½çš„æ¨¡å‹è·¯å¾„
    if model_name == 'full_model':
        model_paths = [os.path.join(CHECKPOINT_DIR, 'best_model_full.pth')]
    else:
        model_paths = [os.path.join(CHECKPOINT_DIR, f'best_model_{model_name}.pth')]
    
    model_path = None
    for path in model_paths:
        if os.path.exists(path):
            model_path = path
            break
    
    if model_path is None:
        print(f"âŒ æ²¡æ‰¾åˆ°æ¨¡å‹: {model_name}")
        print(f"   å·²å°è¯•è·¯å¾„:")
        for path in model_paths:
            print(f"     - {path}")
        return None, None, None
    
    print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
    
    # åŠ è½½æ•°æ®
    train_dataset = FinancialDataset(CSV_PATH, seq_len=30, mode='train')
    test_dataset = FinancialDataset(CSV_PATH, seq_len=30, mode='test', scaler=train_dataset.scaler)
    test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False, num_workers=4)
    
    # åŠ è½½å›¾
    if GRAPH_PATH and os.path.exists(GRAPH_PATH):
        adj = np.load(GRAPH_PATH)
        print(f"âœ… åŠ è½½å›¾è°±: {GRAPH_PATH}, å½¢çŠ¶: {adj.shape}")
    else:
        # å…œåº•ï¼šä½¿ç”¨å•ä½é˜µ
        df_t = pd.read_csv(CSV_PATH, usecols=['Ticker'])
        num_nodes = int(df_t['Ticker'].nunique())
        adj = np.eye(num_nodes, dtype=np.float32)
        print(f"âš ï¸ æœªæ‰¾åˆ°å›¾è°±æ–‡ä»¶ï¼Œä½¿ç”¨å•ä½é˜µï¼Œå½¢çŠ¶: {adj.shape}")
    
    num_nodes = adj.shape[0]
    
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆéœ€è¦ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´çš„é…ç½®ï¼‰
    model = QL_MATCC_GNN_Model(
        input_dim=8,
        n_embd=512,
        n_layers=4,
        n_qubits=4,
        num_nodes=num_nodes,
        adj_matrix=adj,
        gnn_embd=128,
        use_quantum=use_quantum,
        use_matcc=use_matcc,
        use_market_guidance=use_market_guidance,
    ).to(DEVICE)
    
    # åŠ è½½æ¨¡å‹æƒé‡
    model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    model.eval()
    
    # æ”¶é›†æ‰€æœ‰é¢„æµ‹å€¼ã€çœŸå®å€¼å’Œæ³¢åŠ¨ç‡
    all_preds = []
    all_labels = []
    all_vols = []
    
    print(f"ğŸ”„ æ­£åœ¨è®¡ç®— {model_name} çš„é¢„æµ‹ç»“æœ...")
    with torch.no_grad():
        for batch in test_loader:
            x = batch['x'].to(DEVICE)
            y = batch['y'].to(DEVICE)
            vol = batch['vol'].to(DEVICE)
            node_idx = batch.get('node_indices')
            if node_idx is not None:
                node_idx = node_idx.to(DEVICE)
            
            preds = model(x, vol, node_indices=node_idx)
            all_preds.append(preds.cpu().numpy())
            all_labels.append(y.cpu().numpy())
            all_vols.append(vol.cpu().numpy())
    
    all_preds = np.concatenate(all_preds, axis=0)
    all_labels = np.concatenate(all_labels, axis=0)
    all_vols = np.concatenate(all_vols, axis=0)
    
    print(f"âœ… {model_name} é¢„æµ‹å®Œæˆï¼Œå…± {len(all_preds)} ä¸ªæ ·æœ¬")
    
    return all_preds, all_labels, all_vols


def calculate_group_metrics(y_true, y_pred):
    """
    è®¡ç®—ä¸€ç»„çš„è¯„ä¼°æŒ‡æ ‡
    
    è¿”å›:
        dict: åŒ…å«å„ç§æŒ‡æ ‡çš„å­—å…¸
    """
    y_true = y_true.flatten()
    y_pred = y_pred.flatten()
    
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    
    # æ–¹å‘å‡†ç¡®ç‡
    true_direction = np.sign(y_true)
    pred_direction = np.sign(y_pred)
    directional_accuracy = np.mean(true_direction == pred_direction)
    
    # IC (Pearsonç›¸å…³ç³»æ•°)
    try:
        from scipy.stats import pearsonr
        ic, _ = pearsonr(y_pred, y_true)
        ic = float(ic)
    except:
        ic = None
    
    # RankIC (Spearmanç§©ç›¸å…³ç³»æ•°)
    try:
        from scipy.stats import spearmanr
        rank_ic, _ = spearmanr(y_pred, y_true)
        rank_ic = float(rank_ic)
    except:
        rank_ic = None
    
    return {
        'mse': mse,
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'directional_accuracy': directional_accuracy,
        'ic': ic,
        'rank_ic': rank_ic,
        'n_samples': len(y_true),
    }


# ================= 3. ä¸»ç¨‹åº =================
def main():
    print("="*70)
    print("ğŸ“Š åˆ†ç»„è¯„ä¼°ï¼šFull Model vs No Quantum (æŒ‰æ³¢åŠ¨ç‡åˆ†ç»„)")
    print("="*70)
    print(f"ğŸ“ å·¥ä½œç›®å½•: {current_dir}")
    print(f"ğŸ“Š æ•°æ®æ–‡ä»¶: {CSV_PATH}")
    print(f"ğŸ’» è®¾å¤‡: {DEVICE}")
    print()
    
    # è·å–ä¸¤ä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
    print(">>> æ­£åœ¨åŠ è½½æ¨¡å‹å¹¶è®¡ç®—é¢„æµ‹ç»“æœ...")
    print()
    
    preds_full, y_full, vol_full = get_predictions(
        "full_model", 
        use_quantum=True, 
        use_matcc=True, 
        use_market_guidance=True
    )
    
    if preds_full is None:
        print("âŒ æ— æ³•åŠ è½½ full_modelï¼Œè¯·å…ˆè¿è¡Œ run_ablation.py")
        return
    
    preds_noq, y_noq, _ = get_predictions(
        "no_quantum", 
        use_quantum=False, 
        use_matcc=True, 
        use_market_guidance=True
    )
    
    if preds_noq is None:
        print("âŒ æ— æ³•åŠ è½½ no_quantum æ¨¡å‹ï¼Œè¯·å…ˆè¿è¡Œ run_ablation.py")
        return
    
    # éªŒè¯æ•°æ®ä¸€è‡´æ€§
    if not np.allclose(y_full.flatten(), y_noq.flatten()):
        print("âš ï¸ è­¦å‘Š: ä¸¤ä¸ªæ¨¡å‹çš„çœŸå®æ ‡ç­¾ä¸å®Œå…¨ä¸€è‡´ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®åŠ è½½é—®é¢˜")
    
    # ä½¿ç”¨ full_model çš„æ³¢åŠ¨ç‡æ•°æ®ï¼ˆä¸¤ä¸ªæ¨¡å‹åº”è¯¥æ˜¯ä¸€æ ·çš„ï¼‰
    vol = vol_full.flatten()
    y = y_full.flatten()
    pred_full = preds_full.flatten()
    pred_noq = preds_noq.flatten()
    
    # æŒ‰ç…§æ³¢åŠ¨ç‡åˆ†ç»„
    # ä½æ³¢åŠ¨(0-40%)ï¼Œä¸­æ³¢åŠ¨(40-80%)ï¼Œé«˜æ³¢åŠ¨(80-100%)
    quantiles = np.quantile(vol, [0.4, 0.8])
    
    low_vol_mask = vol <= quantiles[0]
    mid_vol_mask = (vol > quantiles[0]) & (vol <= quantiles[1])
    high_vol_mask = vol > quantiles[1]
    
    # åˆ›å»ºåˆ†ç»„æ•°æ®æ¡†
    groups = {
        "Low Vol (0-40%)": {
            'mask': low_vol_mask,
            'y': y[low_vol_mask],
            'pred_full': pred_full[low_vol_mask],
            'pred_noq': pred_noq[low_vol_mask],
            'vol': vol[low_vol_mask],
        },
        "Mid Vol (40-80%)": {
            'mask': mid_vol_mask,
            'y': y[mid_vol_mask],
            'pred_full': pred_full[mid_vol_mask],
            'pred_noq': pred_noq[mid_vol_mask],
            'vol': vol[mid_vol_mask],
        },
        "High Vol (80-100%)": {
            'mask': high_vol_mask,
            'y': y[high_vol_mask],
            'pred_full': pred_full[high_vol_mask],
            'pred_noq': pred_noq[high_vol_mask],
            'vol': vol[high_vol_mask],
        },
    }
    
    # è®¡ç®—å„ç»„çš„æŒ‡æ ‡
    print("\n" + "="*70)
    print("ğŸ“Š åˆ†ç»„è¯„ä¼°ç»“æœå¯¹æ¯”")
    print("="*70)
    
    results = []
    for group_name, group_data in groups.items():
        metrics_full = calculate_group_metrics(group_data['y'], group_data['pred_full'])
        metrics_noq = calculate_group_metrics(group_data['y'], group_data['pred_noq'])
        
        # åˆ¤æ–­èƒœè´Ÿ
        winner_mse = "âœ… Full" if metrics_full['mse'] < metrics_noq['mse'] else "âŒ NoQ"
        winner_r2 = "âœ… Full" if metrics_full['r2'] > metrics_noq['r2'] else "âŒ NoQ"
        winner_dir = "âœ… Full" if metrics_full['directional_accuracy'] > metrics_noq['directional_accuracy'] else "âŒ NoQ"
        
        results.append({
            'group': group_name,
            'n_samples': metrics_full['n_samples'],
            'avg_vol': np.mean(group_data['vol']),
            'full_mse': metrics_full['mse'],
            'noq_mse': metrics_noq['mse'],
            'full_r2': metrics_full['r2'],
            'noq_r2': metrics_noq['r2'],
            'full_dir': metrics_full['directional_accuracy'],
            'noq_dir': metrics_noq['directional_accuracy'],
            'full_ic': metrics_full['ic'],
            'noq_ic': metrics_noq['ic'],
            'full_rank_ic': metrics_full['rank_ic'],
            'noq_rank_ic': metrics_noq['rank_ic'],
            'winner_mse': winner_mse,
            'winner_r2': winner_r2,
            'winner_dir': winner_dir,
        })
    
    # æ‰“å°è¡¨æ ¼
    print(f"\n{'Group':<20} | {'Samples':<10} | {'Avg Vol':<10} | {'Full MSE':<12} | {'NoQ MSE':<12} | {'Winner (MSE)'}")
    print("-" * 90)
    for r in results:
        print(f"{r['group']:<20} | {r['n_samples']:<10} | {r['avg_vol']:<10.4f} | "
              f"{r['full_mse']:<12.6f} | {r['noq_mse']:<12.6f} | {r['winner_mse']}")
    
    print("\n" + "-" * 90)
    print(f"{'Group':<20} | {'Full RÂ²':<12} | {'NoQ RÂ²':<12} | {'Winner (RÂ²)'}")
    print("-" * 90)
    for r in results:
        print(f"{r['group']:<20} | {r['full_r2']:<12.6f} | {r['noq_r2']:<12.6f} | {r['winner_r2']}")
    
    print("\n" + "-" * 90)
    print(f"{'Group':<20} | {'Full DirAcc':<12} | {'NoQ DirAcc':<12} | {'Winner (Dir)'}")
    print("-" * 90)
    for r in results:
        print(f"{r['group']:<20} | {r['full_dir']:<12.4f} | {r['noq_dir']:<12.4f} | {r['winner_dir']}")
    
    if results[2]['full_ic'] is not None and results[2]['noq_ic'] is not None:
        print("\n" + "-" * 90)
        print(f"{'Group':<20} | {'Full IC':<12} | {'NoQ IC':<12} | {'Full RankIC':<12} | {'NoQ RankIC':<12}")
        print("-" * 90)
        for r in results:
            full_ic_str = f"{r['full_ic']:.4f}" if r['full_ic'] is not None else "N/A"
            noq_ic_str = f"{r['noq_ic']:.4f}" if r['noq_ic'] is not None else "N/A"
            full_rank_ic_str = f"{r['full_rank_ic']:.4f}" if r['full_rank_ic'] is not None else "N/A"
            noq_rank_ic_str = f"{r['noq_rank_ic']:.4f}" if r['noq_rank_ic'] is not None else "N/A"
            print(f"{r['group']:<20} | {full_ic_str:<12} | {noq_ic_str:<12} | "
                  f"{full_rank_ic_str:<12} | {noq_rank_ic_str:<12}")
    
    # å…³é”®ç»“è®º
    print("\n" + "="*70)
    print("ğŸ¯ å…³é”®ç»“è®º")
    print("="*70)
    
    high_vol_result = results[2]  # High Volç»„
    if high_vol_result['winner_mse'] == "âœ… Full":
        print("âœ… å¥½æ¶ˆæ¯ï¼Full Model åœ¨é«˜æ³¢åŠ¨æ ·æœ¬ä¸Š MSE æ›´ä¼˜ï¼")
        print("   è¿™éªŒè¯äº†è®ºæ–‡æ ¸å¿ƒè®ºç‚¹ï¼šé‡å­æ¨¡å—æ“…é•¿æ•æ‰é«˜æ³¢åŠ¨/æ··æ²Œç‰¹å¾ã€‚")
        print("   ä½ å¯ä»¥è¿™æ ·å†™è®ºæ–‡ï¼š")
        print("   \"è™½ç„¶å…¨é‡å¹³å‡è¡¨ç°æ¥è¿‘ï¼Œä½†åœ¨é«˜é£é™©é¢„è­¦ï¼ˆé«˜æ³¢åŠ¨ï¼‰åœºæ™¯ä¸‹ï¼Œ")
        print("   å¼•å…¥é‡å­æ¨¡å—æ˜¾è‘—é™ä½äº†é¢„æµ‹è¯¯å·®ï¼ˆMSEä»{:.6f}é™è‡³{:.6f}ï¼‰ã€‚\"".format(
            high_vol_result['noq_mse'], high_vol_result['full_mse']))
    else:
        print("âš ï¸ Full Model åœ¨é«˜æ³¢åŠ¨æ ·æœ¬ä¸Š MSE ä»ä¸å¦‚ No Quantum")
        print("   å»ºè®®è€ƒè™‘ä»¥ä¸‹æ”¹è¿›æ–¹æ¡ˆï¼š")
        print("   1. ä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡ï¼ˆé‡å­å±‚ç”¨æ›´å°çš„å­¦ä¹ ç‡ï¼‰")
        print("   2. å¼•å…¥æ–¹å‘æ€§ Loss (Sign Loss)")
        print("   3. è°ƒæ•´é‡å­å±‚å‚æ•°ï¼ˆqubitsã€layersç­‰ï¼‰")
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°CSV
    df_results = pd.DataFrame(results)
    results_path = os.path.join(RESULTS_DIR, 'group_evaluation_results.csv')
    os.makedirs(RESULTS_DIR, exist_ok=True)
    df_results.to_csv(results_path, index=False, float_format='%.6f')
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_path}")
    print("="*70)


if __name__ == "__main__":
    main()
