# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€è¯„ä¼°è„šæœ¬ï¼šå¯¹æ¯” Graph-RWKV å…¨é‡æ¨¡å‹ä¸æ¶ˆèæ¨¡å‹çš„è¡¨ç°ï¼ˆæ–°æ–¹å‘ï¼‰
========================================================================
åŠŸèƒ½ï¼š
    1. åŠ è½½ Graph-RWKV å…¨é‡æ¨¡å‹ï¼ˆç”± 3_train.py è®­ç»ƒï¼‰
    2. åŠ è½½æ¶ˆèæ¨¡å‹ï¼ˆç”± 3_train_ablation.py è®­ç»ƒï¼‰
    3. åœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—ç»Ÿä¸€æŒ‡æ ‡ï¼ˆMSEã€RÂ²ã€æ–¹å‘å‡†ç¡®ç‡ã€ICã€RankIC ç­‰ï¼‰
    4. ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼å’Œå›¾è¡¨

ä½¿ç”¨æ–¹æ³•ï¼š
    python evaluate_all.py

å‰ç½®æ¡ä»¶ï¼š
    1. å…ˆè¿è¡Œ 3_train.py è®­ç»ƒå…¨é‡æ¨¡å‹ï¼ˆç”Ÿæˆ best_model.pthï¼‰
    2. å†è¿è¡Œ 3_train_ablation.py è®­ç»ƒæ¶ˆèæ¨¡å‹ï¼ˆç”Ÿæˆ best_model_ablation_*.pthï¼‰

ã€æ³¨æ„ã€‘æ–°æ–¹å‘ä¸ä½¿ç”¨ Quantumã€MATCCã€MarketGuidanceï¼Œåªè¯„ä¼°ï¼š
    - Full Modelï¼ˆå®Œæ•´æ¶æ„ï¼‰
    - w/o Graphï¼ˆåªç”¨ RWKVï¼‰
    - w/o Semanticï¼ˆåªç”¨ç»Ÿè®¡å›¾ï¼‰
    - w/o Statisticalï¼ˆåªç”¨è¯­ä¹‰å›¾ï¼‰
    - w/o Sentimentï¼ˆè¯­ä¹‰å›¾ä¸ç”¨æƒ…æ„Ÿåˆ†æ•°ï¼‰
"""

import torch
import numpy as np
import pandas as pd
import os
import sys
import json
from torch.utils.data import DataLoader
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy.stats import pearsonr, spearmanr
import matplotlib.pyplot as plt
from datetime import datetime

# ================= 1. ç¯å¢ƒä¸è·¯å¾„é…ç½® =================
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„

# è·¯å¾„é…ç½®
GRAPH_PATH = os.path.join(parent_dir, 'data', 'processed', 'Graph_Adjacency.npy')
CSV_PATH = os.path.join(parent_dir, 'data', 'processed', 'Final_Model_Data.csv')
OUTPUT_DIR = os.path.join(parent_dir, 'outputs')
CHECKPOINT_DIR = os.path.join(OUTPUT_DIR, 'checkpoints')
RESULTS_DIR = os.path.join(OUTPUT_DIR, 'results')
FIGURE_DIR = os.path.join(OUTPUT_DIR, 'figures')
os.makedirs(RESULTS_DIR, exist_ok=True)
os.makedirs(FIGURE_DIR, exist_ok=True)

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
if not os.path.exists(CSV_PATH):
    print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° {CSV_PATH}")
    exit(1)

try:
    from dataProcessed.dataset import FinancialDataset
    from models.gnn_model import GraphRWKV_GNN_Model, QL_MATCC_GNN_Model  # QL_MATCC_GNN_Model ä¸ºå…¼å®¹æ€§åˆ«å
    print("âœ… æˆåŠŸå¯¼å…¥åŸºç¡€æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    exit(1)

# é…ç½®
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

def _load_train_config(parent_dir_: str) -> dict:
    """
    å°è¯•è¯»å–è®­ç»ƒæ—¥å¿—ä¸­çš„é…ç½®ï¼ˆé¿å…è¯„ä¼°æ—¶æ¨¡å‹ç»´åº¦ä¸åŒ¹é…ï¼‰ã€‚

    ä¼˜å…ˆçº§ï¼š
      1) outputs/logs/training_losses_full.jsonï¼ˆtrain_full.py è¾“å‡ºï¼‰
      2) ç¯å¢ƒå˜é‡ QL_PROFILEï¼ˆpaper / 48gbï¼‰
      3) å…œåº•é»˜è®¤ï¼ˆ256/3/64ï¼‰
    """
    cfg = {}
    path = os.path.join(parent_dir_, "outputs", "logs", "training_losses_full.json")
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
            # train_full.py çš„ç»“æ„ï¼šloss_data["config"] æ˜¯ä¸€ä¸ª dict
            cfg = data.get("config", {}) if isinstance(data, dict) else {}
        except Exception:
            cfg = {}

    profile = os.environ.get("QL_PROFILE", (cfg.get("profile") if isinstance(cfg, dict) else None) or "paper").strip().lower()
    # å…œåº•ï¼šprofile æ¨æ–­
    if not isinstance(cfg, dict):
        cfg = {}

    if profile in ("48gb", "max", "server"):
        defaults = dict(n_embd=384, n_layers=4, gnn_embd=128, seq_len=30)
    else:
        defaults = dict(n_embd=256, n_layers=3, gnn_embd=64, seq_len=30)

    # åˆå¹¶ï¼šlog > profile é»˜è®¤
    merged = dict(defaults)
    for k in ("n_embd", "n_layers", "gnn_embd", "seq_len"):
        if k in cfg and cfg[k] is not None:
            merged[k] = int(cfg[k]) if k != "seq_len" else int(cfg[k])
    merged["profile"] = profile
    return merged


def _eval_batch_size(profile: str) -> int:
    """è¯„ä¼°é˜¶æ®µ batch_sizeï¼šå¯ç”¨ç¯å¢ƒå˜é‡ EVAL_BATCH_SIZE è¦†ç›–ã€‚"""
    env = os.environ.get("EVAL_BATCH_SIZE")
    if env:
        try:
            return int(env)
        except Exception:
            pass
    # è¯„ä¼°åªåšå‰å‘ï¼Œé€šå¸¸ batch å¯ä»¥å¤§ä¸€äº›ï¼›ä½†å¤§æ¨¡å‹ä»å¯èƒ½ OOMï¼Œåç»­ä¼šè‡ªåŠ¨é™çº§
    return 4096 if profile in ("48gb", "max", "server") else 2048


TRAIN_CFG = _load_train_config(parent_dir)

# æ¨¡å‹é…ç½®ï¼ˆå°½é‡ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
MODEL_CONFIG = {
    'input_dim': 8,
    'n_embd': int(TRAIN_CFG['n_embd']),
    'n_layers': int(TRAIN_CFG['n_layers']),
    'gnn_embd': int(TRAIN_CFG['gnn_embd']),
    'seq_len': int(TRAIN_CFG['seq_len']),
    'batch_size': _eval_batch_size(TRAIN_CFG['profile']),
}

# æ‰€æœ‰æ¨¡å‹çš„é…ç½®ï¼ˆæ–°æ–¹å‘ï¼šGraph-RWKVï¼‰
MODELS_TO_EVALUATE = [
    {
        'name': 'Full Model',
        'exp_name': 'full_model',
        'path': os.path.join(CHECKPOINT_DIR, 'best_model.pth'),  # 3_train.py çš„è¾“å‡º
        'use_graph': True,
        'use_semantic': True,
        'use_statistical': True,
        'use_sentiment': True,
    },
    {
        'name': 'w/o Graph',
        'exp_name': 'w/o_graph',
        'path': os.path.join(CHECKPOINT_DIR, 'best_model_ablation_w/o_graph.pth'),
        'use_graph': False,
        'use_semantic': False,
        'use_statistical': False,
        'use_sentiment': False,
    },
    {
        'name': 'w/o Semantic',
        'exp_name': 'w/o_semantic',
        'path': os.path.join(CHECKPOINT_DIR, 'best_model_ablation_w/o_semantic.pth'),
        'use_graph': True,
        'use_semantic': False,
        'use_statistical': True,
        'use_sentiment': False,
    },
    {
        'name': 'w/o Statistical',
        'exp_name': 'w/o_statistical',
        'path': os.path.join(CHECKPOINT_DIR, 'best_model_ablation_w/o_statistical.pth'),
        'use_graph': True,
        'use_semantic': True,
        'use_statistical': False,
        'use_sentiment': True,
    },
    {
        'name': 'w/o Sentiment',
        'exp_name': 'w/o_sentiment',
        'path': os.path.join(CHECKPOINT_DIR, 'best_model_ablation_w/o_sentiment.pth'),
        'use_graph': True,
        'use_semantic': True,
        'use_statistical': True,
        'use_sentiment': False,
    },
]


# ================= 2. è¾…åŠ©å‡½æ•° =================
def calculate_metrics(y_true, y_pred):
    """
    è®¡ç®—å›å½’ä»»åŠ¡çš„å¸¸ç”¨è¯„ä¼°æŒ‡æ ‡ï¼ˆç”¨äºæ•´ä½“å¯¹æ¯”ä¸åˆ†ç»„å¯¹æ¯”ï¼‰ã€‚

    æŒ‡æ ‡ï¼š
      - mse / mae / rmse / r2ï¼šå›å½’è¯¯å·®ä¸æ‹Ÿåˆä¼˜åº¦
      - dir_accï¼šæ–¹å‘å‡†ç¡®ç‡ï¼ˆsign(pred) ä¸ sign(true) ä¸€è‡´çš„æ¯”ä¾‹ï¼‰
      - ic / rank_icï¼šä¿¡æ¯ç³»æ•°ï¼ˆPearsonï¼‰ä¸ç§©ä¿¡æ¯ç³»æ•°ï¼ˆSpearmanï¼‰
    """
    y_true = np.array(y_true).flatten()
    y_pred = np.array(y_pred).flatten()
    
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    
    # æ–¹å‘å‡†ç¡®ç‡
    true_dir = np.sign(y_true)
    pred_dir = np.sign(y_pred)
    dir_acc = np.mean(true_dir == pred_dir)
    
    # IC & RankIC
    try:
        ic, _ = pearsonr(y_pred, y_true)
        ic = float(ic)
    except:
        ic = None
    
    try:
        rank_ic, _ = spearmanr(y_pred, y_true)
        rank_ic = float(rank_ic)
    except:
        rank_ic = None
    
    return {
        'mse': mse,
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'dir_acc': dir_acc,
        'ic': ic,
        'rank_ic': rank_ic,
        'n_samples': len(y_true),
    }


def load_model_and_predict(model_config, test_loader, adj_matrix, num_nodes):
    """åŠ è½½æ¨¡å‹å¹¶è·å–é¢„æµ‹ç»“æœï¼ˆæ–°æ–¹å‘ï¼šGraph-RWKVï¼‰"""
    model_path = model_config['path']
    
    if not os.path.exists(model_path):
        print(f"   âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None, None, None
    
    # å¤„ç† w/o Graph çš„æƒ…å†µï¼ˆåªç”¨ RWKVï¼Œä¸ç”¨ GATï¼‰
    if not model_config['use_graph']:
        from models.base_model import GraphRWKV_Model
        model = GraphRWKV_Model(
            input_dim=MODEL_CONFIG['input_dim'],
            n_embd=MODEL_CONFIG['n_embd'],
            n_layers=MODEL_CONFIG['n_layers'],
        ).to(DEVICE)
    else:
        # ä½¿ç”¨ Graph-RWKV æ¨¡å‹ï¼ˆæ ¹æ®æ¶ˆèé…ç½®è°ƒæ•´å›¾ç»“æ„ï¼‰
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥æ ¹æ® use_semantic/use_statistical è°ƒæ•´å›¾
        adj = adj_matrix  # ç®€åŒ–ï¼šä½¿ç”¨å®Œæ•´å›¾
        model = GraphRWKV_GNN_Model(
            input_dim=MODEL_CONFIG['input_dim'],
            n_embd=MODEL_CONFIG['n_embd'],
            n_layers=MODEL_CONFIG['n_layers'],
            num_nodes=num_nodes,
            adj_matrix=adj,
            gnn_embd=MODEL_CONFIG['gnn_embd'],
        ).to(DEVICE)
    
    # åŠ è½½æƒé‡
    model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    model.eval()
    
    # é¢„æµ‹
    all_preds = []
    all_labels = []
    all_vols = []
    
    with torch.inference_mode():
        for batch in test_loader:
            x = batch['x'].to(DEVICE, non_blocking=True)
            y = batch['y'].to(DEVICE, non_blocking=True)
            vol = batch.get('vol')
            if vol is not None:
                vol = vol.to(DEVICE, non_blocking=True)
            node_idx = batch.get('node_indices')
            if node_idx is not None:
                node_idx = node_idx.to(DEVICE, non_blocking=True)
            
            # æ–°æ–¹å‘ï¼švol å‚æ•°å¯é€‰
            if model_config['use_graph']:
                preds = model(x, vol=vol, node_indices=node_idx)
            else:
                preds = model(x, vol=vol)
            
            all_preds.append(preds.cpu().numpy())
            all_labels.append(y.cpu().numpy())
            if vol is not None:
                all_vols.append(vol.cpu().numpy())
    
    preds = np.concatenate(all_preds, axis=0).flatten()
    labels = np.concatenate(all_labels, axis=0).flatten()
    vols = np.concatenate(all_vols, axis=0).flatten() if all_vols else None
    
    return preds, labels, vols


# ================= 3. ä¸»ç¨‹åº =================
def main():
    """
    ç»Ÿä¸€è¯„ä¼°å…¥å£ï¼š
      1) åŠ è½½æµ‹è¯•é›†
      2) ä¾æ¬¡åŠ è½½å¯ç”¨æ¨¡å‹å¹¶é¢„æµ‹
      3) è®¡ç®—æ•´ä½“æŒ‡æ ‡ + æŒ‰æ³¢åŠ¨ç‡åˆ†ç»„æŒ‡æ ‡
      4) ä¿å­˜ CSV/PNG/JSON åˆ° outputs/results ä¸ outputs/figures
    """
    print("="*70)
    print("ğŸ“Š ç»Ÿä¸€è¯„ä¼°ï¼šGraph-RWKV å…¨é‡æ¨¡å‹ vs æ¶ˆèæ¨¡å‹ï¼ˆæ–°æ–¹å‘ï¼‰")
    print("="*70)
    print(f"ğŸ“ å·¥ä½œç›®å½•: {current_dir}")
    print(f"ğŸ“Š æ•°æ®æ–‡ä»¶: {CSV_PATH}")
    print(f"ğŸ’» è®¾å¤‡: {DEVICE}")
    print()
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    print(">>> æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    available_models = []
    for m in MODELS_TO_EVALUATE:
        if os.path.exists(m['path']):
            print(f"   âœ… {m['name']}: {m['path']}")
            available_models.append(m)
        else:
            print(f"   âŒ {m['name']}: æ–‡ä»¶ä¸å­˜åœ¨ ({m['path']})")
    
    if len(available_models) == 0:
        print("\nâŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬")
        return
    
    print(f">>> è¯„ä¼°å°†ä½¿ç”¨æ¨¡å‹é…ç½®: n_embd={MODEL_CONFIG['n_embd']}, n_layers={MODEL_CONFIG['n_layers']}, gnn_embd={MODEL_CONFIG['gnn_embd']}, batch={MODEL_CONFIG['batch_size']} (profile={TRAIN_CFG['profile']})")
    print(">>> ã€æ³¨æ„ã€‘æ–°æ–¹å‘ä¸ä½¿ç”¨ Quantumã€MATCCã€MarketGuidance")

    # åŠ è½½æ•°æ®
    print("\n>>> åŠ è½½æµ‹è¯•æ•°æ®...")
    train_dataset = FinancialDataset(CSV_PATH, seq_len=MODEL_CONFIG['seq_len'], mode='train')
        test_dataset = FinancialDataset(
            CSV_PATH,
            seq_len=MODEL_CONFIG['seq_len'],
            mode='test',
            scaler=train_dataset.scaler,
            # ã€æ³¨æ„ã€‘æ–°æ–¹å‘ä¸ä½¿ç”¨ vol_statsï¼Œä½†ä¿ç•™å‚æ•°ä»¥å…¼å®¹æ¥å£
            vol_stats=getattr(train_dataset, 'vol_stats', None),
        )
    # æ›´è´´è¿‘æœåŠ¡å™¨ï¼šç”¨æ›´å¤š worker + pin_memoryï¼ˆè‹¥ CUDAï¼‰
    num_workers = min(8, max(2, (os.cpu_count() or 12) - 2))
    pin_memory = torch.cuda.is_available()

    # è¯„ä¼° batch å¯èƒ½ OOMï¼šå‘ç”Ÿæ—¶è‡ªåŠ¨å‡åŠé‡è¯•
    bs = int(MODEL_CONFIG['batch_size'])
    while True:
        try:
            test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, num_workers=num_workers, pin_memory=pin_memory, persistent_workers=num_workers > 0, prefetch_factor=4 if num_workers > 0 else None)
            break
        except Exception:
            # DataLoader æ„å»ºå¤±è´¥è¾ƒå°‘è§ï¼Œç»§ç»­å…œåº•
            bs = max(256, bs // 2)
            if bs <= 256:
                test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False, num_workers=0)
                break
    MODEL_CONFIG['batch_size'] = bs
    print(f"   æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_dataset)}")
    
    # åŠ è½½å›¾
    if GRAPH_PATH and os.path.exists(GRAPH_PATH):
        adj_matrix = np.load(GRAPH_PATH)
        print(f"   å›¾è°±: {GRAPH_PATH}, å½¢çŠ¶: {adj_matrix.shape}")
    else:
        df_t = pd.read_csv(CSV_PATH, usecols=['Ticker'])
        num_nodes = int(df_t['Ticker'].nunique())
        adj_matrix = np.eye(num_nodes, dtype=np.float32)
        print(f"   æœªæ‰¾åˆ°å›¾è°±ï¼Œä½¿ç”¨å•ä½é˜µï¼Œå½¢çŠ¶: {adj_matrix.shape}")
    
    num_nodes = adj_matrix.shape[0]
    
    # è¯„ä¼°æ‰€æœ‰æ¨¡å‹
    print("\n>>> è¯„ä¼°æ‰€æœ‰æ¨¡å‹...")
    all_results = []
    predictions = {}  # å­˜å‚¨æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœ
    
    y_true = None  # çœŸå®å€¼ï¼ˆæ‰€æœ‰æ¨¡å‹ç›¸åŒï¼‰
    vols = None    # æ³¢åŠ¨ç‡
    
    for model_config in available_models:
        print(f"\n   ğŸ“Œ æ­£åœ¨è¯„ä¼°: {model_config['name']}...")
        preds, labels, vol_data = load_model_and_predict(model_config, test_loader, adj_matrix, num_nodes)
        
        if preds is None:
            continue
        
        if y_true is None:
            y_true = labels
            vols = vol_data
        
        predictions[model_config['exp_name']] = preds
        
        # è®¡ç®—å…¨é‡æŒ‡æ ‡
        metrics = calculate_metrics(labels, preds)
        metrics['name'] = model_config['name']
        metrics['exp_name'] = model_config['exp_name']
        all_results.append(metrics)
        
        print(f"      MSE: {metrics['mse']:.6f}, RÂ²: {metrics['r2']:.4f}, "
              f"DirAcc: {metrics['dir_acc']:.4f}, IC: {metrics['ic']:.4f if metrics['ic'] else 'N/A'}")
    
    # ================= å…¨é‡è¯„ä¼°ç»“æœ =================
    print("\n" + "="*70)
    print("ğŸ“Š å…¨é‡è¯„ä¼°ç»“æœå¯¹æ¯”")
    print("="*70)
    
    df_results = pd.DataFrame(all_results)
    cols_order = ['name', 'mse', 'mae', 'rmse', 'r2', 'dir_acc', 'ic', 'rank_ic', 'n_samples']
    cols_order = [c for c in cols_order if c in df_results.columns]
    df_results = df_results[cols_order]
    
    print(df_results.to_string(index=False))
    
    # ä¿å­˜å…¨é‡ç»“æœ
    df_results.to_csv(os.path.join(RESULTS_DIR, 'evaluation_overall.csv'), index=False, float_format='%.6f')
    
    # ================= åˆ†ç»„è¯„ä¼°ï¼ˆæŒ‰æ³¢åŠ¨ç‡ï¼Œå¦‚æœå¯ç”¨ï¼‰=================
    if vols is not None and 'full_model' in predictions and len(predictions) > 1:
        print("\n" + "="*70)
        print("ğŸ“Š åˆ†ç»„è¯„ä¼°ï¼ˆæŒ‰æ³¢åŠ¨ç‡åˆ†ä½æ•°ï¼‰")
        print("="*70)
        
        # æŒ‰æ³¢åŠ¨ç‡åˆ†ç»„
        quantiles = np.quantile(vols, [0.4, 0.8])
        groups = {
            'Low Vol (0-40%)': vols <= quantiles[0],
            'Mid Vol (40-80%)': (vols > quantiles[0]) & (vols <= quantiles[1]),
            'High Vol (80-100%)': vols > quantiles[1],
        }
        
        group_results = []
        
        for group_name, mask in groups.items():
            y_group = y_true[mask]
            
            for exp_name, preds in predictions.items():
                preds_group = preds[mask]
                metrics = calculate_metrics(y_group, preds_group)
                
                # æ‰¾åˆ°å¯¹åº”çš„æ¨¡å‹åç§°
                model_name = next((m['name'] for m in available_models if m['exp_name'] == exp_name), exp_name)
                
                group_results.append({
                    'group': group_name,
                    'model': model_name,
                    'exp_name': exp_name,
                    'mse': metrics['mse'],
                    'r2': metrics['r2'],
                    'dir_acc': metrics['dir_acc'],
                    'ic': metrics['ic'],
                    'rank_ic': metrics['rank_ic'],
                    'n_samples': metrics['n_samples'],
                })
        
        df_group = pd.DataFrame(group_results)
        
        # æ‰“å°åˆ†ç»„ç»“æœ
        for group_name in groups.keys():
            print(f"\nğŸ”¹ {group_name}")
            df_sub = df_group[df_group['group'] == group_name]
            print(df_sub[['model', 'mse', 'r2', 'dir_acc', 'ic', 'rank_ic']].to_string(index=False))
        
        # ä¿å­˜åˆ†ç»„ç»“æœ
        df_group.to_csv(os.path.join(RESULTS_DIR, 'evaluation_by_volatility.csv'), index=False, float_format='%.6f')
        
        # ================= å…³é”®ç»“è®ºï¼šé«˜æ³¢åŠ¨ç»„å¯¹æ¯”ï¼ˆæ–°æ–¹å‘ï¼‰=================
        print("\n" + "="*70)
        print("ğŸ¯ å…³é”®ç»“è®ºï¼šé«˜æ³¢åŠ¨ç»„ï¼ˆTop 20%ï¼‰Full Model vs w/o Graph å¯¹æ¯”")
        print("="*70)
        
        high_vol_full = df_group[(df_group['group'] == 'High Vol (80-100%)') & (df_group['exp_name'] == 'full_model')]
        high_vol_no_graph = df_group[(df_group['group'] == 'High Vol (80-100%)') & (df_group['exp_name'] == 'w/o_graph')]
        
        if not high_vol_full.empty and not high_vol_no_graph.empty:
            full_mse = high_vol_full['mse'].values[0]
            no_graph_mse = high_vol_no_graph['mse'].values[0]
            full_ic = high_vol_full['ic'].values[0]
            no_graph_ic = high_vol_no_graph['ic'].values[0]
            full_rank_ic = high_vol_full['rank_ic'].values[0]
            no_graph_rank_ic = high_vol_no_graph['rank_ic'].values[0]
            
            print(f"\næŒ‡æ ‡               | Full Model     | w/o Graph      | Winner")
            print("-" * 60)
            winner_mse = "âœ… Full" if full_mse < no_graph_mse else "âŒ NoGraph"
            winner_ic = "âœ… Full" if (full_ic or 0) > (no_graph_ic or 0) else "âŒ NoGraph"
            winner_rank_ic = "âœ… Full" if (full_rank_ic or 0) > (no_graph_rank_ic or 0) else "âŒ NoGraph"
            print(f"MSE               | {full_mse:<14.6f} | {no_graph_mse:<14.6f} | {winner_mse}")
            print(f"IC                | {full_ic if full_ic else 'N/A':<14.4f} | {no_graph_ic if no_graph_ic else 'N/A':<14.4f} | {winner_ic}")
            print(f"RankIC            | {full_rank_ic if full_rank_ic else 'N/A':<14.4f} | {no_graph_rank_ic if no_graph_rank_ic else 'N/A':<14.4f} | {winner_rank_ic}")
            
            # ç»“è®º
            if full_mse < no_graph_mse:
                print("\nâœ… å¥½æ¶ˆæ¯ï¼Full Model åœ¨é«˜æ³¢åŠ¨æ ·æœ¬ä¸Š MSE æ›´ä¼˜ï¼")
                print("   éªŒè¯äº†å›¾ç»“æ„ï¼ˆGATï¼‰å¯¹é‡‘èé¢„æµ‹çš„æœ‰æ•ˆæ€§ã€‚")
            elif (full_ic or 0) > (no_graph_ic or 0) or (full_rank_ic or 0) > (no_graph_rank_ic or 0):
                print("\nâš ï¸ MSE æœªé¢†å…ˆï¼Œä½† IC/RankIC æ›´ä¼˜")
                print("   å¯ä»¥ä»ç›¸å…³æ€§è§’åº¦é˜è¿°å›¾ç»“æ„çš„ä¼˜åŠ¿ã€‚")
            else:
                print("\nâš ï¸ é«˜æ³¢åŠ¨ç»„ Full Model æœªèƒ½é¢†å…ˆ w/o Graph")
                print("   å»ºè®®ï¼šæ£€æŸ¥å›¾æ„å»ºè´¨é‡æˆ–è°ƒæ•´æ¨¡å‹è¶…å‚æ•°")
    
    # ================= ç”Ÿæˆå¯¹æ¯”å›¾è¡¨ =================
    print("\n>>> ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # å·¦å›¾ï¼šå…¨é‡ MSE å¯¹æ¯”
    df_sorted = df_results.sort_values('mse')
    colors = ['#FFD700' if n == 'Full Model' else '#1f77b4' for n in df_sorted['name']]
    axes[0].barh(df_sorted['name'], df_sorted['mse'], color=colors)
    axes[0].set_xlabel('MSE (Lower is Better)')
    axes[0].set_title('Overall MSE Comparison', fontweight='bold')
    axes[0].grid(True, alpha=0.3, axis='x')
    for i, v in enumerate(df_sorted['mse']):
        axes[0].text(v, i, f' {v:.6f}', va='center', fontsize=9)
    
    # å³å›¾ï¼šRÂ² å¯¹æ¯”
    df_sorted_r2 = df_results.sort_values('r2', ascending=False)
    colors_r2 = ['#FFD700' if n == 'Full Model' else '#2ca02c' for n in df_sorted_r2['name']]
    axes[1].barh(df_sorted_r2['name'], df_sorted_r2['r2'], color=colors_r2)
    axes[1].set_xlabel('RÂ² (Higher is Better)')
    axes[1].set_title('Overall RÂ² Comparison', fontweight='bold')
    axes[1].grid(True, alpha=0.3, axis='x')
    for i, v in enumerate(df_sorted_r2['r2']):
        axes[1].text(v, i, f' {v:.4f}', va='center', fontsize=9)
    
    plt.tight_layout()
    fig_path = os.path.join(FIGURE_DIR, 'evaluation_comparison.png')
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… å›¾è¡¨å·²ä¿å­˜: {fig_path}")
    
    # ================= ä¿å­˜æ±‡æ€»æŠ¥å‘Š =================
    report = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'device': DEVICE,
        'n_samples': len(test_dataset),
        'models_evaluated': [m['name'] for m in available_models],
        'overall_results': all_results,
    }
    
    with open(os.path.join(RESULTS_DIR, 'evaluation_report.json'), 'w') as f:
        json.dump(report, f, indent=2, default=str)
    
    print("\n" + "="*70)
    print("âœ… è¯„ä¼°å®Œæˆï¼")
    print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {RESULTS_DIR}")
    print("   - evaluation_overall.csv (å…¨é‡æŒ‡æ ‡)")
    print("   - evaluation_by_volatility.csv (åˆ†ç»„æŒ‡æ ‡)")
    print("   - evaluation_comparison.png (å¯¹æ¯”å›¾è¡¨)")
    print("   - evaluation_report.json (å®Œæ•´æŠ¥å‘Š)")
    print("="*70)


if __name__ == "__main__":
    main()
