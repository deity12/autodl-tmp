# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€è¯„ä¼°è„šæœ¬ï¼šå¯¹æ¯” Full Model ä¸æ‰€æœ‰æ¶ˆèæ¨¡å‹çš„è¡¨ç°
========================================================================
åŠŸèƒ½ï¼š
    1. åŠ è½½ Full Modelï¼ˆç”± train_gnn.py è®­ç»ƒï¼‰å’Œæ‰€æœ‰æ¶ˆèæ¨¡å‹ï¼ˆç”± run_ablation.py è®­ç»ƒï¼‰
    2. åœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—ç»Ÿä¸€æŒ‡æ ‡ï¼ˆMSEã€RÂ²ã€æ–¹å‘å‡†ç¡®ç‡ã€ICã€RankIC ç­‰ï¼‰
    3. æŒ‰æ³¢åŠ¨ç‡åˆ†ç»„è¯„ä¼°ï¼ˆä½/ä¸­/é«˜æ³¢åŠ¨ï¼‰ï¼ŒéªŒè¯è®ºæ–‡æ ¸å¿ƒè®ºç‚¹
    4. ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼å’Œå›¾è¡¨

ä½¿ç”¨æ–¹æ³•ï¼š
    python evaluate_all.py

å‰ç½®æ¡ä»¶ï¼š
    1. å…ˆè¿è¡Œ train_gnn.py è®­ç»ƒ Full Modelï¼ˆç”Ÿæˆ best_model_gnn.pthï¼‰
    2. å†è¿è¡Œ run_ablation.py è®­ç»ƒæ¶ˆèæ¨¡å‹ï¼ˆç”Ÿæˆ ablation/best_model_*.pthï¼‰
"""

import torch
import numpy as np
import pandas as pd
import os
import sys
import json
from torch.utils.data import DataLoader
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy.stats import pearsonr, spearmanr
import matplotlib.pyplot as plt
from datetime import datetime

# ================= 1. ç¯å¢ƒä¸è·¯å¾„é…ç½® =================
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)  # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„

# è·¯å¾„é…ç½®
GRAPH_PATH = os.path.join(parent_dir, 'data', 'processed', 'Graph_Adjacency.npy')
CSV_PATH = os.path.join(parent_dir, 'data', 'processed', 'Final_Model_Data.csv')
OUTPUT_DIR = os.path.join(parent_dir, 'outputs')
CHECKPOINT_DIR = os.path.join(OUTPUT_DIR, 'checkpoints')
RESULTS_DIR = os.path.join(OUTPUT_DIR, 'results')
FIGURE_DIR = os.path.join(OUTPUT_DIR, 'figures')
os.makedirs(RESULTS_DIR, exist_ok=True)

# æ£€æŸ¥æ•°æ®æ–‡ä»¶
if not os.path.exists(CSV_PATH):
    print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° {CSV_PATH}")
    exit(1)

try:
    from dataProcessed.dataset import FinancialDataset
    from models.gnn_model import QL_MATCC_GNN_Model
    print("âœ… æˆåŠŸå¯¼å…¥åŸºç¡€æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    exit(1)

# é…ç½®
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# æ¨¡å‹é…ç½®ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
MODEL_CONFIG = {
    'input_dim': 8,
    'n_embd': 512,
    'n_layers': 4,
    'n_qubits': 4,
    'gnn_embd': 128,
    'seq_len': 30,
    'batch_size': 2048,
}

# æ‰€æœ‰æ¨¡å‹çš„é…ç½®
MODELS_TO_EVALUATE = [
    {
        'name': 'Full Model',
        'exp_name': 'full_model',
        'path': os.path.join(CHECKPOINT_DIR, 'best_model_full.pth'),  # train_full.py çš„è¾“å‡º
        'use_quantum': True,
        'use_graph': True,
        'use_matcc': True,
        'use_market_guidance': True,
    },
    {
        'name': 'w/o Quantum',
        'exp_name': 'no_quantum',
        'path': os.path.join(CHECKPOINT_DIR, 'best_model_no_quantum.pth'),
        'use_quantum': False,
        'use_graph': True,
        'use_matcc': True,
        'use_market_guidance': True,
    },
    {
        'name': 'w/o Graph',
        'exp_name': 'no_graph',
        'path': os.path.join(CHECKPOINT_DIR, 'best_model_no_graph.pth'),
        'use_quantum': True,
        'use_graph': False,
        'use_matcc': True,
        'use_market_guidance': True,
    },
    {
        'name': 'w/o MATCC',
        'exp_name': 'no_matcc',
        'path': os.path.join(CHECKPOINT_DIR, 'best_model_no_matcc.pth'),
        'use_quantum': True,
        'use_graph': True,
        'use_matcc': False,
        'use_market_guidance': True,
    },
    {
        'name': 'w/o Market',
        'exp_name': 'no_market_guidance',
        'path': os.path.join(CHECKPOINT_DIR, 'best_model_no_market_guidance.pth'),
        'use_quantum': True,
        'use_graph': True,
        'use_matcc': True,
        'use_market_guidance': False,
    },
]


# ================= 2. è¾…åŠ©å‡½æ•° =================
def calculate_metrics(y_true, y_pred):
    """è®¡ç®—å®Œæ•´è¯„ä¼°æŒ‡æ ‡"""
    y_true = np.array(y_true).flatten()
    y_pred = np.array(y_pred).flatten()
    
    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    
    # æ–¹å‘å‡†ç¡®ç‡
    true_dir = np.sign(y_true)
    pred_dir = np.sign(y_pred)
    dir_acc = np.mean(true_dir == pred_dir)
    
    # IC & RankIC
    try:
        ic, _ = pearsonr(y_pred, y_true)
        ic = float(ic)
    except:
        ic = None
    
    try:
        rank_ic, _ = spearmanr(y_pred, y_true)
        rank_ic = float(rank_ic)
    except:
        rank_ic = None
    
    return {
        'mse': mse,
        'mae': mae,
        'rmse': rmse,
        'r2': r2,
        'dir_acc': dir_acc,
        'ic': ic,
        'rank_ic': rank_ic,
        'n_samples': len(y_true),
    }


def load_model_and_predict(model_config, test_loader, adj_matrix, num_nodes):
    """åŠ è½½æ¨¡å‹å¹¶è·å–é¢„æµ‹ç»“æœ"""
    model_path = model_config['path']
    
    if not os.path.exists(model_path):
        print(f"   âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return None, None
    
    # å¤„ç† w/o Graph çš„æƒ…å†µ
    if not model_config['use_graph']:
        adj = np.eye(num_nodes, dtype=np.float32)
    else:
        adj = adj_matrix
    
    # åˆå§‹åŒ–æ¨¡å‹
    model = QL_MATCC_GNN_Model(
        input_dim=MODEL_CONFIG['input_dim'],
        n_embd=MODEL_CONFIG['n_embd'],
        n_layers=MODEL_CONFIG['n_layers'],
        n_qubits=MODEL_CONFIG['n_qubits'],
        num_nodes=num_nodes,
        adj_matrix=adj,
        gnn_embd=MODEL_CONFIG['gnn_embd'],
        use_quantum=model_config['use_quantum'],
        use_matcc=model_config['use_matcc'],
        use_market_guidance=model_config['use_market_guidance'],
    ).to(DEVICE)
    
    # åŠ è½½æƒé‡
    model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    model.eval()
    
    # é¢„æµ‹
    all_preds = []
    all_labels = []
    all_vols = []
    
    with torch.no_grad():
        for batch in test_loader:
            x = batch['x'].to(DEVICE)
            y = batch['y'].to(DEVICE)
            vol = batch['vol'].to(DEVICE)
            node_idx = batch.get('node_indices')
            if node_idx is not None:
                node_idx = node_idx.to(DEVICE)
            
            preds = model(x, vol, node_indices=node_idx)
            all_preds.append(preds.cpu().numpy())
            all_labels.append(y.cpu().numpy())
            all_vols.append(vol.cpu().numpy())
    
    preds = np.concatenate(all_preds, axis=0).flatten()
    labels = np.concatenate(all_labels, axis=0).flatten()
    vols = np.concatenate(all_vols, axis=0).flatten()
    
    return preds, labels, vols


# ================= 3. ä¸»ç¨‹åº =================
def main():
    print("="*70)
    print("ğŸ“Š ç»Ÿä¸€è¯„ä¼°ï¼šFull Model vs æ¶ˆèæ¨¡å‹")
    print("="*70)
    print(f"ğŸ“ å·¥ä½œç›®å½•: {current_dir}")
    print(f"ğŸ“Š æ•°æ®æ–‡ä»¶: {CSV_PATH}")
    print(f"ğŸ’» è®¾å¤‡: {DEVICE}")
    print()
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    print(">>> æ£€æŸ¥æ¨¡å‹æ–‡ä»¶...")
    available_models = []
    for m in MODELS_TO_EVALUATE:
        if os.path.exists(m['path']):
            print(f"   âœ… {m['name']}: {m['path']}")
            available_models.append(m)
        else:
            print(f"   âŒ {m['name']}: æ–‡ä»¶ä¸å­˜åœ¨ ({m['path']})")
    
    if len(available_models) == 0:
        print("\nâŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œè®­ç»ƒè„šæœ¬")
        return
    
    # åŠ è½½æ•°æ®
    print("\n>>> åŠ è½½æµ‹è¯•æ•°æ®...")
    train_dataset = FinancialDataset(CSV_PATH, seq_len=MODEL_CONFIG['seq_len'], mode='train')
    test_dataset = FinancialDataset(CSV_PATH, seq_len=MODEL_CONFIG['seq_len'], mode='test', scaler=train_dataset.scaler)
    test_loader = DataLoader(test_dataset, batch_size=MODEL_CONFIG['batch_size'], shuffle=False, num_workers=4)
    print(f"   æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_dataset)}")
    
    # åŠ è½½å›¾
    if GRAPH_PATH and os.path.exists(GRAPH_PATH):
        adj_matrix = np.load(GRAPH_PATH)
        print(f"   å›¾è°±: {GRAPH_PATH}, å½¢çŠ¶: {adj_matrix.shape}")
    else:
        df_t = pd.read_csv(CSV_PATH, usecols=['Ticker'])
        num_nodes = int(df_t['Ticker'].nunique())
        adj_matrix = np.eye(num_nodes, dtype=np.float32)
        print(f"   æœªæ‰¾åˆ°å›¾è°±ï¼Œä½¿ç”¨å•ä½é˜µï¼Œå½¢çŠ¶: {adj_matrix.shape}")
    
    num_nodes = adj_matrix.shape[0]
    
    # è¯„ä¼°æ‰€æœ‰æ¨¡å‹
    print("\n>>> è¯„ä¼°æ‰€æœ‰æ¨¡å‹...")
    all_results = []
    predictions = {}  # å­˜å‚¨æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœ
    
    y_true = None  # çœŸå®å€¼ï¼ˆæ‰€æœ‰æ¨¡å‹ç›¸åŒï¼‰
    vols = None    # æ³¢åŠ¨ç‡
    
    for model_config in available_models:
        print(f"\n   ğŸ“Œ æ­£åœ¨è¯„ä¼°: {model_config['name']}...")
        preds, labels, vol_data = load_model_and_predict(model_config, test_loader, adj_matrix, num_nodes)
        
        if preds is None:
            continue
        
        if y_true is None:
            y_true = labels
            vols = vol_data
        
        predictions[model_config['exp_name']] = preds
        
        # è®¡ç®—å…¨é‡æŒ‡æ ‡
        metrics = calculate_metrics(labels, preds)
        metrics['name'] = model_config['name']
        metrics['exp_name'] = model_config['exp_name']
        all_results.append(metrics)
        
        print(f"      MSE: {metrics['mse']:.6f}, RÂ²: {metrics['r2']:.4f}, "
              f"DirAcc: {metrics['dir_acc']:.4f}, IC: {metrics['ic']:.4f if metrics['ic'] else 'N/A'}")
    
    # ================= å…¨é‡è¯„ä¼°ç»“æœ =================
    print("\n" + "="*70)
    print("ğŸ“Š å…¨é‡è¯„ä¼°ç»“æœå¯¹æ¯”")
    print("="*70)
    
    df_results = pd.DataFrame(all_results)
    cols_order = ['name', 'mse', 'mae', 'rmse', 'r2', 'dir_acc', 'ic', 'rank_ic', 'n_samples']
    cols_order = [c for c in cols_order if c in df_results.columns]
    df_results = df_results[cols_order]
    
    print(df_results.to_string(index=False))
    
    # ä¿å­˜å…¨é‡ç»“æœ
    df_results.to_csv(os.path.join(RESULTS_DIR, 'evaluation_overall.csv'), index=False, float_format='%.6f')
    
    # ================= åˆ†ç»„è¯„ä¼°ï¼ˆæŒ‰æ³¢åŠ¨ç‡ï¼‰=================
    if 'full_model' in predictions and len(predictions) > 1:
        print("\n" + "="*70)
        print("ğŸ“Š åˆ†ç»„è¯„ä¼°ï¼ˆæŒ‰æ³¢åŠ¨ç‡åˆ†ä½æ•°ï¼‰")
        print("="*70)
        
        # æŒ‰æ³¢åŠ¨ç‡åˆ†ç»„
        quantiles = np.quantile(vols, [0.4, 0.8])
        groups = {
            'Low Vol (0-40%)': vols <= quantiles[0],
            'Mid Vol (40-80%)': (vols > quantiles[0]) & (vols <= quantiles[1]),
            'High Vol (80-100%)': vols > quantiles[1],
        }
        
        group_results = []
        
        for group_name, mask in groups.items():
            y_group = y_true[mask]
            
            for exp_name, preds in predictions.items():
                preds_group = preds[mask]
                metrics = calculate_metrics(y_group, preds_group)
                
                # æ‰¾åˆ°å¯¹åº”çš„æ¨¡å‹åç§°
                model_name = next((m['name'] for m in available_models if m['exp_name'] == exp_name), exp_name)
                
                group_results.append({
                    'group': group_name,
                    'model': model_name,
                    'exp_name': exp_name,
                    'mse': metrics['mse'],
                    'r2': metrics['r2'],
                    'dir_acc': metrics['dir_acc'],
                    'ic': metrics['ic'],
                    'rank_ic': metrics['rank_ic'],
                    'n_samples': metrics['n_samples'],
                })
        
        df_group = pd.DataFrame(group_results)
        
        # æ‰“å°åˆ†ç»„ç»“æœ
        for group_name in groups.keys():
            print(f"\nğŸ”¹ {group_name}")
            df_sub = df_group[df_group['group'] == group_name]
            print(df_sub[['model', 'mse', 'r2', 'dir_acc', 'ic', 'rank_ic']].to_string(index=False))
        
        # ä¿å­˜åˆ†ç»„ç»“æœ
        df_group.to_csv(os.path.join(RESULTS_DIR, 'evaluation_by_volatility.csv'), index=False, float_format='%.6f')
        
        # ================= å…³é”®ç»“è®ºï¼šé«˜æ³¢åŠ¨ç»„å¯¹æ¯” =================
        print("\n" + "="*70)
        print("ğŸ¯ å…³é”®ç»“è®ºï¼šé«˜æ³¢åŠ¨ç»„ï¼ˆTop 20%ï¼‰Full Model vs w/o Quantum å¯¹æ¯”")
        print("="*70)
        
        high_vol_full = df_group[(df_group['group'] == 'High Vol (80-100%)') & (df_group['exp_name'] == 'full_model')]
        high_vol_noq = df_group[(df_group['group'] == 'High Vol (80-100%)') & (df_group['exp_name'] == 'no_quantum')]
        
        if not high_vol_full.empty and not high_vol_noq.empty:
            full_mse = high_vol_full['mse'].values[0]
            noq_mse = high_vol_noq['mse'].values[0]
            full_ic = high_vol_full['ic'].values[0]
            noq_ic = high_vol_noq['ic'].values[0]
            full_rank_ic = high_vol_full['rank_ic'].values[0]
            noq_rank_ic = high_vol_noq['rank_ic'].values[0]
            
            print(f"\næŒ‡æ ‡               | Full Model     | w/o Quantum    | Winner")
            print("-" * 60)
            winner_mse = "âœ… Full" if full_mse < noq_mse else "âŒ NoQ"
            winner_ic = "âœ… Full" if (full_ic or 0) > (noq_ic or 0) else "âŒ NoQ"
            winner_rank_ic = "âœ… Full" if (full_rank_ic or 0) > (noq_rank_ic or 0) else "âŒ NoQ"
            print(f"MSE               | {full_mse:<14.6f} | {noq_mse:<14.6f} | {winner_mse}")
            print(f"IC                | {full_ic if full_ic else 'N/A':<14.4f} | {noq_ic if noq_ic else 'N/A':<14.4f} | {winner_ic}")
            print(f"RankIC            | {full_rank_ic if full_rank_ic else 'N/A':<14.4f} | {noq_rank_ic if noq_rank_ic else 'N/A':<14.4f} | {winner_rank_ic}")
            
            # ç»“è®º
            if full_mse < noq_mse:
                print("\nâœ… å¥½æ¶ˆæ¯ï¼Full Model åœ¨é«˜æ³¢åŠ¨æ ·æœ¬ä¸Š MSE æ›´ä¼˜ï¼")
                print("   è®ºæ–‡æ ¸å¿ƒè®ºç‚¹å¾—åˆ°éªŒè¯ï¼šé‡å­æ¨¡å—æ“…é•¿æ•æ‰é«˜æ³¢åŠ¨/æ··æ²Œç‰¹å¾ã€‚")
            elif (full_ic or 0) > (noq_ic or 0) or (full_rank_ic or 0) > (noq_rank_ic or 0):
                print("\nâš ï¸ MSE æœªé¢†å…ˆï¼Œä½† IC/RankIC æ›´ä¼˜")
                print("   å¯ä»¥ä»ç›¸å…³æ€§è§’åº¦é˜è¿°é‡å­æ¨¡å—çš„ä¼˜åŠ¿ã€‚")
            else:
                print("\nâš ï¸ é«˜æ³¢åŠ¨ç»„ Full Model æœªèƒ½é¢†å…ˆ w/o Quantum")
                print("   å»ºè®®ï¼šä½¿ç”¨åˆ†å±‚å­¦ä¹ ç‡æˆ–è°ƒæ•´é‡å­å±‚å‚æ•°åé‡æ–°è®­ç»ƒ")
    
    # ================= ç”Ÿæˆå¯¹æ¯”å›¾è¡¨ =================
    print("\n>>> ç”Ÿæˆå¯¹æ¯”å›¾è¡¨...")
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # å·¦å›¾ï¼šå…¨é‡ MSE å¯¹æ¯”
    df_sorted = df_results.sort_values('mse')
    colors = ['#FFD700' if n == 'Full Model' else '#1f77b4' for n in df_sorted['name']]
    axes[0].barh(df_sorted['name'], df_sorted['mse'], color=colors)
    axes[0].set_xlabel('MSE (Lower is Better)')
    axes[0].set_title('Overall MSE Comparison', fontweight='bold')
    axes[0].grid(True, alpha=0.3, axis='x')
    for i, v in enumerate(df_sorted['mse']):
        axes[0].text(v, i, f' {v:.6f}', va='center', fontsize=9)
    
    # å³å›¾ï¼šRÂ² å¯¹æ¯”
    df_sorted_r2 = df_results.sort_values('r2', ascending=False)
    colors_r2 = ['#FFD700' if n == 'Full Model' else '#2ca02c' for n in df_sorted_r2['name']]
    axes[1].barh(df_sorted_r2['name'], df_sorted_r2['r2'], color=colors_r2)
    axes[1].set_xlabel('RÂ² (Higher is Better)')
    axes[1].set_title('Overall RÂ² Comparison', fontweight='bold')
    axes[1].grid(True, alpha=0.3, axis='x')
    for i, v in enumerate(df_sorted_r2['r2']):
        axes[1].text(v, i, f' {v:.4f}', va='center', fontsize=9)
    
    plt.tight_layout()
    fig_path = os.path.join(FIGURE_DIR, 'evaluation_comparison.png')
    plt.savefig(fig_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"   âœ… å›¾è¡¨å·²ä¿å­˜: {fig_path}")
    
    # ================= ä¿å­˜æ±‡æ€»æŠ¥å‘Š =================
    report = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'device': DEVICE,
        'n_samples': len(test_dataset),
        'models_evaluated': [m['name'] for m in available_models],
        'overall_results': all_results,
    }
    
    with open(os.path.join(RESULTS_DIR, 'evaluation_report.json'), 'w') as f:
        json.dump(report, f, indent=2, default=str)
    
    print("\n" + "="*70)
    print("âœ… è¯„ä¼°å®Œæˆï¼")
    print(f"\nğŸ“ ç»“æœä¿å­˜åœ¨: {RESULTS_DIR}")
    print("   - evaluation_overall.csv (å…¨é‡æŒ‡æ ‡)")
    print("   - evaluation_by_volatility.csv (åˆ†ç»„æŒ‡æ ‡)")
    print("   - evaluation_comparison.png (å¯¹æ¯”å›¾è¡¨)")
    print("   - evaluation_report.json (å®Œæ•´æŠ¥å‘Š)")
    print("="*70)


if __name__ == "__main__":
    main()
