# é¡¹ç›®ç»“æ„è¯´æ˜

## ç›®å½•ç»“æ„

```
paper/
â”œâ”€â”€ README.md                  # â­ é¡¹ç›®å…¥å£æ–‡æ¡£
â”‚
â”œâ”€â”€ data/                      # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw/                   # åŸå§‹æ•°æ®ï¼ˆéœ€è‡ªè¡Œå‡†å¤‡ï¼‰
â”‚   â”‚   â””â”€â”€ FNSPID/
â”‚   â”‚       â”œâ”€â”€ full_history/  # ä¸ªè‚¡CSVæ–‡ä»¶
â”‚   â”‚       â”œâ”€â”€ nasdaq_exteral_data.csv  # æ–°é—»æ•°æ®(23GB)
â”‚   â”‚       â””â”€â”€ SP500_Index.csv          # S&P 500æŒ‡æ•°
â”‚   â””â”€â”€ processed/             # å¤„ç†åçš„æ•°æ®ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”‚       â”œâ”€â”€ Stock_Prices.csv
â”‚       â”œâ”€â”€ Stock_News.csv
â”‚       â”œâ”€â”€ Final_Model_Data.csv
â”‚       â””â”€â”€ Graph_Adjacency.npy
â”‚
â”œâ”€â”€ dataProcessed/             # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ etl.py                 # [Step 1] ETL: åˆå¹¶è‚¡ä»·+æ–°é—»
â”‚   â”œâ”€â”€ align.py               # [Step 2] å¯¹é½: è‚¡ä»·+å¸‚åœº+æ–°é—»+ç‰¹å¾
â”‚   â”œâ”€â”€ build_graph.py         # [Step 3] å›¾è°±: LLM/è§„åˆ™æ„å»ºï¼ˆS&P 500ï¼‰
â”‚   â”œâ”€â”€ dataset.py             # [Step 4] Dataset: PyTorchæ•°æ®åŠ è½½
â”‚   â””â”€â”€ download_market_index.py  # [å¯é€‰] ä¸‹è½½S&P 500æŒ‡æ•°
â”‚
â”œâ”€â”€ models/                    # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model.py          # åŸºç¡€æ¨¡å‹ï¼ˆQuantum-RWKV + MATCCï¼‰
â”‚   â”‚                          #  - VQC_Block: é‡å­çº¿è·¯
â”‚   â”‚                          #  - RWKV_TimeMixing: æ—¶é—´æ··åˆ
â”‚   â”‚                          #  - Quantum_ChannelMixing: é‡å­é€šé“
â”‚   â”‚                          #  - MATCCDecompose: è¶‹åŠ¿è§£è€¦
â”‚   â”‚                          #  - QL_MATCC_Model: åŸºç¡€æ¨¡å‹
â”‚   â””â”€â”€ gnn_model.py           # GNNæ¨¡å‹ï¼ˆå®Œæ•´æ¡†æ¶ï¼‰
â”‚                              #  - GraphAttentionLayer: GATå±‚
â”‚                              #  - QL_MATCC_GNN_Model: å®Œæ•´æ¨¡å‹
â”‚
â”œâ”€â”€ training/                  # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train_full.py          # å®Œæ•´æ¨¡å‹è®­ç»ƒ
â”‚   â””â”€â”€ train_ablation.py      # æ¶ˆèå®éªŒï¼ˆ5ç»„ï¼‰
â”‚
â”œâ”€â”€ evaluation/                # è¯„ä¼°è„šæœ¬
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ evaluate_all.py        # ç»Ÿä¸€è¯„ä¼°ï¼ˆIC/RankICç­‰ï¼‰
â”‚   â”œâ”€â”€ evaluate_by_group.py   # æŒ‰æ³¢åŠ¨ç‡åˆ†ç»„è¯„ä¼°
â”‚   â””â”€â”€ plot_ablation_comparison.py  # æ¶ˆèå®éªŒå¯è§†åŒ–
â”‚
â”œâ”€â”€ outputs/                   # æ‰€æœ‰è¾“å‡ºæ–‡ä»¶ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
â”‚   â”œâ”€â”€ checkpoints/           # æ¨¡å‹æƒé‡ (.pth)
â”‚   â”œâ”€â”€ logs/                  # è®­ç»ƒæ—¥å¿— (.json)
â”‚   â”œâ”€â”€ figures/               # å¯è§†åŒ–å›¾è¡¨ (.png)
â”‚   â””â”€â”€ results/               # è¯„ä¼°ç»“æœ (.csv)
â”‚
â”œâ”€â”€ docs/                      # ğŸ“š æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ å¿«é€Ÿå¼€å§‹.md            # 5åˆ†é’Ÿä¸Šæ‰‹æŒ‡å—
â”‚   â”œâ”€â”€ é¡¹ç›®ç»“æ„è¯´æ˜.md        # æœ¬æ–‡ä»¶
â”‚   â”œâ”€â”€ æ¨¡å—è¯´æ˜.md            # æ¯ä¸ªpyæ–‡ä»¶çš„è¯¦ç»†è¯´æ˜
â”‚   â”œâ”€â”€ æ•°æ®å¤„ç†æµç¨‹.md        # ETLæµç¨‹ä¸ç‰¹å¾å·¥ç¨‹
â”‚   â”œâ”€â”€ è®­ç»ƒä¸è¯„ä¼°.md          # è®­ç»ƒå’Œè¯„ä¼°æŒ‡å—
â”‚   â””â”€â”€ æ”¹è¿›æ–¹æ¡ˆè¯´æ˜.md        # ä¼˜åŒ–å†ç¨‹ä¸é—®é¢˜è§£å†³
â”‚
â””â”€â”€ newpaper.md               # è®ºæ–‡æŒ‡å—ï¼ˆå­¦æœ¯ç‰ˆï¼‰
```

## æ ¸å¿ƒæ–‡ä»¶è¯´æ˜

### æ•°æ®å¤„ç†æ¨¡å—

| æ–‡ä»¶ | ä½œç”¨ | è¾“å‡º | è¿è¡Œæ—¶é—´ |
|------|------|------|----------|
| `etl.py` | åˆå¹¶è‚¡ä»·ï¼Œæå–æ–°é—» | `Stock_Prices.csv`, `Stock_News.csv` | 5-10åˆ†é’Ÿ |
| `align.py` | å¯¹é½æ•°æ®ï¼Œè®¡ç®—ç‰¹å¾ | `Final_Model_Data.csv` | 2-5åˆ†é’Ÿ |
| `build_graph.py` | æ„å»ºå›¾è°±ï¼ˆS&P 500ï¼‰ | `Graph_Adjacency.npy` | 1-3åˆ†é’Ÿï¼ˆè§„åˆ™ï¼‰ï¼Œ30-60åˆ†é’Ÿï¼ˆLLMï¼‰ |
| `dataset.py` | PyTorchæ•°æ®é›†ç±» | DataLoaderå¯¹è±¡ | å®æ—¶åŠ è½½ |
| `download_market_index.py` | ä¸‹è½½S&P 500æŒ‡æ•° | `SP500_Index.csv` | 1åˆ†é’Ÿ |

### æ¨¡å‹æ¨¡å—

| æ–‡ä»¶ | åŒ…å«çš„ç±» | ä½œç”¨ |
|------|----------|------|
| `base_model.py` | `VQC_Block` | å˜åˆ†é‡å­çº¿è·¯ |
| | `RWKV_TimeMixing` | RWKVæ—¶é—´æ··åˆ |
| | `Quantum_ChannelMixing` | é‡å­é€šé“æ··åˆï¼ˆè‡ªé€‚åº”é—¨æ§ï¼‰ |
| | `MATCCDecompose` | è¶‹åŠ¿è§£è€¦ |
| | `QL_MATCC_Model` | åŸºç¡€æ¨¡å‹ |
| `gnn_model.py` | `GraphAttentionLayer` | å›¾æ³¨æ„åŠ›å±‚ |
| | `QL_MATCC_GNN_Model` | å®Œæ•´æ¨¡å‹ |

### è®­ç»ƒæ¨¡å—

| æ–‡ä»¶ | ä½œç”¨ | è¾“å‡º | è¿è¡Œæ—¶é—´ |
|------|------|------|----------|
| `train_full.py` | è®­ç»ƒå®Œæ•´æ¨¡å‹ | `best_model_full.pth` + logs + figures | 2-4å°æ—¶ |
| `train_ablation.py` | 5ç»„æ¶ˆèå®éªŒ | 5ä¸ªæ¨¡å‹ + summary + comparison | 10-20å°æ—¶ |

### è¯„ä¼°æ¨¡å—

| æ–‡ä»¶ | ä½œç”¨ | è¾“å‡º |
|------|------|------|
| `evaluate_all.py` | ç»Ÿä¸€è¯„ä¼°æ‰€æœ‰æ¨¡å‹ | `evaluation_overall.csv` + figures |
| `evaluate_by_group.py` | æŒ‰æ³¢åŠ¨ç‡åˆ†ç»„è¯„ä¼° | `evaluation_by_volatility.csv` |
| `plot_ablation_comparison.py` | å¯è§†åŒ–æ¶ˆèå®éªŒ | `ablation_comparison.png` |

---

## å®Œæ•´è¿è¡Œæµç¨‹

### æ–¹æ³•1: é€æ­¥è¿è¡Œ

```bash
cd /root/autodl-tmp/paper

# Step 1: æ•°æ®å¤„ç†
python -m dataProcessed.etl              # åˆå¹¶æ•°æ®
python -m dataProcessed.align            # å¯¹é½æ•°æ®
python -m dataProcessed.build_graph      # æ„å»ºå›¾è°±ï¼ˆS&P 500ï¼Œè§„åˆ™æ¨¡å¼ï¼‰

# Step 2: è®­ç»ƒæ¨¡å‹
python -m training.train_full            # è®­ç»ƒå®Œæ•´æ¨¡å‹

# Step 3: æ¶ˆèå®éªŒï¼ˆå¯é€‰ï¼‰
python -m training.train_ablation        # è¿è¡Œ5ç»„æ¶ˆèå®éªŒ

# Step 4: è¯„ä¼°
python -m evaluation.evaluate_all        # ç»Ÿä¸€è¯„ä¼°
python -m evaluation.evaluate_by_group   # åˆ†ç»„è¯„ä¼°
```

### æ–¹æ³•2: å¿«æ·è„šæœ¬

```bash
#!/bin/bash
# run_pipeline.sh

set -e
cd /root/autodl-tmp/paper

echo "=== Step 1/4: æ•°æ®å¤„ç† ==="
python -m dataProcessed.etl
python -m dataProcessed.align
python -m dataProcessed.build_graph

echo "=== Step 2/4: è®­ç»ƒå®Œæ•´æ¨¡å‹ ==="
python -m training.train_full

echo "=== Step 3/4: æ¶ˆèå®éªŒ ==="
python -m training.train_ablation

echo "=== Step 4/4: è¯„ä¼° ==="
python -m evaluation.evaluate_all
python -m evaluation.evaluate_by_group

echo "=== å®Œæˆï¼è¯·æŸ¥çœ‹ outputs/ ç›®å½• ==="
```

---

## æ¨¡å—å¯¼å…¥ç¤ºä¾‹

```python
# åœ¨ paper ç›®å½•ä¸‹è¿è¡ŒPython

# å¯¼å…¥æ¨¡å‹
from models import QL_MATCC_GNN_Model, QL_MATCC_Model
from models.base_model import Quantum_ChannelMixing

# å¯¼å…¥æ•°æ®é›†
from dataProcessed import FinancialDataset

# ä½¿ç”¨ç¤ºä¾‹
dataset = FinancialDataset(mode='train', seq_len=30)
q_threshold = dataset.vol_stats['p70']

model = QL_MATCC_GNN_Model(
    input_dim=8,
    n_embd=256,
    n_layers=3,
    q_threshold=q_threshold
)
```

---

## è¾“å‡ºç›®å½•è¯´æ˜

### outputs/checkpoints/
```
best_model_full.pth              # å®Œæ•´æ¨¡å‹
best_model_no_quantum.pth        # æ— é‡å­æ¨¡å—
best_model_no_graph.pth          # æ— å›¾ç¥ç»ç½‘ç»œ
best_model_no_matcc.pth          # æ— è¶‹åŠ¿è§£è€¦
best_model_no_market_guidance.pth  # æ— å¸‚åœºå¼•å¯¼
```

### outputs/logs/
```
training_losses_full.json        # å®Œæ•´æ¨¡å‹è®­ç»ƒå†å²
losses_full_model.json           # æ¶ˆèå®éªŒï¼šå®Œæ•´æ¨¡å‹
losses_no_quantum.json           # æ¶ˆèå®éªŒï¼šæ— é‡å­
losses_no_graph.json             # ...
losses_no_matcc.json
losses_no_market_guidance.json
```

### outputs/figures/
```
training_curve_full.png          # å®Œæ•´æ¨¡å‹è®­ç»ƒæ›²çº¿
ablation_comparison.png          # æ¶ˆèå®éªŒå¯¹æ¯”å›¾
evaluation_comparison.png        # è¯„ä¼°æŒ‡æ ‡å¯¹æ¯”å›¾
```

### outputs/results/
```
ablation_results_summary.csv     # æ¶ˆèå®éªŒæ±‡æ€»è¡¨
evaluation_overall.csv           # æ•´ä½“è¯„ä¼°ç»“æœ
evaluation_by_volatility.csv     # åˆ†æ³¢åŠ¨ç‡ç»„è¯„ä¼°
```

---

## æ–‡æ¡£å¯¼èˆª

- ğŸš€ [**å¿«é€Ÿå¼€å§‹**](å¿«é€Ÿå¼€å§‹.md) - 5åˆ†é’Ÿä¸Šæ‰‹
- ğŸ“¦ [**æ¨¡å—è¯´æ˜**](æ¨¡å—è¯´æ˜.md) - æ¯ä¸ªPythonæ–‡ä»¶çš„è¯¦ç»†è¯´æ˜
- ğŸ”„ [**æ•°æ®å¤„ç†æµç¨‹**](æ•°æ®å¤„ç†æµç¨‹.md) - ETLæµç¨‹ä¸ç‰¹å¾å·¥ç¨‹
- ğŸ“ [**è®­ç»ƒä¸è¯„ä¼°**](è®­ç»ƒä¸è¯„ä¼°.md) - æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°æŒ‡å—
- ğŸ’¡ [**æ”¹è¿›æ–¹æ¡ˆè¯´æ˜**](æ”¹è¿›æ–¹æ¡ˆè¯´æ˜.md) - ä¼˜åŒ–å†ç¨‹ä¸é—®é¢˜è§£å†³

---

## æ•°æ®æµå‘å›¾

```
åŸå§‹æ•°æ®
â”œâ”€ full_history/*.csv (æ•°åƒä¸ª)
â”œâ”€ nasdaq_exteral_data.csv (23GB)
â””â”€ SP500_Index.csv
      â†“ [etl.py]
â”œâ”€ Stock_Prices.csv
â””â”€ Stock_News.csv
      â†“ [align.py]
Final_Model_Data.csv
      â†“
  â”Œâ”€â”€â”€â”´â”€â”€â”€â”
  â†“       â†“
dataset.py  build_graph.py (S&P 500è¿‡æ»¤ + åˆ†å±‚é‡‡æ ·)
  â†“       â†“
DataLoader  Graph_Adjacency.npy
  â””â”€â”€â”€â”¬â”€â”€â”€â”˜
      â†“
train_full.py / train_ablation.py
  (åŠ¨æ€q_threshold + å·®å¼‚åŒ–å­¦ä¹ ç‡)
      â†“
best_model_*.pth
      â†“
evaluate_all.py
  (IC, RankIC, æ–¹å‘å‡†ç¡®ç‡ç­‰)
      â†“
evaluation_*.csv
```

---

## å…³é”®åˆ›æ–°ç‚¹

1. **åŠ¨æ€é‡å­é˜ˆå€¼**: ä»è®­ç»ƒé›†æ³¢åŠ¨ç‡p70ç™¾åˆ†ä½è‡ªåŠ¨è·å–
2. **S&P 500è¿‡æ»¤**: ä½¿ç”¨é«˜è´¨é‡æˆåˆ†è‚¡ï¼Œæå‡å›¾è°±è´¨é‡
3. **åˆ†å±‚é‡‡æ ·**: ç¡®ä¿æ¯åªè‚¡ç¥¨éƒ½æœ‰ä»£è¡¨æ€§çš„æ–°é—»
4. **å·®å¼‚åŒ–å­¦ä¹ ç‡**: é‡å­å±‚3e-5ï¼Œç»å…¸å±‚3e-4
5. **è‡ªé€‚åº”é—¨æ§**: ä»…åœ¨é«˜æ³¢åŠ¨æ—¶æ¿€æ´»é‡å­é€šé“

---

## å¸¸è§ç›®å½•é—®é¢˜

### Q: data/processed/ ç›®å½•ä¸ºç©ºï¼Ÿ

ç¡®ä¿å·²è¿è¡Œæ•°æ®å¤„ç†è„šæœ¬ï¼š
```bash
python -m dataProcessed.etl
python -m dataProcessed.align
python -m dataProcessed.build_graph
```

### Q: outputs/ ç›®å½•ä¸å­˜åœ¨ï¼Ÿ

é¦–æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨åˆ›å»ºï¼Œæˆ–æ‰‹åŠ¨åˆ›å»ºï¼š
```bash
mkdir -p outputs/{checkpoints,logs,figures,results}
```

### Q: å¦‚ä½•æ¸…ç†æ‰€æœ‰è¾“å‡ºé‡æ–°å¼€å§‹ï¼Ÿ

```bash
rm -rf outputs/*
rm -rf data/processed/*
```

**æ³¨æ„**: ä¸è¦åˆ é™¤ `data/raw/` ç›®å½•ï¼ˆåŸå§‹æ•°æ®ï¼‰

---

## ç£ç›˜ç©ºé—´è¦æ±‚

| ç›®å½• | ä¼°è®¡å¤§å° |
|------|----------|
| `data/raw/` | ~30GBï¼ˆåŸå§‹æ•°æ®ï¼‰ |
| `data/processed/` | ~5GBï¼ˆå¤„ç†åæ•°æ®ï¼‰ |
| `outputs/checkpoints/` | ~500MBï¼ˆ5ä¸ªæ¨¡å‹ï¼‰ |
| `outputs/logs/` | ~10MBï¼ˆJSONæ—¥å¿—ï¼‰ |
| `outputs/figures/` | ~5MBï¼ˆå›¾è¡¨ï¼‰ |
| `outputs/results/` | ~1MBï¼ˆCSVç»“æœï¼‰ |
| **æ€»è®¡** | ~35-40GB |

å»ºè®®é¢„ç•™è‡³å°‘ **50GB** å¯ç”¨ç©ºé—´ã€‚
