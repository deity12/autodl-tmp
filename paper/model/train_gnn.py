# -*- coding: utf-8 -*-
"""
QL-MATCC-GNN æ¨¡å‹è®­ç»ƒè„šæœ¬ï¼ˆå¯¹åº”è®ºæ–‡å®Œæ•´æ¶æ„ï¼šLLM å›¾è°± + Quantum-RWKV + MATCC + GNNï¼‰
========================================================================
ç›¸å¯¹ train_autodl.py çš„ä¿®æ”¹ï¼š
    1. ä½¿ç”¨ QL_MATCC_GNN_Modelï¼ˆèåˆ GAT å›¾ç¥ç»ç½‘ç»œï¼‰
    2. åŠ è½½é‚»æ¥çŸ©é˜µ Graph_Adjacency.npyï¼ˆç”± dataProcessed/build_graph.py ç”Ÿæˆï¼‰
    3. å‰å‘æ—¶ä¼ å…¥ node_indices=Noneï¼ˆé€€åŒ–æ¨¡å¼ï¼šbatch å†…æ— å›¾ç»“æ„æ—¶ GNN ä»…è‡ªç¯ï¼‰
    4. æ¨¡å‹ä¸æ›²çº¿åˆ†åˆ«ä¿å­˜ä¸º best_model_gnn.pthã€training_curve_gnn.pngï¼Œé¿å…è¦†ç›–åŸç‰ˆ

è¿è¡Œé¡ºåºå»ºè®®ï¼š
    1. å…ˆè¿è¡Œ dataProcessed/build_graph.py ç”Ÿæˆ Graph_Adjacency.npy
    2. å†è¿è¡Œæœ¬è„šæœ¬ï¼špython model/train_gnn.py
"""

import sys
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# ================= 1. ç¯å¢ƒä¸è·¯å¾„ =================
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(os.path.join(parent_dir, 'dataProcessed'))
sys.path.append(current_dir)

# é‚»æ¥çŸ©é˜µè·¯å¾„ï¼ˆä¸ build_graph è¾“å‡ºä¸€è‡´ï¼‰
GRAPH_PATH = os.path.join(parent_dir, 'data', 'processed', 'Graph_Adjacency.npy')

try:
    from dataset import FinancialDataset
    from model_gnn import QL_MATCC_GNN_Model
    print("âœ… æˆåŠŸå¯¼å…¥ datasetã€model_gnn æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    exit(1)

# ================= 2. è¶…å‚æ•° =================
CONFIG = {
    'csv_path': os.path.join(parent_dir, 'data', 'processed', 'Final_Model_Data.csv'),
    'input_dim': 8,
    'n_embd': 512,
    'n_layers': 4,
    'n_qubits': 4,
    # GNNï¼šå›¾åµŒå…¥ç”¨è¾ƒå°ç»´åº¦å¯å‡è½»æ˜¾å­˜ï¼ˆGAT çš„ NÃ—NÃ—2*gnn_embdï¼‰
    'gnn_embd': 64,
    'seq_len': 30,
    # GNN çš„ GAT å±‚æœ‰ O(B^2) æ˜¾å­˜ï¼Œè¾ƒå¤§ n_embd+gnn æ—¶å»ºè®®é€‚å½“å‡å° batch
    'batch_size': 512,
    'epochs': 10,
    'lr': 1e-4,
    'early_stop_patience': 3,
    'device': 'cuda' if torch.cuda.is_available() else 'cpu',
    'num_workers': 8,
    'prefetch_factor': 4,
}


def main():
    print(f">>> Training on device: {CONFIG['device']}")
    if CONFIG['device'] == 'cuda':
        print(f"   GPU: {torch.cuda.get_device_name(0)}")

    # ================= 3. åŠ è½½é‚»æ¥çŸ©é˜µ =================
    if os.path.exists(GRAPH_PATH):
        adj_matrix = np.load(GRAPH_PATH)
        print(f">>> åŠ è½½å›¾è°±: {GRAPH_PATH}, å½¢çŠ¶: {adj_matrix.shape}")
    else:
        # è‹¥æœªç”Ÿæˆå›¾è°±ï¼Œç”¨å•ä½é˜µå…œåº•ï¼ˆGNN é€€åŒ–ä¸ºä»…è‡ªç¯ï¼‰
        df_t = pd.read_csv(CONFIG['csv_path'], usecols=['Ticker'])
        num_nodes = int(df_t['Ticker'].nunique())
        adj_matrix = np.eye(num_nodes, dtype=np.float32)
        print(f">>> æœªæ‰¾åˆ° {GRAPH_PATH}ï¼Œä½¿ç”¨å•ä½é˜µ (num_nodes={num_nodes})ã€‚å»ºè®®å…ˆè¿è¡Œ: python dataProcessed/build_graph.py")

    num_nodes = adj_matrix.shape[0]

    # ================= 4. æ•°æ®åŠ è½½ =================
    print("\n>>> Loading Datasets...")
    try:
        train_dataset = FinancialDataset(CONFIG['csv_path'], seq_len=CONFIG['seq_len'], mode='train')
        test_dataset = FinancialDataset(CONFIG['csv_path'], seq_len=CONFIG['seq_len'], mode='test', scaler=train_dataset.scaler)
        print(f"   Train: {len(train_dataset)}, Test: {len(test_dataset)}")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    train_loader = DataLoader(
        train_dataset,
        batch_size=CONFIG['batch_size'],
        shuffle=True,
        num_workers=CONFIG.get('num_workers', 8),
        pin_memory=True,
        prefetch_factor=CONFIG.get('prefetch_factor', 4),
        persistent_workers=True if CONFIG.get('num_workers', 0) > 0 else False,
    )
    test_loader = DataLoader(
        test_dataset,
        batch_size=CONFIG['batch_size'],
        shuffle=False,
        num_workers=CONFIG.get('num_workers', 8),
        pin_memory=True,
        prefetch_factor=CONFIG.get('prefetch_factor', 4),
        persistent_workers=True if CONFIG.get('num_workers', 0) > 0 else False,
    )

    # ================= 5. æ¨¡å‹åˆå§‹åŒ–ï¼ˆQL-MATCC-GNNï¼‰=================
    print("\n>>> Initializing QL_MATCC_GNN_Model...")
    model = QL_MATCC_GNN_Model(
        input_dim=CONFIG['input_dim'],
        n_embd=CONFIG['n_embd'],
        n_layers=CONFIG['n_layers'],
        n_qubits=CONFIG['n_qubits'],
        num_nodes=num_nodes,
        adj_matrix=adj_matrix,
        gnn_embd=CONFIG.get('gnn_embd', 64),
    ).to(CONFIG['device'])

    total_params = sum(p.numel() for p in model.parameters())
    print(f"   Total parameters: {total_params:,}")

    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=CONFIG['lr'], betas=(0.9, 0.999), eps=1e-8)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, min_lr=1e-6)
    use_amp = False

    # ================= 6. è®­ç»ƒå¾ªç¯ =================
    train_losses, val_losses = [], []
    best_val_loss = float('inf')
    early_stop_counter = 0
    early_stop_patience = CONFIG['early_stop_patience']

    print("\n>>> Start Training (QL-MATCC-GNN)...")
    print(">>> Dataset å·²æä¾› node_indicesï¼Œå°†ç”¨å…¶ä»é‚»æ¥çŸ©é˜µåˆ‡ç‰‡ batch å†…å­å›¾åš GNN èšåˆã€‚")
    print("=" * 60)

    for epoch in range(CONFIG['epochs']):
        model.train()
        epoch_train_loss = 0.0
        num_batches = 0
        progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{CONFIG['epochs']} [Train]", ncols=100)

        for batch_idx, batch in enumerate(progress_bar):
            x = batch['x'].to(CONFIG['device'], non_blocking=True)
            y = batch['y'].to(CONFIG['device'], non_blocking=True)
            vol = batch['vol'].to(CONFIG['device'], non_blocking=True)
            # Dataset å·²è¿”å› node_indices (B,)ï¼Œç”¨äºä»å…¨å›¾é‚»æ¥çŸ©é˜µåˆ‡ç‰‡ batch å†…å­å›¾
            node_indices = batch.get('node_indices')
            if node_indices is not None:
                node_indices = node_indices.to(CONFIG['device'], non_blocking=True)

            optimizer.zero_grad()
            preds = model(x, vol, node_indices=node_indices)
            loss = criterion(preds, y)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            if torch.isnan(loss) or torch.isinf(loss):
                print(f"\nâŒ NaN/Inf at batch {batch_idx}")
                return

            epoch_train_loss += loss.item()
            num_batches += 1
            progress_bar.set_postfix(loss=f'{loss.item():.6f}', avg=f'{epoch_train_loss/num_batches:.6f}')

        avg_train = epoch_train_loss / len(train_loader)
        train_losses.append(avg_train)

        # ---------- éªŒè¯ ----------
        model.eval()
        epoch_val = 0.0
        with torch.no_grad():
            for batch in test_loader:
                x = batch['x'].to(CONFIG['device'], non_blocking=True)
                y = batch['y'].to(CONFIG['device'], non_blocking=True)
                vol = batch['vol'].to(CONFIG['device'], non_blocking=True)
                node_indices = batch.get('node_indices')
                if node_indices is not None:
                    node_indices = node_indices.to(CONFIG['device'], non_blocking=True)
                preds = model(x, vol, node_indices=node_indices)
                epoch_val += criterion(preds, y).item()
        avg_val = epoch_val / len(test_loader)
        val_losses.append(avg_val)

        old_lr = optimizer.param_groups[0]['lr']
        scheduler.step(avg_val)
        cur_lr = optimizer.param_groups[0]['lr']

        print(f"\nEpoch {epoch+1}/{CONFIG['epochs']}: Train={avg_train:.6f}, Val={avg_val:.6f}, lr={cur_lr:.2e}" + (" â¬‡ï¸" if cur_lr != old_lr else ""))

        if avg_val < best_val_loss:
            best_val_loss = avg_val
            save_path = os.path.join(current_dir, 'best_model_gnn.pth')
            torch.save(model.state_dict(), save_path)
            print(f"  ğŸŒŸ Best model saved: {save_path}")
            early_stop_counter = 0
        else:
            early_stop_counter += 1

        if early_stop_counter >= early_stop_patience:
            print(f"\nğŸ›‘ Early stopping (best val loss: {best_val_loss:.6f})")
            break
        print("-" * 60)

    # ================= 7. æ›²çº¿ä¸æ€»ç»“ =================
    curve_path = os.path.join(current_dir, 'training_curve_gnn.png')
    plt.figure(figsize=(12, 6))
    plt.plot(range(1, len(train_losses) + 1), train_losses, 'b-', label='Train Loss', lw=2)
    plt.plot(range(1, len(val_losses) + 1), val_losses, 'r-', label='Val Loss', lw=2)
    if val_losses:
        be = val_losses.index(best_val_loss) + 1
        plt.plot(be, best_val_loss, 'g*', markersize=14, label=f'Best (Epoch {be})')
    plt.title('QL-MATCC-GNN Training', fontsize=14)
    plt.xlabel('Epoch')
    plt.ylabel('MSE Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(curve_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f">>> è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {curve_path}")

    print("\n" + "=" * 60)
    print(">>> QL-MATCC-GNN è®­ç»ƒç»“æŸ")
    print(f"    Best Val Loss: {best_val_loss:.6f}")
    print(f"    Model: best_model_gnn.pth")
    print("=" * 60)


if __name__ == "__main__":
    main()
