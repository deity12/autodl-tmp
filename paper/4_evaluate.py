#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
4_evaluate.py - å•æ¨¡å‹è¯„ä¼°è„šæœ¬ï¼ˆå¯ç›´æ¥è¿è¡Œï¼‰

ç”¨æ³•ï¼š
  æ–¹å¼1ï¼šç›´æ¥è¿è¡Œï¼ˆé»˜è®¤é…ç½®ï¼‰
 æ–¹å¼2ï¼šå‘½ä»¤è¡Œè¦†ç›–å‚æ•°
    python 4_evaluate.py --checkpoint ./outputs/checkpoints/best_model.pth --test_data ./paper/data/processed/Final_Model_Data.csv
"""

from __future__ import annotations

import argparse
import json
import os
import sys
import warnings
from typing import Optional

# æŠ‘åˆ¶ PyG å¯é€‰æ‰©å±•åº“åŠ è½½å¤±è´¥è­¦å‘Šï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼Œä»…éƒ¨åˆ†ç®—å­å›é€€åˆ° PyTorchï¼‰
warnings.filterwarnings("ignore", message=".*An issue occurred while importing.*", category=UserWarning)

import numpy as np
import torch
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from scipy.stats import pearsonr, spearmanr

from utils.logging_utils import setup_logging

# ================= é…ç½®ï¼ˆå¯ç›´æ¥ä¿®æ”¹ï¼‰=================
_SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
CHECKPOINT_PATH = os.path.join(_SCRIPT_DIR, "outputs", "checkpoints", "best_model.pth")
DATA_CSV_PATH = os.path.join(_SCRIPT_DIR, "data", "processed", "Final_Model_Data.csv")
GRAPH_PATH = os.path.join(_SCRIPT_DIR, "data", "processed", "Graph_Adjacency.npy")
GRAPH_TICKERS_PATH = os.path.join(_SCRIPT_DIR, "data", "processed", "Graph_Tickers.json")

BATCH_SIZE = 2048
USE_GRAPH = True
TOP_K = 30  # ä¸è®ºæ–‡ä¸€è‡´ï¼šTop-30 Long-Short
ANNUALIZATION = 252

# ä¸ train_full ä¸€è‡´ï¼šscaler ç”¨è®­ç»ƒæœŸï¼Œæµ‹è¯•é›†ç”¨ 2021-01-01~2023-12-31ï¼ˆè®ºæ–‡æŠ¥å‘ŠåŒºé—´ï¼‰
TRAIN_START = "2018-01-01"
TRAIN_END = "2020-06-30"
TEST_START = "2021-01-01"
TEST_END = "2023-12-31"

MODEL_N_EMBD = 256
MODEL_N_LAYERS = 3
MODEL_GNN_EMBD = 64
SEQ_LEN = 30
# ====================================================


def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="è¯„ä¼° Graph-RWKV æ¨¡å‹")
    parser.add_argument("--checkpoint", type=str, default=CHECKPOINT_PATH, help="æ¨¡å‹æƒé‡è·¯å¾„")
    parser.add_argument("--test_data", type=str, default=DATA_CSV_PATH, help="æµ‹è¯•æ•°æ® CSV è·¯å¾„")
    parser.add_argument("--graph", type=str, default=GRAPH_PATH, help="å›¾è°±é‚»æ¥çŸ©é˜µè·¯å¾„")
    parser.add_argument("--graph_tickers", type=str, default=GRAPH_TICKERS_PATH, help="å›¾è°± tickers è·¯å¾„")
    parser.add_argument("--batch_size", type=int, default=BATCH_SIZE, help="è¯„ä¼°æ‰¹å¤§å°")
    parser.add_argument("--use_graph", action=argparse.BooleanOptionalAction, default=USE_GRAPH, help="æ˜¯å¦ä½¿ç”¨å›¾æ¨¡å‹")
    parser.add_argument("--top_k", type=int, default=TOP_K, help="Top-K Long-Short çš„ K")
    parser.add_argument("--annualization", type=int, default=ANNUALIZATION, help="å¹´åŒ–ç³»æ•°ï¼ˆäº¤æ˜“æ—¥ï¼‰")
    parser.add_argument("--train_start", type=str, default=TRAIN_START, help="è®­ç»ƒæœŸèµ·å§‹ï¼ˆç”¨äº fit scalerï¼‰")
    parser.add_argument("--train_end", type=str, default=TRAIN_END, help="è®­ç»ƒæœŸç»“æŸ")
    parser.add_argument("--test_start", type=str, default=TEST_START, help="æµ‹è¯•é›†èµ·å§‹ï¼ˆè®ºæ–‡æŠ¥å‘ŠåŒºé—´ï¼‰")
    parser.add_argument("--test_end", type=str, default=TEST_END, help="æµ‹è¯•é›†ç»“æŸ")
    return parser.parse_args()


def _calc_metrics(y_true: np.ndarray, y_pred: np.ndarray, dates: list[str] = None) -> dict:
    """è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬æ¯æ—¥ IC/RankIC å’Œ ICIR/RankICIRï¼ˆç¬¦åˆé¡¶ä¼šæ ‡å‡†ï¼‰"""
    from collections import defaultdict
    
    y_true = y_true.flatten()
    y_pred = y_pred.flatten()

    mse = mean_squared_error(y_true, y_pred)
    mae = mean_absolute_error(y_true, y_pred)
    rmse = float(np.sqrt(mse))
    r2 = r2_score(y_true, y_pred)

    true_dir = np.sign(y_true)
    pred_dir = np.sign(y_pred)
    dir_acc = float(np.mean(true_dir == pred_dir))

    # è®¡ç®—æ•´ä½“ IC/RankIC
    ic = None
    rank_ic = None
    try:
        ic_val, _ = pearsonr(y_pred, y_true)
        ic = float(ic_val)
    except Exception:
        pass
    try:
        ric_val, _ = spearmanr(y_pred, y_true)
        rank_ic = float(ric_val)
    except Exception:
        pass

    # è®¡ç®—æ¯æ—¥ IC/RankICï¼Œç„¶åèšåˆä¸º ICIR/RankICIRï¼ˆé¡¶ä¼šæ ‡å‡†åšæ³•ï¼‰
    icir = None
    rank_icir = None
    daily_ic = None
    daily_rankic = None
    
    if dates is not None and len(dates) == len(y_true):
        buckets_true = defaultdict(list)
        buckets_pred = defaultdict(list)
        for t, p, d in zip(y_true, y_pred, dates):
            buckets_true[d].append(float(t))
            buckets_pred[d].append(float(p))
        
        ic_list = []
        rankic_list = []
        for d in buckets_true.keys():
            yt = np.asarray(buckets_true[d], dtype=np.float64)
            yp = np.asarray(buckets_pred[d], dtype=np.float64)
            if yt.size < 2:
                continue
            try:
                ic_val, _ = pearsonr(yp, yt)
                ic_list.append(float(ic_val))
            except Exception:
                pass
            try:
                ric_val, _ = spearmanr(yp, yt)
                rankic_list.append(float(ric_val))
            except Exception:
                pass
        
        if ic_list:
            daily_ic = float(np.mean(ic_list))
            if np.std(ic_list) > 1e-8:
                icir = float(np.mean(ic_list) / np.std(ic_list))
        
        if rankic_list:
            daily_rankic = float(np.mean(rankic_list))
            if np.std(rankic_list) > 1e-8:
                rank_icir = float(np.mean(rankic_list) / np.std(rankic_list))

    return {
        "mse": float(mse),
        "mae": float(mae),
        "rmse": rmse,
        "r2": float(r2),
        "dir_acc": dir_acc,
        "ic": ic,
        "rank_ic": rank_ic,
        "daily_ic": daily_ic,        # æ¯æ—¥ IC å‡å€¼
        "daily_rankic": daily_rankic, # æ¯æ—¥ RankIC å‡å€¼
        "icir": icir,                # IC ç¨³å®šæ€§æŒ‡æ ‡
        "rank_icir": rank_icir,      # RankIC ç¨³å®šæ€§æŒ‡æ ‡
        "n_samples": int(len(y_true)),
    }


def _calc_backtest_metrics(
    y_true: np.ndarray,
    y_pred: np.ndarray,
    dates: list[str],
    top_k: int = 10,
    annualization: int = 252,
) -> dict:
    """Top-K Long-Short å›æµ‹æŒ‡æ ‡ã€‚"""
    if not dates:
        return {}

    df = {
        "date": dates,
        "y_true": y_true.flatten(),
        "y_pred": y_pred.flatten(),
    }
    df = np.rec.fromarrays([df["date"], df["y_true"], df["y_pred"]], names="date,y_true,y_pred")
    df = np.array(df)

    daily_returns = []
    unique_dates = np.unique(df["date"])
    for d in unique_dates:
        mask = df["date"] == d
        day = df[mask]
        if len(day) < top_k * 2:
            continue
        order = np.argsort(day["y_pred"])
        short_idx = order[:top_k]
        long_idx = order[-top_k:]
        long_ret = np.expm1(day["y_true"][long_idx]).mean()
        short_ret = np.expm1(day["y_true"][short_idx]).mean()
        daily_returns.append(long_ret - short_ret)

    if not daily_returns:
        return {}

    daily_returns = np.array(daily_returns, dtype=np.float64)
    mean_ret = daily_returns.mean()
    std_ret = daily_returns.std(ddof=1) if daily_returns.size > 1 else 0.0

    cumulative = np.cumprod(1.0 + daily_returns)
    peak = np.maximum.accumulate(cumulative)
    drawdown = (cumulative - peak) / peak

    ann_return = cumulative[-1] ** (annualization / len(daily_returns)) - 1.0
    sharpe = (mean_ret / std_ret) * np.sqrt(annualization) if std_ret > 1e-12 else None
    max_dd = float(drawdown.min()) if drawdown.size else 0.0

    return {
        "topk_k": int(top_k),
        "annual_return": float(ann_return),
        "sharpe": float(sharpe) if sharpe is not None else None,
        "max_drawdown": max_dd,
        "n_days": int(len(daily_returns)),
    }


def _load_model_config_from_log(checkpoint_path: str) -> dict:
    """å°è¯•ä»è®­ç»ƒæ—¥å¿—ä¸­è¯»å–æ¨¡å‹é…ç½®ï¼Œé¿å…è¯„ä¼°ç»´åº¦ä¸åŒ¹é…ã€‚"""
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(checkpoint_path)))
    log_path = os.path.join(base_dir, "logs", "training_losses_full.json")
    if not os.path.exists(log_path):
        return {}
    try:
        with open(log_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        cfg = data.get("config", {}) if isinstance(data, dict) else {}
        return {
            "n_embd": cfg.get("n_embd"),
            "n_layers": cfg.get("n_layers"),
            "gnn_embd": cfg.get("gnn_embd"),
            "seq_len": cfg.get("seq_len"),
        }
    except Exception:
        return {}


def main() -> None:
    args = _parse_args()
    log_ctx = setup_logging(os.path.dirname(args.checkpoint) or ".", "evaluate")
    logger = log_ctx.logger

    try:
        sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
        from dataProcessed.dataset import FinancialDataset
        from models.gnn_model import GraphRWKV_GNN_Model
        from models.base_model import GraphRWKV_Model

        if not os.path.exists(args.checkpoint):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {args.checkpoint}")
        if not os.path.exists(args.test_data):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°æµ‹è¯•æ•°æ®: {args.test_data}")

        device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info("è®¾å¤‡: %s", device)

        cfg_override = _load_model_config_from_log(args.checkpoint)
        n_embd = int(cfg_override.get("n_embd") or MODEL_N_EMBD)
        n_layers = int(cfg_override.get("n_layers") or MODEL_N_LAYERS)
        gnn_embd = int(cfg_override.get("gnn_embd") or MODEL_GNN_EMBD)
        seq_len = int(cfg_override.get("seq_len") or SEQ_LEN)

        train_dataset = FinancialDataset(
            args.test_data,
            seq_len=seq_len,
            mode="train",
            start_date=args.train_start,
            end_date=args.train_end,
        )
        test_dataset = FinancialDataset(
            args.test_data,
            seq_len=seq_len,
            mode="test",
            scaler=train_dataset.scaler,
            vol_stats=getattr(train_dataset, "vol_stats", None),
            start_date=args.test_start,
            end_date=args.test_end,
        )
        input_dim = len(train_dataset.feature_cols)

        test_loader = torch.utils.data.DataLoader(
            test_dataset,
            batch_size=args.batch_size,
            shuffle=False,
            num_workers=min(8, max(2, (os.cpu_count() or 12) - 2)),
            pin_memory=torch.cuda.is_available(),
            persistent_workers=True,
            prefetch_factor=4,
        )

        if args.use_graph:
            if not os.path.exists(args.graph):
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°å›¾è°±æ–‡ä»¶: {args.graph}")
            adj_matrix = np.load(args.graph)
            num_nodes = adj_matrix.shape[0]
            model = GraphRWKV_GNN_Model(
                input_dim=input_dim,
                n_embd=n_embd,
                n_layers=n_layers,
                num_nodes=num_nodes,
                adj_matrix=adj_matrix,
                gnn_embd=gnn_embd,
            ).to(device)
        else:
            model = GraphRWKV_Model(
                input_dim=input_dim,
                n_embd=n_embd,
                n_layers=n_layers,
            ).to(device)

        model.load_state_dict(torch.load(args.checkpoint, map_location=device))
        model.eval()

        all_preds = []
        all_labels = []
        all_dates = []

        with torch.inference_mode():
            for batch in test_loader:
                x = batch["x"].to(device, non_blocking=True)
                y = batch["y"].to(device, non_blocking=True)
                vol = batch.get("vol")
                if vol is not None:
                    vol = vol.to(device, non_blocking=True)
                node_idx = batch.get("node_indices")
                if node_idx is not None:
                    node_idx = node_idx.to(device, non_blocking=True)
                dates = batch.get("target_date")
                if dates is not None:
                    all_dates.extend(list(dates))

                if args.use_graph:
                    preds = model(x, vol=vol, node_indices=node_idx)
                else:
                    preds = model(x, vol=vol)
                all_preds.append(preds.cpu().numpy())
                all_labels.append(y.cpu().numpy())

        y_pred = np.concatenate(all_preds, axis=0)
        y_true = np.concatenate(all_labels, axis=0)
        metrics = _calc_metrics(y_true, y_pred, all_dates)  # ä¼ å…¥ dates ä»¥è®¡ç®— ICIR
        backtest = _calc_backtest_metrics(
            y_true,
            y_pred,
            all_dates,
            top_k=args.top_k,
            annualization=args.annualization,
        )

        # æ ¼å¼åŒ–è¾“å‡ºï¼ˆç¬¦åˆé¡¶ä¼šè®ºæ–‡è¡¨æ ¼æ ¼å¼ï¼‰
        print("\n" + "=" * 60)
        print("ğŸ“Š Graph-RWKV æ¨¡å‹è¯„ä¼°ç»“æœï¼ˆæµ‹è¯•é›†ï¼‰")
        print(f"   æµ‹è¯•é›†åŒºé—´: {args.test_start} ~ {args.test_end}ï¼ˆä¸ train_full ä¸€è‡´ï¼‰")
        print("=" * 60)
        print(f"\nã€é¢„æµ‹èƒ½åŠ›æŒ‡æ ‡ã€‘")
        print(f"  IC (æ¯æ—¥å‡å€¼):        {metrics.get('daily_ic', 'N/A'):.4f}" if metrics.get('daily_ic') else "  IC (æ¯æ—¥å‡å€¼):        N/A")
        print(f"  RankIC (æ¯æ—¥å‡å€¼):    {metrics.get('daily_rankic', 'N/A'):.4f}" if metrics.get('daily_rankic') else "  RankIC (æ¯æ—¥å‡å€¼):    N/A")
        print(f"  ICIR:                 {metrics.get('icir', 'N/A'):.4f}" if metrics.get('icir') else "  ICIR:                 N/A")
        print(f"  RankICIR:             {metrics.get('rank_icir', 'N/A'):.4f}" if metrics.get('rank_icir') else "  RankICIR:             N/A")
        print(f"\nã€å›å½’æŒ‡æ ‡ã€‘")
        print(f"  MSE:                  {metrics['mse']:.6f}")
        print(f"  RMSE:                 {metrics['rmse']:.6f}")
        print(f"  RÂ²:                   {metrics['r2']:.4f}")
        print(f"  æ–¹å‘å‡†ç¡®ç‡:           {metrics['dir_acc']:.2%}")
        print(f"  æ ·æœ¬æ•°:               {metrics['n_samples']}")
        
        if backtest:
            print(f"\nã€Top-{args.top_k} Long-Short å›æµ‹ã€‘")
            print(f"  å¹´åŒ–æ”¶ç›Šç‡:           {backtest.get('annual_return', 'N/A'):.2%}" if backtest.get('annual_return') is not None else "  å¹´åŒ–æ”¶ç›Šç‡:           N/A")
            print(f"  å¤æ™®æ¯”ç‡:             {backtest.get('sharpe', 'N/A'):.4f}" if backtest.get('sharpe') else "  å¤æ™®æ¯”ç‡:             N/A")
            print(f"  æœ€å¤§å›æ’¤:             {backtest.get('max_drawdown', 'N/A'):.2%}" if backtest.get('max_drawdown') is not None else "  æœ€å¤§å›æ’¤:             N/A")
            print(f"  äº¤æ˜“å¤©æ•°:             {backtest.get('n_days', 'N/A')}")
        
        print("=" * 60)
        
        logger.info("è¯„ä¼°å®Œæˆ: %s", metrics)
        if backtest:
            logger.info("å›æµ‹æŒ‡æ ‡: %s", backtest)
    except Exception as exc:
        logger.exception("è¯„ä¼°å¤±è´¥: %s", exc)
        raise
    finally:
        log_ctx.restore_print()


if __name__ == "__main__":
    main()
