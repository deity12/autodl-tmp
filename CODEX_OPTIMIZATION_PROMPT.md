# Codex ä»£ç ä¼˜åŒ–æç¤ºè¯ï¼ˆGraph-RWKV é¡¹ç›®ï¼‰

## ğŸ“‹ é¡¹ç›®èƒŒæ™¯

**é¡¹ç›®åç§°**ï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹åŠ¨æ€å›¾è°±ä¸ Graph-RWKV çš„æ—¶ç©ºè§£è€¦é‡‘èé¢„æµ‹ç ”ç©¶

**å½“å‰çŠ¶æ€**ï¼š
- å·²å®Œæˆä»æ—§æ¶æ„ï¼ˆQL-MATCC-GNN with Quantumï¼‰åˆ°æ–°æ¶æ„ï¼ˆGraph-RWKVï¼‰çš„ä»£ç é‡æ„
- å·²ç§»é™¤ Quantumã€MATCCã€MarketGuidance ç­‰ä¸éœ€è¦çš„ç»„ä»¶
- æ ¸å¿ƒæ¶æ„ï¼šRWKV æ—¶é—´åºåˆ—ç¼–ç å™¨ + åŠ¨æ€å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰
- æ•°æ®æµï¼šFNSPID æ–°é—»æ•°æ® â†’ LLM æå–å…³ç³»+æƒ…æ„Ÿ â†’ æ··åˆå›¾æ„å»º â†’ Graph-RWKV è®­ç»ƒ

## ğŸ–¥ï¸ æœåŠ¡å™¨é…ç½®ï¼ˆé‡è¦ï¼ï¼‰

**ç¡¬ä»¶èµ„æº**ï¼š
- **GPU**: 48GB VRAM (vGPU-48GB-350W) Ã— 1
- **CPU**: 12 vCPU Intel Xeon Platinum 8260 @ 2.40GHz
- **RAM**: 90GB
- **Disk**: 50GB æ•°æ®ç›˜ï¼ˆéœ€æ³¨æ„ç©ºé—´ç®¡ç†ï¼‰

**è½¯ä»¶ç¯å¢ƒ**ï¼š
- **PyTorch**: 2.1.2
- **Python**: 3.10
- **CUDA**: 11.8
- **OS**: Ubuntu 22.04

**ä¼˜åŒ–é‡ç‚¹**ï¼š
- å……åˆ†åˆ©ç”¨ 48GB GPUï¼šå¤§ batch sizeã€é•¿åºåˆ—ã€å¤§æ¨¡å‹
- å……åˆ†åˆ©ç”¨ 90GB RAMï¼šæ•°æ®ç¼“å­˜ã€å†…å­˜æ˜ å°„ã€é¢„åŠ è½½
- 12 vCPUï¼šå¤šè¿›ç¨‹æ•°æ®åŠ è½½ï¼ˆnum_workers=8-10ï¼‰
- 50GB ç£ç›˜ï¼šä¼˜åŒ–å­˜å‚¨æ ¼å¼ï¼Œé¿å…å†—ä½™æ–‡ä»¶

---

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„è¯´æ˜

### 1. **æ—¶é—´ç»´ï¼šRWKV æ—¶é—´åºåˆ—ç¼–ç å™¨**
- **ç»„ä»¶**ï¼š`GraphRWKV_Model` (ä½äº `paper/models/base_model.py`)
- **æ ¸å¿ƒ**ï¼š`RWKV_TimeMixing` - çº¿æ€§ Attention æœºåˆ¶ï¼ŒO(1) æ¨ç†å¤æ‚åº¦
- **ç»“æ„**ï¼š
  ```
  è¾“å…¥ (B, T, F) 
  â†’ Linear(input_dim â†’ n_embd)
  â†’ N å±‚ RWKV Block:
     - RWKV_TimeMixing (æ—¶é—´ç»´çº¿æ€§æ³¨æ„åŠ›)
     - Classical_ChannelMixing (ç»å…¸ FFN)
  â†’ è¾“å‡ºæœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾å‘é‡ (B, n_embd)
  ```

### 2. **ç©ºé—´ç»´ï¼šåŠ¨æ€å›¾æ³¨æ„åŠ›ç½‘ç»œï¼ˆGATï¼‰**
- **ç»„ä»¶**ï¼š`GraphRWKV_GNN_Model` (ä½äº `paper/models/gnn_model.py`)
- **è¾“å…¥å›¾**ï¼šLLM å¢å¼ºçš„æƒ…æ„ŸåŠ æƒæ··åˆå›¾
  - è¯­ä¹‰å›¾ï¼šLLM æå–çš„å…³ç³» + æƒ…æ„Ÿææ€§åˆ†æ•° (-1.0 åˆ° 1.0)
  - ç»Ÿè®¡å›¾ï¼š30 å¤©æ”¶ç›Šç‡ Pearson ç›¸å…³æ€§ï¼ˆ|Ï| > 0.6ï¼‰
  - æ··åˆå…¬å¼ï¼š`A_t^final = Norm(A_t^semantic + Î» Â· A_t^stat)`
- **ç»“æ„**ï¼š
  ```
  æ—¶åºç‰¹å¾ (B, n_embd)
  â†’ GAT ç©ºé—´èšåˆ (åŸºäºæ··åˆå›¾)
  â†’ æ—¶ç©ºç‰¹å¾èåˆ (Concat + Linear)
  â†’ æ”¶ç›Šç‡é¢„æµ‹
  ```

### 3. **æ•°æ®å¯¹é½æœºåˆ¶**
- **16:00 Cut-off**ï¼šT æ—¥ 16:00 ä¹‹å‰çš„æ–°é—» â†’ æ„å»º T æ—¥å›¾ â†’ é¢„æµ‹ T+1 æ—¥æ”¶ç›Š
- **ä¸¥æ ¼å‰ç»åå·®è§„é¿**ï¼šç¡®ä¿ä¸ä½¿ç”¨æœªæ¥ä¿¡æ¯

---

## ğŸ¯ æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼ˆæœ€é‡è¦ï¼ï¼‰

### **1. å‚»ç“œå¼è¿è¡Œ**
- **æ¯ä¸ªè„šæœ¬éƒ½æ˜¯ç‹¬ç«‹çš„ `.py` æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œ**
- **å‘½ä»¤è¡Œå‚æ•°ç®€æ´æ˜äº†ï¼Œä¸€çœ¼å°±çŸ¥é“æ˜¯å¹²ä»€ä¹ˆçš„**
- **ç¤ºä¾‹**ï¼š
  ```bash
  # æ•°æ®é¢„å¤„ç†
  python 1_preprocess_data.py --input_dir ./data/raw --output_dir ./data/processed
  
  # æ„å»ºå›¾è°±
  python 2_build_graph.py --news_file ./data/processed/Stock_News.csv --output ./data/processed/graph.npy
  
  # è®­ç»ƒæ¨¡å‹
  python 3_train.py --gpu 0  # é…ç½®åœ¨è„šæœ¬é¡¶éƒ¨ï¼Œå‘½ä»¤è¡Œå‚æ•°å¯é€‰
  
  # è¯„ä¼°æ¨¡å‹
  python 4_evaluate.py --checkpoint ./outputs/best_model.pth --test_data ./data/processed/test.csv
  ```

### **2. è„šæœ¬å‘½åè§„èŒƒ**
- **æ•°å­—å‰ç¼€**ï¼šè¡¨ç¤ºæ‰§è¡Œé¡ºåºï¼ˆ1_preprocess, 2_build_graph, 3_train, 4_evaluateï¼‰
- **åŠŸèƒ½æ˜ç¡®**ï¼šæ–‡ä»¶åç›´æ¥è¯´æ˜åŠŸèƒ½
- **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªè„šæœ¬åªåšä¸€ä»¶äº‹

### **3. æ—¥å¿—ç³»ç»Ÿï¼ˆé‡è¦ï¼ï¼‰**
- **æ¯æ¬¡è¿è¡Œè‡ªåŠ¨ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶**
- **æ—¥å¿—æ–‡ä»¶å‘½ååŒ…å«æ—¶é—´æˆ³ï¼Œæ–¹ä¾¿åŒºåˆ†ä¸åŒè¿è¡Œ**
- **æ—¥å¿—åŒ…å«ï¼šæ—¶é—´æˆ³ã€æ­¥éª¤ã€è¿›åº¦ã€é”™è¯¯ä¿¡æ¯ã€èµ„æºä½¿ç”¨ç­‰**
- **æ—¥å¿—æ ¼å¼æ¸…æ™°ï¼Œæ–¹ä¾¿æ£€æŸ¥å’Œè°ƒè¯•**
- **ç¤ºä¾‹**ï¼š
  ```python
  # æ—¥å¿—æ–‡ä»¶å‘½åï¼štrain_20260123_143025.logï¼ˆæ—¥æœŸ_æ—¶é—´ï¼‰
  # æ—¥å¿—å†…å®¹ï¼š
  # 2026-01-23 14:30:25 - INFO - å¼€å§‹è®­ç»ƒ Graph-RWKV æ¨¡å‹
  # 2026-01-23 14:30:26 - INFO - åŠ è½½æ•°æ®: ./data/processed/Final_Model_Data.csv
  # 2026-01-23 14:30:30 - INFO - æ•°æ®åŠ è½½å®Œæˆï¼Œè®­ç»ƒé›†: 10000 æ ·æœ¬ï¼Œæµ‹è¯•é›†: 2000 æ ·æœ¬
  # 2026-01-23 14:30:31 - INFO - åˆå§‹åŒ–æ¨¡å‹: n_embd=256, n_layers=3
  # 2026-01-23 14:30:35 - INFO - å¼€å§‹è®­ç»ƒï¼ŒEpoch 1/30
  # 2026-01-23 14:32:10 - INFO - Epoch 1 å®Œæˆï¼ŒTrain Loss: 0.0234, Val Loss: 0.0198
  # ...
  ```

### **3. é…ç½®ç®¡ç†**
- **é…ç½®ç›´æ¥å†™åœ¨ py æ–‡ä»¶é‡Œ**ï¼ˆä¸ä½¿ç”¨ config.yamlï¼‰
- **å‘½ä»¤è¡Œå‚æ•°åªè¦†ç›–å…³é”®å‚æ•°ï¼ˆå¦‚ GPU IDã€æ•°æ®è·¯å¾„ï¼‰**
- **é»˜è®¤é…ç½®é€‚åˆ 48GB GPU + 90GB RAM**

## ğŸ¯ ä»£ç ä¼˜åŒ–æ–¹å‘

### **ä¼˜å…ˆçº§ 0ï¼šè„šæœ¬ç®€åŒ–å’Œæ˜“ç”¨æ€§ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰**

1. **é‡æ„ä¸ºç‹¬ç«‹å¯è¿è¡Œè„šæœ¬**
   - å°†ç°æœ‰æ¨¡å—åŒ–ä»£ç æ•´åˆä¸ºå¯ç›´æ¥è¿è¡Œçš„è„šæœ¬
   - æ¯ä¸ªè„šæœ¬åŒ…å«å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œè¿›åº¦æ˜¾ç¤º
   - æ·»åŠ  `if __name__ == "__main__"` å…¥å£

2. **å‘½ä»¤è¡Œæ¥å£è®¾è®¡**
   ```python
   # âœ… å¥½çš„è®¾è®¡
   python 3_train.py \
       --data ./data/processed/Final_Model_Data.csv \
       --graph ./data/processed/Graph_Adjacency.npy \
       --output ./outputs \
       --batch_size 1024 \
       --epochs 30
   
   # âŒ é¿å…çš„è®¾è®¡
   python 3_train.py --batch_size 2048  # åªè¦†ç›–éœ€è¦ä¿®æ”¹çš„å‚æ•°
   ```

3. **è¿›åº¦æ˜¾ç¤ºå’Œæ—¥å¿—**
   - ä½¿ç”¨ `tqdm` æ˜¾ç¤ºè¿›åº¦æ¡
   - å…³é”®æ­¥éª¤æ‰“å°æ¸…æ™°çš„ä¸­æ–‡æç¤º
   - é”™è¯¯ä¿¡æ¯å‹å¥½ä¸”åŒ…å«è§£å†³å»ºè®®

### **ä¼˜å…ˆçº§ 1ï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆé’ˆå¯¹ 48GB GPU + 90GB RAMï¼‰**

1. **RWKV æ—¶é—´æ··åˆå±‚ä¼˜åŒ–ï¼ˆé’ˆå¯¹ 48GB GPUï¼‰**
   - å½“å‰ä½¿ç”¨ `torch.jit.script` ç¼–è¯‘ `rwkv_linear_attention_cpu`
   - **ä¼˜åŒ–æ–¹å‘**ï¼š
     - ä½¿ç”¨ `torch.compile` (PyTorch 2.1.2 æ”¯æŒ) åŠ é€Ÿæ•´ä¸ªæ¨¡å‹
     - ä¼˜åŒ– GPU å†…å­˜è®¿é—®æ¨¡å¼ï¼Œæ”¯æŒæ›´å¤§çš„ batch sizeï¼ˆ1024+ï¼‰
     - æ”¯æŒæ›´é•¿çš„åºåˆ—é•¿åº¦ï¼ˆseq_len=60+ï¼Œå……åˆ†åˆ©ç”¨ GPU å†…å­˜ï¼‰
     - ä½¿ç”¨ TF32 ç²¾åº¦ï¼ˆ`torch.set_float32_matmul_precision('high')`ï¼‰

2. **GAT å›¾æ³¨æ„åŠ›è®¡ç®—ä¼˜åŒ–ï¼ˆé’ˆå¯¹å¤§å›¾ï¼‰**
   - å½“å‰ä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›ï¼ˆä»…å¯¹æœ‰è¾¹çš„èŠ‚ç‚¹å¯¹è®¡ç®—ï¼‰
   - **ä¼˜åŒ–æ–¹å‘**ï¼š
     - ä½¿ç”¨ PyTorch Geometric (PyG) çš„ `GATv2Conv` æ›¿ä»£æ‰‹åŠ¨å®ç°
     - æ”¯æŒè¾¹æƒé‡ï¼ˆæƒ…æ„Ÿåˆ†æ•°ï¼‰ä½œä¸ºæ³¨æ„åŠ›æƒé‡
     - æ‰¹é‡å›¾å¤„ç†ä¼˜åŒ–ï¼ˆå……åˆ†åˆ©ç”¨ 48GB GPUï¼‰
     - ä½¿ç”¨ `torch.sparse` ä¼˜åŒ–ç¨€ç–çŸ©é˜µä¹˜æ³•

3. **æ•°æ®åŠ è½½ä¼˜åŒ–ï¼ˆé’ˆå¯¹ 90GB RAM + 12 vCPUï¼‰**
   - **ä¼˜åŒ–æ–¹å‘**ï¼š
     - `num_workers=8-10`ï¼ˆå……åˆ†åˆ©ç”¨ 12 vCPUï¼‰
     - `pin_memory=True`, `prefetch_factor=4`ï¼ˆå‡å°‘ GPU ç­‰å¾…ï¼‰
     - ä½¿ç”¨å†…å­˜æ˜ å°„æ–‡ä»¶ï¼ˆ`np.memmap`ï¼‰å¤„ç†å¤§ CSV
     - æ•°æ®é¢„å¤„ç†ç»“æœç¼“å­˜åˆ° RAMï¼ˆ90GB è¶³å¤Ÿå¤§ï¼‰
     - ä½¿ç”¨ `torchdata` ä¼˜åŒ–æ•°æ®ç®¡é“

### **ä¼˜å…ˆçº§ 2ï¼šä»£ç è´¨é‡ä¼˜åŒ–**

1. **ç±»å‹æ³¨è§£å®Œå–„**
   - æ‰€æœ‰å‡½æ•°æ·»åŠ å®Œæ•´çš„ç±»å‹æ³¨è§£ï¼ˆ`typing` æ¨¡å—ï¼‰
   - ä½¿ç”¨ `torch.jit.script` å…¼å®¹çš„ç±»å‹æ³¨è§£
   - æ·»åŠ  `__annotations__` æ£€æŸ¥

2. **é”™è¯¯å¤„ç†å¢å¼º**
   - æ·»åŠ è¾“å…¥éªŒè¯ï¼ˆshapeã€dtypeã€device æ£€æŸ¥ï¼‰
   - æ·»åŠ å‹å¥½çš„é”™è¯¯æ¶ˆæ¯ï¼ˆåŒ…å«ä¿®å¤å»ºè®®ï¼‰
   - æ·»åŠ æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥ï¼ˆNaN/Inf æ£€æµ‹ï¼‰

3. **æ–‡æ¡£å­—ç¬¦ä¸²æ ‡å‡†åŒ–**
   - ä½¿ç”¨ Google/NumPy é£æ ¼æ–‡æ¡£å­—ç¬¦ä¸²
   - æ·»åŠ å‚æ•°è¯´æ˜ã€è¿”å›å€¼è¯´æ˜ã€ç¤ºä¾‹ä»£ç 
   - æ·»åŠ æ•°å­¦å…¬å¼çš„ LaTeX æ³¨é‡Š

### **ä¼˜å…ˆçº§ 3ï¼šæ¶æ„ä¼˜åŒ–**

1. **æ¨¡å—åŒ–æ”¹è¿›**
   - å°† RWKV Block æå–ä¸ºç‹¬ç«‹æ¨¡å—
   - å°†å›¾æ„å»ºé€»è¾‘è¿›ä¸€æ­¥æ¨¡å—åŒ–
   - æ·»åŠ é…ç½®ç®¡ç†æ¨¡å—ï¼ˆä½¿ç”¨ `hydra` æˆ– `omegaconf`ï¼‰

2. **å¯æ‰©å±•æ€§**
   - æ”¯æŒå¤š GPU è®­ç»ƒï¼ˆ`torch.nn.DataParallel` æˆ– `DistributedDataParallel`ï¼‰
   - æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼Œå·²éƒ¨åˆ†å®ç°ï¼‰
   - æ”¯æŒæ¨¡å‹æ£€æŸ¥ç‚¹æ¢å¤å’Œæ–­ç‚¹ç»­è®­

3. **å®éªŒç®¡ç†**
   - é›†æˆ `wandb` æˆ– `tensorboard` è¿›è¡Œå®éªŒè·Ÿè¸ª
   - æ·»åŠ è¶…å‚æ•°æœç´¢æ”¯æŒï¼ˆ`optuna` æˆ– `ray.tune`ï¼‰
   - æ·»åŠ æ¨¡å‹ç‰ˆæœ¬ç®¡ç†

---

## ğŸ“ ä»£ç è§„èŒƒè¦æ±‚

### **1. Python ä»£ç é£æ ¼**
- éµå¾ª **PEP 8** è§„èŒƒ
- ä½¿ç”¨ **Black** æ ¼å¼åŒ–ï¼ˆè¡Œé•¿åº¦ 100ï¼‰
- ä½¿ç”¨ **isort** æ’åºå¯¼å…¥
- ä½¿ç”¨ **mypy** è¿›è¡Œç±»å‹æ£€æŸ¥

### **2. å‘½åè§„èŒƒ**
- **ç±»å**ï¼š`PascalCase`ï¼ˆå¦‚ `GraphRWKV_Model`ï¼‰
- **å‡½æ•°/å˜é‡å**ï¼š`snake_case`ï¼ˆå¦‚ `build_dynamic_graph`ï¼‰
- **å¸¸é‡**ï¼š`UPPER_SNAKE_CASE`ï¼ˆå¦‚ `CUTOFF_HOUR`ï¼‰
- **ç§æœ‰æˆå‘˜**ï¼šå‰ç¼€ `_`ï¼ˆå¦‚ `_normalize_llm_relations`ï¼‰

### **3. æ³¨é‡Šè§„èŒƒ**
- **ä¸­æ–‡æ³¨é‡Š**ï¼šæ‰€æœ‰æ³¨é‡Šä½¿ç”¨ä¸­æ–‡ï¼ˆé¡¹ç›®è¦æ±‚ï¼‰
- **æ¨¡å—çº§æ³¨é‡Š**ï¼šæ¯ä¸ªæ–‡ä»¶å¼€å¤´æœ‰æ¨¡å—è¯´æ˜
- **å‡½æ•°æ³¨é‡Š**ï¼šåŒ…å«åŠŸèƒ½è¯´æ˜ã€å‚æ•°è¯´æ˜ã€è¿”å›å€¼è¯´æ˜
- **å…³é”®é€»è¾‘**ï¼šå¤æ‚ç®—æ³•æ·»åŠ è¡Œå†…æ³¨é‡Š

### **4. é”™è¯¯å¤„ç†**
```python
# âœ… å¥½çš„åšæ³•
try:
    result = risky_operation()
except SpecificError as e:
    logger.error(f"æ“ä½œå¤±è´¥: {e}")
    raise ValueError(f"å‹å¥½çš„é”™è¯¯æ¶ˆæ¯: {e}") from e

# âŒ é¿å…çš„åšæ³•
try:
    result = risky_operation()
except:
    pass  # é™é»˜å¤±è´¥
```

### **5. ç±»å‹æ³¨è§£ç¤ºä¾‹**
```python
from typing import Optional, Tuple, Dict, List
import torch

def forward(
    self,
    x: torch.Tensor,  # (B, T, F)
    vol: Optional[torch.Tensor] = None,  # (B, 1)
    node_indices: Optional[torch.Tensor] = None,  # (B,)
) -> torch.Tensor:  # (B, 1)
    """å‰å‘ä¼ æ’­ã€‚
    
    Args:
        x: è¾“å…¥åºåˆ—ï¼Œå½¢çŠ¶ (B, T, F)
        vol: æ³¢åŠ¨ç‡ï¼ˆä¿ç•™ä»¥å…¼å®¹æ¥å£ï¼Œæ–°æ–¹å‘ä¸­ä¸ä½¿ç”¨ï¼‰
        node_indices: èŠ‚ç‚¹ç´¢å¼•ï¼Œç”¨äº GAT èšåˆ
    
    Returns:
        æ”¶ç›Šç‡é¢„æµ‹ï¼Œå½¢çŠ¶ (B, 1)
    """
    pass
```

---

## ğŸ”§ å…·ä½“ä¼˜åŒ–ä»»åŠ¡æ¸…å•

### **ä»»åŠ¡ 0ï¼šè„šæœ¬é‡æ„ä¸ºç‹¬ç«‹å¯è¿è¡Œæ–‡ä»¶ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰**

**ç›®æ ‡**ï¼šå°†ç°æœ‰ä»£ç é‡æ„ä¸º 5 ä¸ªç‹¬ç«‹å¯è¿è¡Œçš„è„šæœ¬

1. **`1_preprocess_data.py`** - æ•°æ®é¢„å¤„ç†
   ```python
   """
   åŠŸèƒ½ï¼šæ•°æ®æ¸…æ´—ã€å¯¹é½ã€ç‰¹å¾å·¥ç¨‹
   è¾“å…¥ï¼šåŸå§‹æ•°æ®ç›®å½•
   è¾“å‡ºï¼šFinal_Model_Data.csv
   å‘½ä»¤è¡Œï¼špython 1_preprocess_data.py --input_dir ./data/raw --output_dir ./data/processed
   """
   ```

2. **`2_build_graph.py`** - æ„å»ºå›¾è°±
   ```python
   """
   åŠŸèƒ½ï¼šLLM æå–å…³ç³»+æƒ…æ„Ÿï¼Œæ„å»ºæ··åˆå›¾
   è¾“å…¥ï¼šStock_News.csv, Stock_Prices.csv
   è¾“å‡ºï¼šGraph_Adjacency.npy, Graph_Adjacency_tickers.json
   å‘½ä»¤è¡Œï¼špython 2_build_graph.py --news ./data/processed/Stock_News.csv --prices ./data/processed/Stock_Prices.csv --output ./data/processed
   """
   ```

3. **`3_train.py`** - å…¨é‡æ¨¡å‹è®­ç»ƒ
   ```python
   """
   åŠŸèƒ½ï¼šè®­ç»ƒ Graph-RWKV å…¨é‡æ¨¡å‹ï¼ˆå®Œæ•´æ¶æ„ï¼šRWKV + GAT + æ··åˆå›¾ï¼‰
   è¾“å…¥ï¼šFinal_Model_Data.csv, Graph_Adjacency.npy
   è¾“å‡ºï¼šcheckpoints/best_model.pth, training_logs.json
   å‘½ä»¤è¡Œï¼špython 3_train.py --data ./data/processed/Final_Model_Data.csv --graph ./data/processed/Graph_Adjacency.npy --output ./outputs --batch_size 1024 --epochs 30
   """
   ```

4. **`3_train_ablation.py`** - æ¶ˆèå®éªŒè®­ç»ƒ
   ```python
   """
   åŠŸèƒ½ï¼šè¿è¡Œæ¶ˆèå®éªŒï¼ŒéªŒè¯å„ç»„ä»¶çš„æœ‰æ•ˆæ€§
   æ”¯æŒçš„æ¶ˆèå®éªŒï¼š
     - w/o_graph: å»æ‰ GAT å›¾èšåˆï¼ˆåªç”¨ RWKVï¼‰
     - w/o_semantic: åªç”¨ç»Ÿè®¡å›¾ï¼Œä¸ç”¨è¯­ä¹‰å›¾
     - w/o_statistical: åªç”¨è¯­ä¹‰å›¾ï¼Œä¸ç”¨ç»Ÿè®¡å›¾
     - w/o_sentiment: è¯­ä¹‰å›¾ä¸ç”¨æƒ…æ„Ÿåˆ†æ•°ï¼ˆåªç”¨å…³ç³»ï¼‰
   
   è¾“å…¥ï¼šFinal_Model_Data.csv, Graph_Adjacency.npy
   è¾“å‡ºï¼šcheckpoints/best_model_ablation_*.pth, ablation_results.json
   å‘½ä»¤è¡Œï¼špython 3_train_ablation.py --data ./data/processed/Final_Model_Data.csv --graph ./data/processed/Graph_Adjacency.npy --output ./outputs --ablation w/o_graph --batch_size 1024
   
   æ‰¹é‡è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒï¼š
   python 3_train_ablation.py --data ./data/processed/Final_Model_Data.csv --graph ./data/processed/Graph_Adjacency.npy --output ./outputs --ablation all
   """
   ```

5. **`4_evaluate.py`** - è¯„ä¼°æ¨¡å‹
   ```python
   """
   åŠŸèƒ½ï¼šè®­ç»ƒ Graph-RWKV æ¨¡å‹
   è¾“å…¥ï¼šFinal_Model_Data.csv, Graph_Adjacency.npy
   è¾“å‡ºï¼šcheckpoints/best_model.pth, training_logs.json
   å‘½ä»¤è¡Œï¼špython 3_train.py --data ./data/processed/Final_Model_Data.csv --graph ./data/processed/Graph_Adjacency.npy --output ./outputs --batch_size 1024 --epochs 30
   """
   ```

4. **`4_evaluate.py`** - è¯„ä¼°æ¨¡å‹
   ```python
   """
   åŠŸèƒ½ï¼šè¯„ä¼°æ¨¡å‹æ€§èƒ½ï¼ˆIC, RankIC, Sharpe Ratioï¼‰
   è¾“å…¥ï¼šcheckpoint, test_data
   è¾“å‡ºï¼ševaluation_results.csv, plots/
   å‘½ä»¤è¡Œï¼špython 4_evaluate.py --checkpoint ./outputs/best_model.pth --test_data ./data/processed/test.csv --output ./outputs/results
   """
   ```

**è¦æ±‚**ï¼š
- **å¯ä»¥ç›´æ¥ç‚¹å‡»è¿è¡Œ**ï¼šä½¿ç”¨é»˜è®¤é…ç½®ï¼Œæ— éœ€å‘½ä»¤è¡Œå‚æ•°
- **å‘½ä»¤è¡Œå‚æ•°å¯é€‰**ï¼šç”¨äºè¦†ç›–é»˜è®¤é…ç½®ï¼ˆargparse with defaultsï¼‰
- **å®Œå–„çš„æ—¥å¿—ç³»ç»Ÿ**ï¼šæ¯æ¬¡è¿è¡Œè‡ªåŠ¨ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶
- **æ—¥å¿—æ–‡ä»¶å‘½å**ï¼šåŒ…å«æ—¶é—´æˆ³ï¼Œå¦‚ `train_20260123_143025.log`
- **æ—¥å¿—å†…å®¹**ï¼šæ—¶é—´æˆ³ã€æ­¥éª¤ã€è¿›åº¦ã€é”™è¯¯ã€èµ„æºä½¿ç”¨ç­‰
- **è¿›åº¦æ˜¾ç¤º**ï¼šä½¿ç”¨ `tqdm` æ˜¾ç¤ºè¿›åº¦æ¡
- **é”™è¯¯å¤„ç†**ï¼šå‹å¥½çš„é”™è¯¯æç¤ºå’Œå¼‚å¸¸æ•è·
- **å…³é”®æ­¥éª¤**ï¼šæ‰“å°æ¸…æ™°çš„ä¸­æ–‡è¯´æ˜ï¼ˆåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ—¥å¿—æ–‡ä»¶ï¼‰

### **ä»»åŠ¡ 1ï¼šRWKV æ—¶é—´æ··åˆå±‚æ€§èƒ½ä¼˜åŒ–ï¼ˆé’ˆå¯¹ 48GB GPUï¼‰**
```python
# æ–‡ä»¶ï¼špaper/models/base_model.py
# ç±»ï¼šRWKV_TimeMixing
# ä¼˜åŒ–ç‚¹ï¼ˆé’ˆå¯¹ 48GB GPUï¼‰ï¼š
# 1. ä½¿ç”¨ torch.compile åŠ é€Ÿï¼ˆPyTorch 2.1.2 æ”¯æŒï¼‰
# 2. å¯ç”¨ TF32 ç²¾åº¦ï¼ˆtorch.set_float32_matmul_precision('high')ï¼‰
# 3. ä¼˜åŒ– GPU å†…å­˜è®¿é—®ï¼Œæ”¯æŒ batch_size=1024+
# 4. æ”¯æŒæ›´é•¿åºåˆ—ï¼ˆseq_len=60+ï¼‰
# 5. å‚è€ƒ RWKV-LM å®˜æ–¹å®ç°çš„ä¼˜åŒ–æŠ€å·§
```

### **ä»»åŠ¡ 2ï¼šGAT å±‚ä½¿ç”¨ PyG é‡æ„ï¼ˆå‚è€ƒ ADGATï¼‰**
```python
# æ–‡ä»¶ï¼špaper/models/gnn_model.py
# ç±»ï¼šGraphAttentionLayer
# ä¼˜åŒ–ç‚¹ï¼ˆå‚è€ƒ ADGAT å®ç°ï¼‰ï¼š
# 1. ä½¿ç”¨ torch_geometric.nn.GATv2Conv æ›¿ä»£æ‰‹åŠ¨å®ç°
# 2. æ”¯æŒè¾¹æƒé‡ï¼ˆæƒ…æ„Ÿåˆ†æ•°ä½œä¸ºè¾¹æƒé‡ï¼‰
# 3. ä¼˜åŒ– batch å¤„ç†ï¼ˆå……åˆ†åˆ©ç”¨ 48GB GPUï¼‰
# 4. å‚è€ƒ ADGAT çš„é‡‘èå›¾å¤„ç†æŠ€å·§
# 5. ä½¿ç”¨ torch.sparse ä¼˜åŒ–ç¨€ç–çŸ©é˜µæ“ä½œ
```

### **ä»»åŠ¡ 3ï¼šå…¨é‡æ¨¡å‹è®­ç»ƒè„šæœ¬ï¼ˆé‡æ„ä¸º 3_train.pyï¼‰**
```python
# æ–‡ä»¶ï¼š3_train.pyï¼ˆé‡æ„è‡ª paper/training/train_full.pyï¼‰
# åŠŸèƒ½ï¼šè®­ç»ƒ Graph-RWKV å…¨é‡æ¨¡å‹ï¼ˆå®Œæ•´æ¶æ„ï¼‰
# ä¼˜åŒ–ç‚¹ï¼ˆé’ˆå¯¹ 48GB GPU + 90GB RAMï¼‰ï¼š
# 1. é»˜è®¤ batch_size=1024ï¼ˆå……åˆ†åˆ©ç”¨ GPUï¼‰
# 2. num_workers=8-10ï¼ˆå……åˆ†åˆ©ç”¨ 12 vCPUï¼‰
# 3. æ··åˆç²¾åº¦è®­ç»ƒï¼ˆAMPï¼‰å®Œæ•´æ”¯æŒ
# 4. torch.compile æ¨¡å‹åŠ é€Ÿ
# 5. å¯ç”¨ TF32 ç²¾åº¦
# 6. æ·»åŠ  wandb/tensorboard é›†æˆï¼ˆå¯é€‰ï¼‰
# 7. æ¨¡å‹æ£€æŸ¥ç‚¹è‡ªåŠ¨ä¿å­˜å’Œæ¢å¤
# 8. ç®€æ´çš„å‘½ä»¤è¡Œæ¥å£
# 9. åªè®­ç»ƒå…¨é‡æ¨¡å‹ï¼Œä¸åŒ…å«æ¶ˆèå®éªŒé€»è¾‘
```

### **ä»»åŠ¡ 3.5ï¼šæ¶ˆèå®éªŒè®­ç»ƒè„šæœ¬ï¼ˆæ–°å»º 3_train_ablation.pyï¼‰**
```python
# æ–‡ä»¶ï¼š3_train_ablation.pyï¼ˆæ–°å»ºï¼Œå‚è€ƒ paper/training/train_ablation.pyï¼‰
# åŠŸèƒ½ï¼šè¿è¡Œæ¶ˆèå®éªŒï¼ŒéªŒè¯å„ç»„ä»¶çš„æœ‰æ•ˆæ€§
# è®¾è®¡è¦ç‚¹ï¼š
# 1. æ”¯æŒå¤šç§æ¶ˆèå®éªŒç±»å‹ï¼ˆ--ablation å‚æ•°ï¼‰
# 2. å¯ä»¥å•ç‹¬è¿è¡ŒæŸä¸ªæ¶ˆèå®éªŒï¼Œä¹Ÿå¯ä»¥æ‰¹é‡è¿è¡Œæ‰€æœ‰
# 3. æ¯ä¸ªæ¶ˆèå®éªŒä¿å­˜ç‹¬ç«‹çš„ checkpoint å’Œæ—¥å¿—
# 4. è¾“å‡ºæ¶ˆèå®éªŒç»“æœå¯¹æ¯”è¡¨
# 5. å‘½ä»¤è¡Œæ¥å£ç®€æ´æ˜äº†
# 6. å¤ç”¨ 3_train.py çš„è®­ç»ƒé€»è¾‘ï¼ˆé¿å…ä»£ç é‡å¤ï¼‰
```

### **ä»»åŠ¡ 4ï¼šæ•°æ®åŠ è½½ä¼˜åŒ–ï¼ˆé’ˆå¯¹ 90GB RAMï¼‰**
```python
# æ–‡ä»¶ï¼špaper/dataProcessed/dataset.py
# ç±»ï¼šFinancialDataset
# ä¼˜åŒ–ç‚¹ï¼ˆå……åˆ†åˆ©ç”¨ 90GB RAMï¼‰ï¼š
# 1. æ•°æ®é¢„åŠ è½½åˆ° RAMï¼ˆ90GB è¶³å¤Ÿå¤§ï¼‰
# 2. ä½¿ç”¨å†…å­˜æ˜ å°„æ–‡ä»¶ï¼ˆnp.memmapï¼‰å¤„ç†å¤§ CSV
# 3. num_workers=8-10ï¼ˆå……åˆ†åˆ©ç”¨ 12 vCPUï¼‰
# 4. pin_memory=True, prefetch_factor=4
# 5. æ•°æ®é¢„å¤„ç†ç»“æœç¼“å­˜åˆ° RAM
# 6. ä½¿ç”¨ torchdata ä¼˜åŒ–æ•°æ®ç®¡é“
```

### **ä»»åŠ¡ 5ï¼šå›¾æ„å»ºä¼˜åŒ–ï¼ˆé‡æ„ä¸º 2_build_graph.pyï¼‰**
```python
# æ–‡ä»¶ï¼š2_build_graph.pyï¼ˆé‡æ„è‡ª paper/dataProcessed/build_graph.pyï¼‰
# ä¼˜åŒ–ç‚¹ï¼š
# 1. LLM æ‰¹å¤„ç†ä¼˜åŒ–ï¼ˆå‡å°‘ API è°ƒç”¨ï¼Œå‚è€ƒ FinGPTï¼‰
# 2. ç»Ÿè®¡ç›¸å…³æ€§è®¡ç®—ä½¿ç”¨ GPU åŠ é€Ÿï¼ˆ48GB GPUï¼‰
# 3. å›¾æ„å»ºç»“æœç¼“å­˜åˆ°ç£ç›˜ï¼ˆé¿å…é‡å¤æ„å»ºï¼‰
# 4. å¤šè¿›ç¨‹å¤„ç†ï¼ˆå……åˆ†åˆ©ç”¨ 12 vCPUï¼‰
# 5. ç®€æ´çš„å‘½ä»¤è¡Œæ¥å£
# 6. è¿›åº¦æ˜¾ç¤ºï¼ˆtqdmï¼‰
```

---

## ğŸš€ ä¼˜åŒ–ç¤ºä¾‹ä»£ç æ¨¡æ¿

### **ç¤ºä¾‹ 0ï¼šå…¨é‡æ¨¡å‹è®­ç»ƒè„šæœ¬æ¨¡æ¿ï¼ˆ3_train.pyï¼‰- å¯ç›´æ¥ç‚¹å‡»è¿è¡Œ**
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
3_train.py - Graph-RWKV å…¨é‡æ¨¡å‹è®­ç»ƒè„šæœ¬

åŠŸèƒ½ï¼šè®­ç»ƒ Graph-RWKV å…¨é‡æ¨¡å‹ï¼ˆå®Œæ•´æ¶æ„ï¼šRWKV + GAT + æ··åˆå›¾ï¼‰
ç”¨æ³•ï¼š
  æ–¹å¼1ï¼ˆæ¨èï¼‰ï¼šç›´æ¥ç‚¹å‡»è¿è¡Œï¼Œä½¿ç”¨é»˜è®¤é…ç½®
  æ–¹å¼2ï¼šå‘½ä»¤è¡Œè¿è¡Œï¼Œè¦†ç›–éƒ¨åˆ†å‚æ•°
    python 3_train.py --batch_size 2048 --epochs 50
"""

import argparse
import os
import sys
import logging
from datetime import datetime
from pathlib import Path
import torch
from tqdm import tqdm
import yaml
from models.gnn_model import GraphRWKV_GNN_Model

def setup_logging(output_dir: str) -> logging.Logger:
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶ã€‚"""
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = Path(output_dir) / 'logs'
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # æ—¥å¿—æ–‡ä»¶ååŒ…å«æ—¶é—´æˆ³
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = log_dir / f'train_{timestamp}.log'
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = '%(asctime)s - %(levelname)s - %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        datefmt=date_format,
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),  # æ–‡ä»¶è¾“å‡º
            logging.StreamHandler(sys.stdout)  # æ§åˆ¶å°è¾“å‡º
        ]
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"æ—¥å¿—æ–‡ä»¶å·²åˆ›å»º: {log_file}")
    return logger

# ==================== é…ç½®å‚æ•°ï¼ˆç›´æ¥å†™åœ¨æ–‡ä»¶é‡Œï¼Œæ–¹ä¾¿ä¿®æ”¹ï¼‰====================
# æ•°æ®é…ç½®
DATA_CSV_PATH = './data/processed/Final_Model_Data.csv'
GRAPH_PATH = './data/processed/Graph_Adjacency.npy'

# æ¨¡å‹é…ç½®
MODEL_N_EMBD = 256      # åµŒå…¥ç»´åº¦ï¼ˆé€‚åˆ 48GB GPUï¼‰
MODEL_N_LAYERS = 3      # RWKV å±‚æ•°
MODEL_GNN_EMBD = 64     # GAT åµŒå…¥ç»´åº¦
MODEL_DROPOUT = 0.1     # Dropout ç‡

# è®­ç»ƒé…ç½®
TRAIN_BATCH_SIZE = 1024      # æ‰¹å¤§å°ï¼ˆé€‚åˆ 48GB GPUï¼‰
TRAIN_EPOCHS = 30            # è®­ç»ƒè½®æ•°
TRAIN_LR = 3e-4              # å­¦ä¹ ç‡
TRAIN_NUM_WORKERS = 10       # æ•°æ®åŠ è½½è¿›ç¨‹æ•°ï¼ˆé€‚åˆ 12 vCPUï¼‰
TRAIN_PIN_MEMORY = True      # å›ºå®šå†…å­˜
TRAIN_PREFETCH_FACTOR = 4    # é¢„å–å› å­

# è¾“å‡ºé…ç½®
OUTPUT_DIR = './outputs'
CHECKPOINT_DIR = './outputs/checkpoints'
LOG_DIR = './outputs/logs'

# GPU é…ç½®
GPU_ID = 0                   # GPU ID
# ============================================================================

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°ï¼ˆå¯é€‰ï¼Œç”¨äºè¦†ç›–è„šæœ¬ä¸­çš„é…ç½®ï¼‰
    parser = argparse.ArgumentParser(description='è®­ç»ƒ Graph-RWKV å…¨é‡æ¨¡å‹')
    parser.add_argument('--data', type=str, default=DATA_CSV_PATH, 
                       help=f'è®­ç»ƒæ•°æ® CSV è·¯å¾„ï¼ˆé»˜è®¤: {DATA_CSV_PATH}ï¼‰')
    parser.add_argument('--graph', type=str, default=GRAPH_PATH,
                       help=f'å›¾è°±é‚»æ¥çŸ©é˜µè·¯å¾„ï¼ˆé»˜è®¤: {GRAPH_PATH}ï¼‰')
    parser.add_argument('--output', type=str, default=OUTPUT_DIR,
                       help=f'è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: {OUTPUT_DIR}ï¼‰')
    parser.add_argument('--batch_size', type=int, default=TRAIN_BATCH_SIZE,
                       help=f'æ‰¹å¤§å°ï¼ˆé»˜è®¤: {TRAIN_BATCH_SIZE}ï¼Œé€‚åˆ48GB GPUï¼‰')
    parser.add_argument('--epochs', type=int, default=TRAIN_EPOCHS,
                       help=f'è®­ç»ƒè½®æ•°ï¼ˆé»˜è®¤: {TRAIN_EPOCHS}ï¼‰')
    parser.add_argument('--lr', type=float, default=TRAIN_LR,
                       help=f'å­¦ä¹ ç‡ï¼ˆé»˜è®¤: {TRAIN_LR}ï¼‰')
    parser.add_argument('--gpu', type=int, default=GPU_ID, 
                       help=f'GPU IDï¼ˆé»˜è®¤: {GPU_ID}ï¼‰')
    
    args = parser.parse_args()
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°æˆ–è„šæœ¬ä¸­çš„é»˜è®¤é…ç½®
    data_path = args.data
    graph_path = args.graph
    output_dir = args.output
    batch_size = args.batch_size
    epochs = args.epochs
    lr = args.lr
    gpu_id = args.gpu
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(args.output)
    logger.info("="*60)
    logger.info("å¼€å§‹è®­ç»ƒ Graph-RWKV å…¨é‡æ¨¡å‹")
    logger.info("="*60)
    logger.info(f"é…ç½®å‚æ•°:")
    logger.info(f"  - æ•°æ®è·¯å¾„: {args.data}")
    logger.info(f"  - å›¾è°±è·¯å¾„: {args.graph}")
    logger.info(f"  - è¾“å‡ºç›®å½•: {args.output}")
    logger.info(f"  - Batch Size: {args.batch_size}")
    logger.info(f"  - Epochs: {args.epochs}")
    logger.info(f"  - Learning Rate: {args.lr}")
    
    # è®¾ç½® GPU
    device = torch.device(f'cuda:{args.gpu}' if torch.cuda.is_available() else 'cpu')
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    if torch.cuda.is_available():
        logger.info(f"GPU: {torch.cuda.get_device_name(args.gpu)}")
        logger.info(f"GPU å†…å­˜: {torch.cuda.get_device_properties(args.gpu).total_memory / 1024**3:.1f} GB")
    
    # å¯ç”¨ TF32ï¼ˆé’ˆå¯¹ A100/H100ï¼‰
    torch.set_float32_matmul_precision('high')
    torch.backends.cudnn.benchmark = True
    logger.info("å·²å¯ç”¨ TF32 å’Œ cuDNN benchmark")
    
    try:
        # åŠ è½½æ•°æ®
        logger.info("åŠ è½½æ•°æ®...")
        # ... æ•°æ®åŠ è½½ä»£ç  ...
        logger.info(f"æ•°æ®åŠ è½½å®Œæˆï¼Œè®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬ï¼Œæµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
        
        # åˆå§‹åŒ–æ¨¡å‹ï¼ˆå…¨é‡æ¨¡å‹ï¼šRWKV + GAT + æ··åˆå›¾ï¼‰
        logger.info("åˆå§‹åŒ– Graph-RWKV å…¨é‡æ¨¡å‹...")
        logger.info(f"æ¨¡å‹é…ç½®: n_embd={MODEL_N_EMBD}, n_layers={MODEL_N_LAYERS}, gnn_embd={MODEL_GNN_EMBD}")
        model = GraphRWKV_GNN_Model(
            input_dim=8,
            n_embd=MODEL_N_EMBD,
            n_layers=MODEL_N_LAYERS,
            gnn_embd=MODEL_GNN_EMBD,
            dropout=MODEL_DROPOUT,
        ).to(device)
        
        # ä½¿ç”¨ torch.compile åŠ é€Ÿï¼ˆPyTorch 2.1.2ï¼‰
        logger.info("ä½¿ç”¨ torch.compile åŠ é€Ÿæ¨¡å‹...")
        model = torch.compile(model, mode='reduce-overhead')
        
        # è®­ç»ƒå¾ªç¯
        logger.info("å¼€å§‹è®­ç»ƒå…¨é‡æ¨¡å‹...")
        for epoch in tqdm(range(epochs), desc='è®­ç»ƒè¿›åº¦'):
            # ... è®­ç»ƒä»£ç  ...
            train_loss = 0.0  # ç¤ºä¾‹
            val_loss = 0.0    # ç¤ºä¾‹
            
            logger.info(f"Epoch {epoch+1}/{args.epochs} å®Œæˆï¼ŒTrain Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}")
        
        logger.info("="*60)
        logger.info("å…¨é‡æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        logger.info("="*60)
        
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­è®­ç»ƒï¼Œæ­£åœ¨ä¿å­˜æ£€æŸ¥ç‚¹...")
        # ä¿å­˜å½“å‰çŠ¶æ€
    except Exception as e:
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}", exc_info=True)
        raise

if __name__ == '__main__':
    main()
```

### **ç¤ºä¾‹ 0.5ï¼šæ¶ˆèå®éªŒè®­ç»ƒè„šæœ¬æ¨¡æ¿ï¼ˆ3_train_ablation.pyï¼‰**
```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
3_train_ablation.py - Graph-RWKV æ¶ˆèå®éªŒè®­ç»ƒè„šæœ¬

åŠŸèƒ½ï¼šè¿è¡Œæ¶ˆèå®éªŒï¼ŒéªŒè¯å„ç»„ä»¶çš„æœ‰æ•ˆæ€§
ç”¨æ³•ï¼š
  å•ä¸ªæ¶ˆèå®éªŒï¼špython 3_train_ablation.py --data ./data/processed/Final_Model_Data.csv --graph ./data/processed/Graph_Adjacency.npy --ablation w/o_graph
  æ‰€æœ‰æ¶ˆèå®éªŒï¼špython 3_train_ablation.py --data ./data/processed/Final_Model_Data.csv --graph ./data/processed/Graph_Adjacency.npy --ablation all
"""

import argparse
import torch
from tqdm import tqdm
from models.gnn_model import GraphRWKV_GNN_Model

# æ”¯æŒçš„æ¶ˆèå®éªŒç±»å‹
ABLATION_TYPES = {
    'w/o_graph': {'use_graph': False, 'use_semantic': True, 'use_statistical': True},
    'w/o_semantic': {'use_graph': True, 'use_semantic': False, 'use_statistical': True},
    'w/o_statistical': {'use_graph': True, 'use_semantic': True, 'use_statistical': False},
    'w/o_sentiment': {'use_graph': True, 'use_semantic': True, 'use_statistical': True, 'use_sentiment': False},
}

def train_ablation(ablation_type: str, args):
    """è®­ç»ƒå•ä¸ªæ¶ˆèå®éªŒã€‚"""
    config = ABLATION_TYPES[ablation_type]
    print(f"\nå¼€å§‹è®­ç»ƒæ¶ˆèå®éªŒ: {ablation_type}")
    print(f"é…ç½®: {config}")
    
    # åŠ è½½æ•°æ®
    # ... æ•°æ®åŠ è½½ä»£ç  ...
    
    # åˆå§‹åŒ–æ¨¡å‹ï¼ˆæ ¹æ®æ¶ˆèé…ç½®ï¼‰
    if not config['use_graph']:
        # åªç”¨ RWKVï¼Œä¸ç”¨ GAT
        from models.base_model import GraphRWKV_Model
        model = GraphRWKV_Model(...).to(device)
    else:
        # ä½¿ç”¨ GATï¼Œä½†æ ¹æ®é…ç½®è°ƒæ•´å›¾ç»“æ„
        model = GraphRWKV_GNN_Model(
            ...,
            use_semantic_graph=config.get('use_semantic', True),
            use_statistical_graph=config.get('use_statistical', True),
            use_sentiment=config.get('use_sentiment', True),
        ).to(device)
    
    # è®­ç»ƒå¾ªç¯ï¼ˆå¤ç”¨ 3_train.py çš„è®­ç»ƒé€»è¾‘ï¼‰
    # ... è®­ç»ƒä»£ç  ...
    
    # ä¿å­˜ç»“æœ
    output_path = f"{args.output}/checkpoints/best_model_ablation_{ablation_type}.pth"
    torch.save(model.state_dict(), output_path)
    print(f"æ¶ˆèå®éªŒ {ablation_type} å®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜åˆ°: {output_path}")

def main():
    parser = argparse.ArgumentParser(description='è¿è¡Œ Graph-RWKV æ¶ˆèå®éªŒ')
    parser.add_argument('--data', type=str, required=True, help='è®­ç»ƒæ•°æ® CSV è·¯å¾„')
    parser.add_argument('--graph', type=str, required=True, help='å›¾è°±é‚»æ¥çŸ©é˜µè·¯å¾„')
    parser.add_argument('--output', type=str, default='./outputs', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--ablation', type=str, required=True, 
                       choices=list(ABLATION_TYPES.keys()) + ['all'],
                       help='æ¶ˆèå®éªŒç±»å‹ï¼šw/o_graph, w/o_semantic, w/o_statistical, w/o_sentiment, æˆ– allï¼ˆè¿è¡Œæ‰€æœ‰ï¼‰')
    parser.add_argument('--batch_size', type=int, default=1024, help='æ‰¹å¤§å°')
    parser.add_argument('--epochs', type=int, default=30, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--gpu', type=int, default=0, help='GPU ID')
    
    args = parser.parse_args()
    
    # è®¾ç½® GPU
    device = torch.device(f'cuda:{args.gpu}' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # å¯ç”¨ TF32
    torch.set_float32_matmul_precision('high')
    
    # è¿è¡Œæ¶ˆèå®éªŒ
    if args.ablation == 'all':
        print("è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ...")
        for ablation_type in ABLATION_TYPES.keys():
            train_ablation(ablation_type, args)
        print("\næ‰€æœ‰æ¶ˆèå®éªŒå®Œæˆï¼")
    else:
        train_ablation(args.ablation, args)

if __name__ == '__main__':
    main()
```

### **ç¤ºä¾‹ 1ï¼šä¼˜åŒ–çš„ RWKV TimeMixingï¼ˆé’ˆå¯¹ 48GB GPUï¼‰**
```python
@torch.jit.script
def rwkv_linear_attention_optimized(
    time_decay: torch.Tensor,
    time_first: torch.Tensor,
    k: torch.Tensor,
    v: torch.Tensor,
) -> torch.Tensor:
    """ä¼˜åŒ–çš„ RWKV çº¿æ€§æ³¨æ„åŠ›è®¡ç®—ï¼ˆé’ˆå¯¹ 48GB GPUï¼‰ã€‚
    
    å‚è€ƒ RWKV-LM å®˜æ–¹å®ç°ä¼˜åŒ–ã€‚
    ä½¿ç”¨åŸåœ°æ“ä½œå’Œé¢„åˆ†é…å†…å­˜å‡å°‘åˆ†é…å¼€é”€ã€‚
    æ”¯æŒå¤§ batch size (1024+) å’Œé•¿åºåˆ— (60+)ã€‚
    """
    B, T, C = k.shape
    device = k.device
    
    # é¢„åˆ†é…è¾“å‡ºå¼ é‡ï¼ˆGPU å†…å­˜å……è¶³ï¼‰
    wkv = torch.zeros(B, T, C, device=device, dtype=k.dtype)
    
    # åˆå§‹åŒ–çŠ¶æ€
    aa = torch.zeros(B, C, device=device, dtype=k.dtype)
    bb = torch.zeros(B, C, device=device, dtype=k.dtype)
    pp = torch.full((B, C), -1e9, device=device, dtype=k.dtype)
    
    # ä¼˜åŒ–çš„å¾ªç¯ï¼ˆGPU å‹å¥½ï¼‰
    for t in range(T):
        kt = k[:, t, :]
        vt = v[:, t, :]
        ww = time_decay + pp
        p = torch.maximum(pp, ww)
        e1 = torch.exp(pp - p)
        e2 = torch.exp(ww - p)
        
        # åŸåœ°æ“ä½œï¼ˆå‡å°‘å†…å­˜åˆ†é…ï¼‰
        aa.mul_(e1).add_(e2 * vt)
        bb.mul_(e1).add_(e2)
        pp.copy_(p)
        
        wkv[:, t, :] = aa / bb.clamp(min=1e-8)
    
    return wkv

# åœ¨æ¨¡å‹åˆå§‹åŒ–æ—¶å¯ç”¨ torch.compile
class GraphRWKV_Model(nn.Module):
    def __init__(self, ...):
        super().__init__()
        # ... åˆå§‹åŒ–ä»£ç  ...
    
    def forward(self, x, vol=None):
        # ... å‰å‘ä¼ æ’­ ...
        pass

# ä½¿ç”¨æ–¹å¼ï¼ˆåœ¨è®­ç»ƒè„šæœ¬ä¸­ï¼‰
model = GraphRWKV_Model(...).to(device)
model = torch.compile(model, mode='reduce-overhead')  # PyTorch 2.1.2
```

### **ç¤ºä¾‹ 2ï¼šä½¿ç”¨ PyG çš„ GATï¼ˆå‚è€ƒ ADGATï¼‰**
```python
from torch_geometric.nn import GATv2Conv

class OptimizedGraphAttentionLayer(nn.Module):
    """ä½¿ç”¨ PyG ä¼˜åŒ–çš„ GAT å±‚ï¼ˆå‚è€ƒ ADGAT å®ç°ï¼‰ã€‚
    
    æ”¯æŒè¾¹æƒé‡ï¼ˆæƒ…æ„Ÿåˆ†æ•°ï¼‰ï¼Œå……åˆ†åˆ©ç”¨ 48GB GPUã€‚
    """
    
    def __init__(
        self,
        in_features: int,
        out_features: int,
        num_heads: int = 2,
        dropout: float = 0.1,
    ):
        super().__init__()
        self.gat = GATv2Conv(
            in_channels=in_features,
            out_channels=out_features // num_heads,
            heads=num_heads,
            dropout=dropout,
            edge_dim=1,  # æ”¯æŒè¾¹æƒé‡ï¼ˆæƒ…æ„Ÿåˆ†æ•°ï¼‰
            concat=True,
            add_self_loops=True,  # æ·»åŠ è‡ªç¯
        )
        self.layer_norm = nn.LayerNorm(out_features)
    
    def forward(
        self,
        x: torch.Tensor,  # (N, in_features)
        edge_index: torch.Tensor,  # (2, E)
        edge_attr: Optional[torch.Tensor] = None,  # (E, 1) æƒ…æ„Ÿåˆ†æ•°
    ) -> torch.Tensor:
        """å‰å‘ä¼ æ’­ã€‚
        
        Args:
            x: èŠ‚ç‚¹ç‰¹å¾
            edge_index: è¾¹ç´¢å¼•
            edge_attr: è¾¹æƒé‡ï¼ˆæƒ…æ„Ÿåˆ†æ•°ï¼Œ-1.0 åˆ° 1.0ï¼‰
        
        Returns:
            èšåˆåçš„èŠ‚ç‚¹ç‰¹å¾
        """
        h = self.gat(x, edge_index, edge_attr=edge_attr)
        return self.layer_norm(h)
```

### **ç¤ºä¾‹ 3ï¼šæ•°æ®åŠ è½½ä¼˜åŒ–ï¼ˆé’ˆå¯¹ 90GB RAMï¼‰**
```python
from torch.utils.data import DataLoader
import numpy as np

class OptimizedFinancialDataset:
    """ä¼˜åŒ–çš„é‡‘èæ•°æ®é›†ï¼ˆå……åˆ†åˆ©ç”¨ 90GB RAMï¼‰ã€‚"""
    
    def __init__(self, csv_path: str, seq_len: int = 30):
        # ä½¿ç”¨å†…å­˜æ˜ å°„æ–‡ä»¶ï¼ˆé€‚åˆå¤§æ–‡ä»¶ï¼‰
        self.data = np.memmap(csv_path, mode='r', dtype=np.float32)
        
        # é¢„åŠ è½½åˆ° RAMï¼ˆ90GB è¶³å¤Ÿå¤§ï¼‰
        print("é¢„åŠ è½½æ•°æ®åˆ° RAM...")
        self.data = np.array(self.data)  # ä» memmap è½¬ä¸ºæ™®é€šæ•°ç»„
        
        # ... å…¶ä»–åˆå§‹åŒ– ...
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        # ... è¿”å›æ ·æœ¬ ...
        pass

# æ•°æ®åŠ è½½å™¨é…ç½®ï¼ˆå……åˆ†åˆ©ç”¨ 12 vCPUï¼‰
train_loader = DataLoader(
    dataset,
    batch_size=1024,  # å¤§ batch sizeï¼ˆ48GB GPUï¼‰
    shuffle=True,
    num_workers=10,  # å……åˆ†åˆ©ç”¨ 12 vCPU
    pin_memory=True,  # GPU åŠ é€Ÿ
    prefetch_factor=4,  # é¢„å–æ›´å¤šæ•°æ®
    persistent_workers=True,  # ä¿æŒ worker è¿›ç¨‹
)
```

### **ç¤ºä¾‹ 4ï¼šè®­ç»ƒè„šæœ¬ä¼˜åŒ–ï¼ˆé’ˆå¯¹ 48GB GPUï¼‰**
```python
import torch
from torch.cuda.amp import autocast, GradScaler

def train_optimized(model, train_loader, val_loader, config):
    """ä¼˜åŒ–çš„è®­ç»ƒå‡½æ•°ï¼ˆé’ˆå¯¹ 48GB GPU + 90GB RAMï¼‰ã€‚"""
    
    device = torch.device('cuda:0')
    
    # å¯ç”¨ TF32ï¼ˆA100/H100ï¼‰
    torch.set_float32_matmul_precision('high')
    torch.backends.cudnn.benchmark = True
    
    # ä½¿ç”¨ torch.compile åŠ é€Ÿï¼ˆPyTorch 2.1.2ï¼‰
    model = torch.compile(model, mode='reduce-overhead')
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler()
    
    # ä¼˜åŒ–å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config['lr'],
        weight_decay=1e-5,
    )
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(config['epochs']):
        model.train()
        for batch in train_loader:
            x = batch['x'].to(device, non_blocking=True)
            y = batch['y'].to(device, non_blocking=True)
            node_indices = batch['node_indices'].to(device, non_blocking=True)
            
            optimizer.zero_grad()
            
            # æ··åˆç²¾åº¦å‰å‘ä¼ æ’­
            with autocast():
                pred = model(x, node_indices=node_indices)
                loss = criterion(pred, y)
            
            # æ··åˆç²¾åº¦åå‘ä¼ æ’­
            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            scaler.step(optimizer)
            scaler.update()
        
        # éªŒè¯
        val_loss = validate(model, val_loader)
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if val_loss < best_val_loss:
            torch.save(model.state_dict(), 'best_model.pth')
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•è¦æ±‚ï¼ˆé’ˆå¯¹ 48GB GPU + 90GB RAMï¼‰

ä¼˜åŒ–åéœ€è¦æä¾›ä»¥ä¸‹æ€§èƒ½æŒ‡æ ‡ï¼š

1. **è®­ç»ƒé€Ÿåº¦**ï¼ˆç›®æ ‡ï¼‰ï¼š
   - æ¯ä¸ª epoch çš„è®­ç»ƒæ—¶é—´ï¼š< 5 åˆ†é’Ÿï¼ˆbatch_size=1024ï¼‰
   - æ¯ç§’å¤„ç†çš„æ ·æœ¬æ•°ï¼š> 2000 samples/sec
   - GPU åˆ©ç”¨ç‡ï¼š> 90%
   - GPU å†…å­˜ä½¿ç”¨ï¼šå……åˆ†åˆ©ç”¨ï¼ˆ30-40GBï¼‰

2. **å†…å­˜å ç”¨**ï¼ˆç›®æ ‡ï¼‰ï¼š
   - å³°å€¼ GPU å†…å­˜ï¼š30-40GBï¼ˆå……åˆ†åˆ©ç”¨ 48GBï¼‰
   - å³°å€¼ CPU å†…å­˜ï¼š< 50GBï¼ˆ90GB RAM å……è¶³ï¼‰
   - æ•°æ®åŠ è½½å†…å­˜ï¼š< 20GBï¼ˆRAM ç¼“å­˜ï¼‰

3. **æ¨¡å‹æ€§èƒ½**ï¼ˆç›®æ ‡ï¼‰ï¼š
   - éªŒè¯é›† Lossï¼šæŒç»­ä¸‹é™
   - IC (Information Coefficient)ï¼š> 0.05
   - RankICï¼š> 0.08
   - æ–¹å‘å‡†ç¡®ç‡ï¼š> 52%

4. **æ¨ç†é€Ÿåº¦**ï¼ˆç›®æ ‡ï¼‰ï¼š
   - å•ä¸ªæ ·æœ¬æ¨ç†æ—¶é—´ï¼š< 1ms
   - æ‰¹é‡æ¨ç†ååé‡ï¼š> 5000 samples/secï¼ˆbatch_size=1024ï¼‰

---

## âœ… éªŒæ”¶æ ‡å‡†

ä¼˜åŒ–åçš„ä»£ç éœ€è¦æ»¡è¶³ï¼š

1. **å‚»ç“œå¼è¿è¡Œ**ï¼ˆæœ€é‡è¦ï¼‰ï¼š
   - âœ… 5 ä¸ªç‹¬ç«‹å¯è¿è¡Œçš„è„šæœ¬ï¼ˆ1_preprocess_data.py, 2_build_graph.py, 3_train.py, 3_train_ablation.py, 4_evaluate.pyï¼‰
   - âœ… å…¨é‡æ¨¡å‹è®­ç»ƒå’Œæ¶ˆèå®éªŒåˆ†å¼€ï¼ˆ3_train.py å’Œ 3_train_ablation.pyï¼‰
   - âœ… å‘½ä»¤è¡Œå‚æ•°ç®€æ´æ˜äº†ï¼Œä¸€çœ¼å°±çŸ¥é“æ˜¯å¹²ä»€ä¹ˆçš„
   - âœ… æ¯ä¸ªè„šæœ¬éƒ½æœ‰å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œè¿›åº¦æ˜¾ç¤º
   - âœ… å…³é”®æ­¥éª¤æ‰“å°æ¸…æ™°çš„ä¸­æ–‡æç¤º

2. **åŠŸèƒ½æ­£ç¡®æ€§**ï¼š
   - âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡
   - âœ… æ¨¡å‹è¾“å‡ºå½¢çŠ¶æ­£ç¡®
   - âœ… è®­ç»ƒå¯ä»¥æ­£å¸¸è¿›è¡Œ
   - âœ… æ•°æ®æµå®Œæ•´ï¼ˆé¢„å¤„ç† â†’ å»ºå›¾ â†’ è®­ç»ƒ â†’ è¯„ä¼°ï¼‰

3. **æ€§èƒ½æå‡**ï¼ˆé’ˆå¯¹ 48GB GPU + 90GB RAMï¼‰ï¼š
   - âœ… è®­ç»ƒé€Ÿåº¦ï¼šbatch_size=1024 æ—¶ï¼Œæ¯ä¸ª epoch < 5 åˆ†é’Ÿ
   - âœ… GPU åˆ©ç”¨ç‡ï¼š> 90%
   - âœ… GPU å†…å­˜ä½¿ç”¨ï¼š30-40GBï¼ˆå……åˆ†åˆ©ç”¨ï¼‰
   - âœ… æ•°æ®åŠ è½½ï¼šnum_workers=10ï¼Œå……åˆ†åˆ©ç”¨ 12 vCPU

4. **ä»£ç è´¨é‡**ï¼š
   - âœ… é€šè¿‡ `mypy` ç±»å‹æ£€æŸ¥
   - âœ… é€šè¿‡ `pylint` ä»£ç æ£€æŸ¥ï¼ˆåˆ†æ•° â‰¥ 8.0ï¼‰
   - âœ… æ‰€æœ‰å‡½æ•°æœ‰å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆä¸­æ–‡ï¼‰
   - âœ… ä»£ç ç»“æ„æ¸…æ™°ï¼Œæ˜“äºç†è§£

5. **å¯ç»´æŠ¤æ€§**ï¼š
   - âœ… ä»£ç ç»“æ„æ¸…æ™°
   - âœ… æ³¨é‡Šå®Œæ•´ï¼ˆä¸­æ–‡ï¼‰
   - âœ… æ˜“äºæ‰©å±•
   - âœ… é…ç½®ç›´æ¥å†™åœ¨ py æ–‡ä»¶é‡Œï¼ˆè„šæœ¬é¡¶éƒ¨ï¼‰

---

## ğŸ“ å‚è€ƒèµ„æºï¼ˆè®ºæ–‡å…¬å¼€æºç ï¼‰

æ ¹æ®è®ºæ–‡å‚è€ƒæ–‡çŒ®ï¼Œä»¥ä¸‹å¼€æºé¡¹ç›®å¯ä»¥å‚è€ƒï¼š

1. **RWKV å®˜æ–¹å®ç°**ï¼š
   - GitHub: https://github.com/BlinkDL/RWKV-LM
   - **å‚è€ƒç‚¹**ï¼šRWKV æ—¶é—´æ··åˆå±‚çš„ä¼˜åŒ–å®ç°ã€JIT ç¼–è¯‘æŠ€å·§

2. **ADGAT (Attribute-Driven Graph Attention Networks)**ï¼š
   - GitHub: https://github.com/RuichengFIC/ADGAT
   - **å‚è€ƒç‚¹**ï¼šé‡‘èå›¾ç¥ç»ç½‘ç»œçš„å®ç°ã€GAT ä¼˜åŒ–æŠ€å·§
   - **è®ºæ–‡**ï¼šCheng, D., et al. (2022). "Modeling the Momentum Spillover Effect for Stock Prediction via Attribute-Driven Graph Attention Networks (ADGAT)." AAAI

3. **PyTorch Geometric**ï¼š
   - GitHub: https://github.com/pyg-team/pytorch_geometric
   - **å‚è€ƒç‚¹**ï¼šä½¿ç”¨ `GATv2Conv` æ›¿ä»£æ‰‹åŠ¨å®ç°ã€æ‰¹é‡å›¾å¤„ç†

4. **FinGPT**ï¼š
   - GitHub: https://github.com/AI4Finance-Foundation/FinGPT
   - **å‚è€ƒç‚¹**ï¼šé‡‘èæ–‡æœ¬å¤„ç†ã€LLM åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨

5. **PyTorch æ€§èƒ½ä¼˜åŒ–æŒ‡å—**ï¼š
   - https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html
   - **å‚è€ƒç‚¹**ï¼š48GB GPU çš„ä¼˜åŒ–é…ç½®ã€æ··åˆç²¾åº¦è®­ç»ƒ

6. **MATCC (å‚è€ƒè¶‹åŠ¿è§£è€¦æ€è·¯ï¼Œä½†ä¸ä½¿ç”¨)**ï¼š
   - GitHub: https://github.com/caozhiy/MATCC
   - **æ³¨æ„**ï¼šæ–°æ–¹å‘ä¸ä½¿ç”¨ MATCCï¼Œä½†å¯ä»¥å‚è€ƒå…¶æ•°æ®å¤„ç†æ€è·¯

---

## ğŸ“Œ æ³¨æ„äº‹é¡¹

1. **å‚»ç“œå¼è®¾è®¡**ï¼š
   - æ¯ä¸ªè„šæœ¬éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œ
   - å‘½ä»¤è¡Œå‚æ•°ç®€æ´æ˜äº†ï¼Œä¸è¦è¿‡åº¦å¤æ‚
   - æ·»åŠ æ¸…æ™°çš„è¿›åº¦æ˜¾ç¤ºå’Œé”™è¯¯æç¤º
   - å…³é”®æ­¥éª¤æ‰“å°ä¸­æ–‡è¯´æ˜

2. **å……åˆ†åˆ©ç”¨ç¡¬ä»¶**ï¼š
   - 48GB GPUï¼šbatch_size=1024+ï¼Œseq_len=60+ï¼Œå¯ç”¨ TF32
   - 90GB RAMï¼šæ•°æ®é¢„åŠ è½½ï¼Œå†…å­˜æ˜ å°„æ–‡ä»¶
   - 12 vCPUï¼šnum_workers=8-10ï¼Œå¤šè¿›ç¨‹å¤„ç†

3. **ä¿æŒå…¼å®¹æ€§**ï¼š
   - ä¼˜åŒ–æ—¶ä¸è¦ç ´åç°æœ‰æ¥å£
   - ä¿ç•™ `QL_MATCC_Model` ç­‰å…¼å®¹æ€§åˆ«å
   - é…ç½®æ–‡ä»¶å‘åå…¼å®¹

4. **å‚è€ƒè®ºæ–‡æºç **ï¼š
   - RWKV-LMï¼šRWKV æ—¶é—´æ··åˆå±‚ä¼˜åŒ–
   - ADGATï¼šGAT å±‚å®ç°å’Œé‡‘èå›¾å¤„ç†
   - FinGPTï¼šLLM æ‰¹å¤„ç†ä¼˜åŒ–

5. **æ¸è¿›å¼ä¼˜åŒ–**ï¼š
   - å…ˆå®Œæˆè„šæœ¬é‡æ„ï¼ˆä»»åŠ¡ 0ï¼‰
   - å†ä¼˜åŒ–æ€§èƒ½ï¼ˆä»»åŠ¡ 1-5ï¼‰
   - æ¯æ¬¡ä¼˜åŒ–åæµ‹è¯•éªŒè¯

6. **æ–‡æ¡£æ›´æ–°**ï¼š
   - ä¼˜åŒ–åæ›´æ–° README
   - æ›´æ–°ä»£ç æ³¨é‡Š
   - æ·»åŠ ä½¿ç”¨ç¤ºä¾‹

---

---

## ğŸ’¡ é¢å¤–ä¼˜åŒ–å»ºè®®

### **1. é¡¹ç›®ç»“æ„ä¼˜åŒ–**

å»ºè®®çš„é¡¹ç›®ç›®å½•ç»“æ„ï¼š
```
paper/
â”œâ”€â”€ 1_preprocess_data.py      # æ•°æ®é¢„å¤„ç†ï¼ˆç‹¬ç«‹è„šæœ¬ï¼‰
â”œâ”€â”€ 2_build_graph.py           # æ„å»ºå›¾è°±ï¼ˆç‹¬ç«‹è„šæœ¬ï¼‰
â”œâ”€â”€ 3_train.py                 # å…¨é‡æ¨¡å‹è®­ç»ƒï¼ˆç‹¬ç«‹è„šæœ¬ï¼‰
â”œâ”€â”€ 3_train_ablation.py        # æ¶ˆèå®éªŒè®­ç»ƒï¼ˆç‹¬ç«‹è„šæœ¬ï¼‰
â”œâ”€â”€ 4_evaluate.py              # è¯„ä¼°æ¨¡å‹ï¼ˆç‹¬ç«‹è„šæœ¬ï¼‰
â”œâ”€â”€ requirements.txt           # Python ä¾èµ–ï¼ˆæ˜ç¡®ç‰ˆæœ¬ï¼‰
â”œâ”€â”€ README.md                  # ä½¿ç”¨è¯´æ˜
â”œâ”€â”€ models/                    # æ¨¡å‹å®šä¹‰
â”‚   â”œâ”€â”€ base_model.py
â”‚   â””â”€â”€ gnn_model.py
â”œâ”€â”€ dataProcessed/             # æ•°æ®å¤„ç†æ¨¡å—ï¼ˆè¢«è„šæœ¬è°ƒç”¨ï¼‰
â”‚   â”œâ”€â”€ etl.py
â”‚   â”œâ”€â”€ align.py
â”‚   â”œâ”€â”€ build_graph.py
â”‚   â””â”€â”€ dataset.py
â”œâ”€â”€ data/                      # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw/                   # åŸå§‹æ•°æ®
â”‚   â””â”€â”€ processed/             # å¤„ç†åçš„æ•°æ®
â””â”€â”€ outputs/                   # è¾“å‡ºç›®å½•
    â”œâ”€â”€ checkpoints/           # æ¨¡å‹æ£€æŸ¥ç‚¹
    â”œâ”€â”€ logs/                  # è®­ç»ƒæ—¥å¿—
    â”œâ”€â”€ figures/               # å›¾è¡¨
    â””â”€â”€ results/               # è¯„ä¼°ç»“æœ
```

### **2. ä¾èµ–ç®¡ç†ä¼˜åŒ–**

åˆ›å»º `requirements.txt`ï¼Œæ˜ç¡®ç‰ˆæœ¬ï¼š
```txt
# æ ¸å¿ƒæ¡†æ¶
torch==2.1.2
torchvision==0.16.2
torchaudio==2.1.2

# å›¾ç¥ç»ç½‘ç»œ
torch-geometric==2.4.0

# æ•°æ®å¤„ç†
pandas==2.1.4
numpy==1.24.3
scikit-learn==1.3.2

# LLM ç›¸å…³
transformers==4.36.2
accelerate==0.25.0

# å¯è§†åŒ–
matplotlib==3.8.2
seaborn==0.13.0
tqdm==4.66.1

# å·¥å…·
pyyaml==6.0.1
```

**å»ºè®®**ï¼š
- ä½¿ç”¨ `pip freeze > requirements.txt` é”å®šç‰ˆæœ¬
- åœ¨ README ä¸­è¯´æ˜å¦‚ä½•å®‰è£…ä¾èµ–
- è€ƒè™‘ä½¿ç”¨ `conda` ç¯å¢ƒç®¡ç†ï¼ˆå¯é€‰ï¼‰

### **3. æ—¥å¿—ç³»ç»Ÿï¼ˆé‡è¦ï¼æ¯æ¬¡è¿è¡Œè‡ªåŠ¨ä¿å­˜ï¼‰**

æ¯ä¸ªè„šæœ¬éƒ½åº”è¯¥æœ‰å®Œå–„çš„æ—¥å¿—ç³»ç»Ÿï¼Œ**æ¯æ¬¡è¿è¡Œè‡ªåŠ¨ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶**ï¼š

```python
import logging
import sys
from datetime import datetime
from pathlib import Path

def setup_logging(output_dir: str, script_name: str) -> logging.Logger:
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿï¼Œæ¯æ¬¡è¿è¡Œåˆ›å»ºæ–°çš„æ—¥å¿—æ–‡ä»¶ã€‚
    
    Args:
        output_dir: è¾“å‡ºç›®å½•
        script_name: è„šæœ¬åç§°ï¼ˆç”¨äºæ—¥å¿—æ–‡ä»¶åï¼‰
    
    Returns:
        Logger å¯¹è±¡
    """
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = Path(output_dir) / 'logs'
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # æ—¥å¿—æ–‡ä»¶ååŒ…å«æ—¶é—´æˆ³ï¼šscript_name_YYYYMMDD_HHMMSS.log
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    log_file = log_dir / f'{script_name}_{timestamp}.log'
    
    # é…ç½®æ—¥å¿—æ ¼å¼
    log_format = '%(asctime)s - %(levelname)s - %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'
    
    # é…ç½®æ—¥å¿—ï¼ˆåŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°ï¼‰
    logging.basicConfig(
        level=logging.INFO,
        format=log_format,
        datefmt=date_format,
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),  # æ–‡ä»¶è¾“å‡º
            logging.StreamHandler(sys.stdout)  # æ§åˆ¶å°è¾“å‡º
        ],
        force=True  # å¼ºåˆ¶é‡æ–°é…ç½®ï¼ˆé¿å…é‡å¤è¿è¡Œæ—¶çš„æ—¥å¿—æ··ä¹±ï¼‰
    )
    
    logger = logging.getLogger(__name__)
    logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    logger.info("="*60)
    return logger

def main():
    # è®¾ç½®æ—¥å¿—ï¼ˆæ¯æ¬¡è¿è¡Œåˆ›å»ºæ–°æ–‡ä»¶ï¼‰
    logger = setup_logging('./outputs', 'train')
    
    try:
        # è®°å½•å…³é”®ä¿¡æ¯
        logger.info("å¼€å§‹è®­ç»ƒ Graph-RWKV æ¨¡å‹")
        logger.info(f"é…ç½®å‚æ•°: batch_size={args.batch_size}, epochs={args.epochs}")
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not os.path.exists(args.data):
            logger.error(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
            raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
        
        # æ£€æŸ¥ GPU
        if not torch.cuda.is_available():
            logger.warning("CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPUï¼ˆè®­ç»ƒä¼šå¾ˆæ…¢ï¼‰")
        else:
            logger.info(f"GPU: {torch.cuda.get_device_name(0)}")
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´ï¼ˆ50GB æ•°æ®ç›˜ï¼‰
        disk_usage = shutil.disk_usage(args.output)
        if disk_usage.free < 10 * 1024**3:  # å°äº 10GB
            logger.warning(f"ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œå‰©ä½™: {disk_usage.free / 1024**3:.1f} GB")
        
        # è®°å½•æ¯ä¸ªæ­¥éª¤
        logger.info("æ­¥éª¤ 1/5: åŠ è½½æ•°æ®...")
        # ... åŠ è½½æ•°æ® ...
        logger.info(f"æ•°æ®åŠ è½½å®Œæˆï¼Œè®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
        
        logger.info("æ­¥éª¤ 2/5: åˆå§‹åŒ–æ¨¡å‹...")
        # ... åˆå§‹åŒ–æ¨¡å‹ ...
        logger.info("æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        
        logger.info("æ­¥éª¤ 3/5: å¼€å§‹è®­ç»ƒ...")
        for epoch in range(args.epochs):
            # ... è®­ç»ƒä»£ç  ...
            logger.info(f"Epoch {epoch+1}/{args.epochs} å®Œæˆï¼ŒLoss: {loss:.6f}")
        
        logger.info("è®­ç»ƒå®Œæˆï¼")
        
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­è®­ç»ƒï¼Œæ­£åœ¨ä¿å­˜æ£€æŸ¥ç‚¹...")
        # ä¿å­˜å½“å‰çŠ¶æ€
    except Exception as e:
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}", exc_info=True)  # exc_info=True è®°å½•å®Œæ•´å †æ ˆ
        raise
    finally:
        logger.info("="*60)
        logger.info(f"æ—¥å¿—å·²ä¿å­˜åˆ°: {log_file}")
```

**æ—¥å¿—æ–‡ä»¶å‘½åè§„åˆ™**ï¼š
- æ ¼å¼ï¼š`{script_name}_{YYYYMMDD}_{HHMMSS}.log`
- ç¤ºä¾‹ï¼š`train_20260123_143025.log`, `build_graph_20260123_150130.log`
- å¥½å¤„ï¼šæ¯æ¬¡è¿è¡Œéƒ½æœ‰ç‹¬ç«‹çš„æ—¥å¿—æ–‡ä»¶ï¼Œæ–¹ä¾¿æŸ¥çœ‹å’Œå¯¹æ¯”

**æ—¥å¿—å†…å®¹è¦æ±‚**ï¼š
- æ—¶é—´æˆ³ï¼šæ¯æ¡æ—¥å¿—éƒ½æœ‰æ—¶é—´æˆ³
- æ­¥éª¤ï¼šæ¸…æ™°æ ‡æ³¨å½“å‰æ‰§è¡Œæ­¥éª¤ï¼ˆå¦‚ "æ­¥éª¤ 1/5: åŠ è½½æ•°æ®..."ï¼‰
- è¿›åº¦ï¼šè®°å½•è®­ç»ƒè¿›åº¦ï¼ˆepochã€loss ç­‰ï¼‰
- é”™è¯¯ï¼šå®Œæ•´çš„é”™è¯¯ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ª
- èµ„æºï¼šGPUã€å†…å­˜ä½¿ç”¨æƒ…å†µ
- é…ç½®ï¼šè®°å½•ä½¿ç”¨çš„é…ç½®å‚æ•°

### **4. æ€§èƒ½ç›‘æ§å’Œèµ„æºä½¿ç”¨**

æ·»åŠ èµ„æºç›‘æ§åŠŸèƒ½ï¼š

```python
import psutil
import GPUtil

def monitor_resources():
    """ç›‘æ§ CPUã€å†…å­˜ã€GPU ä½¿ç”¨æƒ…å†µã€‚"""
    # CPU ä½¿ç”¨ç‡
    cpu_percent = psutil.cpu_percent(interval=1)
    
    # å†…å­˜ä½¿ç”¨
    memory = psutil.virtual_memory()
    
    # GPU ä½¿ç”¨
    gpus = GPUtil.getGPUs()
    if gpus:
        gpu = gpus[0]
        logger.info(f"CPU: {cpu_percent}% | "
                   f"RAM: {memory.percent}% ({memory.used/1024**3:.1f}GB/{memory.total/1024**3:.1f}GB) | "
                   f"GPU: {gpu.load*100:.1f}% | "
                   f"GPU Memory: {gpu.memoryUsed}MB/{gpu.memoryTotal}MB")
```

### **5. æ•°æ®ç®¡ç†ä¼˜åŒ–ï¼ˆé’ˆå¯¹ 50GB ç£ç›˜ï¼‰**

**å»ºè®®**ï¼š
1. **å‹ç¼©å­˜å‚¨**ï¼šä½¿ç”¨å‹ç¼©æ ¼å¼å­˜å‚¨ä¸­é—´æ–‡ä»¶
   ```python
   # ä½¿ç”¨å‹ç¼©çš„ NumPy æ ¼å¼
   np.savez_compressed('graph.npz', adj_matrix=adj_matrix)
   
   # ä½¿ç”¨ Parquet æ ¼å¼å­˜å‚¨ CSVï¼ˆæ›´å°ï¼‰
   df.to_parquet('data.parquet', compression='snappy')
   ```

2. **æ¸…ç†ä¸´æ—¶æ–‡ä»¶**ï¼šè„šæœ¬è¿è¡Œåè‡ªåŠ¨æ¸…ç†
   ```python
   import tempfile
   import shutil
   
   # ä½¿ç”¨ä¸´æ—¶ç›®å½•
   temp_dir = tempfile.mkdtemp()
   try:
       # ... å¤„ç†é€»è¾‘ ...
   finally:
       shutil.rmtree(temp_dir)  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
   ```

3. **æ•°æ®æ£€æŸ¥ç‚¹**ï¼šæ”¯æŒæ–­ç‚¹ç»­è·‘
   ```python
   # ä¿å­˜å¤„ç†è¿›åº¦
   checkpoint_file = 'data/processed/.preprocess_checkpoint.json'
   if os.path.exists(checkpoint_file):
       # ä»æ£€æŸ¥ç‚¹æ¢å¤
       with open(checkpoint_file) as f:
           checkpoint = json.load(f)
   ```

### **6. é…ç½®ç®¡ç†ä¼˜åŒ–**

ä½¿ç”¨ `config.yaml` ç»Ÿä¸€ç®¡ç†é…ç½®ï¼Œè„šæœ¬åªè¦†ç›–å…³é”®å‚æ•°ï¼š

```yaml
# config.yaml
data:
  input_dir: "./data/raw"
  output_dir: "./data/processed"
  seq_len: 30

model:
  n_embd: 256
  n_layers: 3
  gnn_embd: 64
  dropout: 0.1

training:
  batch_size: 1024      # é’ˆå¯¹ 48GB GPU
  epochs: 30
  lr: 3e-4
  num_workers: 10       # é’ˆå¯¹ 12 vCPU
  pin_memory: true
  prefetch_factor: 4

hardware:
  gpu_id: 0
  enable_tf32: true
  enable_compile: true   # torch.compile
  mixed_precision: true  # AMP
```

è„šæœ¬ä¸­åŠ è½½é…ç½®ï¼š
```python
import yaml

def load_config(config_path='config.yaml'):
    with open(config_path) as f:
        config = yaml.safe_load(f)
    return config

# å‘½ä»¤è¡Œå‚æ•°å¯ä»¥è¦†ç›–é…ç½®
config = load_config()
if args.batch_size:
    config['training']['batch_size'] = args.batch_size
```

### **7. å®éªŒç®¡ç†å’Œç‰ˆæœ¬æ§åˆ¶**

**å»ºè®®**ï¼š
1. **å®éªŒå‘½å**ï¼šä½¿ç”¨æ—¶é—´æˆ³æˆ–æè¿°æ€§åç§°
   ```python
   from datetime import datetime
   exp_name = f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
   # æˆ–
   exp_name = f"graph_rwkv_embd{MODEL_N_EMBD}_layers{MODEL_N_LAYERS}"
   ```

2. **ä¿å­˜å®éªŒé…ç½®**ï¼šæ¯æ¬¡è®­ç»ƒä¿å­˜å®Œæ•´é…ç½®åˆ°æ—¥å¿—
   ```python
   experiment_dir = f"outputs/experiments/{exp_name}"
   os.makedirs(experiment_dir, exist_ok=True)
   
   # ä¿å­˜é…ç½®ï¼ˆä»¥ JSON æ ¼å¼ï¼Œä¸ä½¿ç”¨ yamlï¼‰
   config_dict = {
       'n_embd': MODEL_N_EMBD,
       'n_layers': MODEL_N_LAYERS,
       'batch_size': TRAIN_BATCH_SIZE,
       'epochs': TRAIN_EPOCHS,
       # ... å…¶ä»–é…ç½®
   }
   with open(f"{experiment_dir}/config.json", 'w') as f:
       json.dump(config_dict, f, indent=2)
   
   # ä¿å­˜å‘½ä»¤è¡Œå‚æ•°
   with open(f"{experiment_dir}/args.txt", 'w') as f:
       f.write(str(args))
   ```

3. **Git é›†æˆ**ï¼šè®°å½•ä»£ç ç‰ˆæœ¬
   ```python
   import subprocess
   
   def get_git_hash():
       try:
           return subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode().strip()
       except:
           return "unknown"
   
   config['git_hash'] = get_git_hash()
   ```

### **8. å¿«é€ŸéªŒè¯è„šæœ¬**

åˆ›å»ºä¸€ä¸ªå¿«é€ŸéªŒè¯è„šæœ¬ï¼Œæ£€æŸ¥ç¯å¢ƒæ˜¯å¦æ­£ç¡®ï¼š

```python
# check_environment.py
"""å¿«é€Ÿæ£€æŸ¥ç¯å¢ƒå’Œä¾èµ–ã€‚"""

import sys

def check_python_version():
    if sys.version_info < (3, 10):
        print("âŒ Python ç‰ˆæœ¬éœ€è¦ >= 3.10")
        return False
    print(f"âœ… Python ç‰ˆæœ¬: {sys.version}")
    return True

def check_torch():
    try:
        import torch
        print(f"âœ… PyTorch ç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ… CUDA å¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"âœ… GPU: {torch.cuda.get_device_name(0)}")
            print(f"âœ… GPU å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        return True
    except ImportError:
        print("âŒ PyTorch æœªå®‰è£…")
        return False

def check_dependencies():
    deps = ['pandas', 'numpy', 'sklearn', 'torch_geometric', 'transformers']
    for dep in deps:
        try:
            __import__(dep)
            print(f"âœ… {dep} å·²å®‰è£…")
        except ImportError:
            print(f"âŒ {dep} æœªå®‰è£…")
            return False
    return True

if __name__ == '__main__':
    print("æ£€æŸ¥ç¯å¢ƒ...")
    all_ok = True
    all_ok &= check_python_version()
    all_ok &= check_torch()
    all_ok &= check_dependencies()
    
    if all_ok:
        print("\nâœ… ç¯å¢ƒæ£€æŸ¥é€šè¿‡ï¼")
    else:
        print("\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·å®‰è£…ç¼ºå¤±çš„ä¾èµ–")
        sys.exit(1)
```

### **9. README å®Œå–„**

README åº”è¯¥åŒ…å«ï¼š

1. **å¿«é€Ÿå¼€å§‹**ï¼š
   ```markdown
   ## å¿«é€Ÿå¼€å§‹
   
   ### 1. å®‰è£…ä¾èµ–
   ```bash
   pip install -r requirements.txt
   ```
   
   ### 2. æ£€æŸ¥ç¯å¢ƒ
   ```bash
   python check_environment.py
   ```
   
   ### 3. è¿è¡Œå®Œæ•´æµç¨‹
   ```bash
   # æ•°æ®é¢„å¤„ç†
   python 1_preprocess_data.py --input_dir ./data/raw --output_dir ./data/processed
   
   # æ„å»ºå›¾è°±
   python 2_build_graph.py --news ./data/processed/Stock_News.csv --output ./data/processed
   
   # è®­ç»ƒå…¨é‡æ¨¡å‹
   python 3_train.py --data ./data/processed/Final_Model_Data.csv --graph ./data/processed/Graph_Adjacency.npy --output ./outputs
   
   # è¯„ä¼°æ¨¡å‹
   python 4_evaluate.py --checkpoint ./outputs/best_model.pth --test_data ./data/processed/test.csv
   ```
   ```

2. **å¸¸è§é—®é¢˜**ï¼š
   ```markdown
   ## å¸¸è§é—®é¢˜
   
   ### Q: è®­ç»ƒæ—¶ GPU å†…å­˜ä¸è¶³ï¼Ÿ
   A: å‡å° batch_sizeï¼Œæˆ–å‡å° n_embdã€n_layers
   
   ### Q: æ•°æ®é¢„å¤„ç†å¾ˆæ…¢ï¼Ÿ
   A: æ£€æŸ¥ num_workers è®¾ç½®ï¼Œå……åˆ†åˆ©ç”¨ 12 vCPU
   
   ### Q: ç£ç›˜ç©ºé—´ä¸è¶³ï¼Ÿ
   A: æ¸…ç† outputs/ ç›®å½•çš„æ—§å®éªŒï¼Œæˆ–ä½¿ç”¨å‹ç¼©æ ¼å¼
   ```

### **10. æ€§èƒ½ä¼˜åŒ–æ£€æŸ¥æ¸…å•**

åœ¨ä»£ç ä¸­æ·»åŠ æ€§èƒ½æ£€æŸ¥ï¼š

```python
def check_performance_settings():
    """æ£€æŸ¥æ€§èƒ½ä¼˜åŒ–è®¾ç½®ã€‚"""
    checks = []
    
    # æ£€æŸ¥ TF32
    if torch.cuda.is_available():
        if torch.backends.cuda.matmul.allow_tf32:
            checks.append("âœ… TF32 å·²å¯ç”¨")
        else:
            checks.append("âš ï¸ TF32 æœªå¯ç”¨ï¼ˆå»ºè®®å¯ç”¨ï¼‰")
    
    # æ£€æŸ¥ cuDNN benchmark
    if torch.backends.cudnn.benchmark:
        checks.append("âœ… cuDNN benchmark å·²å¯ç”¨")
    else:
        checks.append("âš ï¸ cuDNN benchmark æœªå¯ç”¨ï¼ˆå»ºè®®å¯ç”¨ï¼‰")
    
    # æ£€æŸ¥æ•°æ®åŠ è½½
    if num_workers >= 8:
        checks.append(f"âœ… num_workers={num_workers}ï¼ˆå……åˆ†åˆ©ç”¨ CPUï¼‰")
    else:
        checks.append(f"âš ï¸ num_workers={num_workers}ï¼ˆå»ºè®® >= 8ï¼‰")
    
    for check in checks:
        logger.info(check)
```

### **11. ä¸€é”®è¿è¡Œè„šæœ¬**

åˆ›å»ºä¸€ä¸ªä¸»è„šæœ¬ï¼Œå¯ä»¥ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹ï¼š

```python
# run_all.py
"""ä¸€é”®è¿è¡Œå®Œæ•´æµç¨‹ã€‚"""

import subprocess
import sys

def run_command(cmd, description):
    print(f"\n{'='*60}")
    print(f"æ‰§è¡Œ: {description}")
    print(f"å‘½ä»¤: {' '.join(cmd)}")
    print('='*60)
    
    result = subprocess.run(cmd, check=False)
    if result.returncode != 0:
        print(f"âŒ {description} å¤±è´¥")
        sys.exit(1)
    print(f"âœ… {description} å®Œæˆ")

if __name__ == '__main__':
    # 1. æ•°æ®é¢„å¤„ç†
    run_command(
        ['python', '1_preprocess_data.py', '--input_dir', './data/raw', '--output_dir', './data/processed'],
        'æ•°æ®é¢„å¤„ç†'
    )
    
    # 2. æ„å»ºå›¾è°±
    run_command(
        ['python', '2_build_graph.py', '--news', './data/processed/Stock_News.csv', '--output', './data/processed'],
        'æ„å»ºå›¾è°±'
    )
    
    # 3. è®­ç»ƒæ¨¡å‹
    run_command(
        ['python', '3_train.py', '--data', './data/processed/Final_Model_Data.csv', 
         '--graph', './data/processed/Graph_Adjacency.npy', '--output', './outputs'],
        'è®­ç»ƒæ¨¡å‹'
    )
    
    # 4. è¯„ä¼°æ¨¡å‹
    run_command(
        ['python', '4_evaluate.py', '--checkpoint', './outputs/best_model.pth', 
         '--test_data', './data/processed/test.csv'],
        'è¯„ä¼°æ¨¡å‹'
    )
    
    print("\nâœ… å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸï¼")
```

### **12. è¾“å‡ºç»“æœæ•´ç†**

è‡ªåŠ¨æ•´ç†å®éªŒç»“æœï¼š

```python
# è®­ç»ƒå®Œæˆåè‡ªåŠ¨ç”ŸæˆæŠ¥å‘Š
def generate_training_report(output_dir, metrics):
    report = f"""
# è®­ç»ƒæŠ¥å‘Š

## æ¨¡å‹é…ç½®
- n_embd: {config['n_embd']}
- n_layers: {config['n_layers']}
- batch_size: {config['batch_size']}

## è®­ç»ƒç»“æœ
- æœ€ä½³éªŒè¯ Loss: {metrics['best_val_loss']:.6f}
- IC: {metrics['ic']:.4f}
- RankIC: {metrics['rank_ic']:.4f}

## èµ„æºä½¿ç”¨
- è®­ç»ƒæ—¶é—´: {metrics['training_time']:.1f} åˆ†é’Ÿ
- GPU å³°å€¼å†…å­˜: {metrics['gpu_memory']:.1f} GB
"""
    with open(f"{output_dir}/report.md", 'w') as f:
        f.write(report)
```

---

## ğŸ“‹ æœ€ç»ˆæ£€æŸ¥æ¸…å•

ä¼˜åŒ–å®Œæˆåï¼Œç¡®ä¿ï¼š

- [ ] **5 ä¸ªè„šæœ¬éƒ½å¯ä»¥ç›´æ¥ç‚¹å‡»è¿è¡Œ**ï¼ˆæ— éœ€å‘½ä»¤è¡Œå‚æ•°ï¼‰
- [ ] **æ¯æ¬¡è¿è¡Œè‡ªåŠ¨ä¿å­˜æ—¥å¿—åˆ°æ–‡ä»¶**ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
- [ ] **æ—¥å¿—å†…å®¹å®Œæ•´**ï¼šæ—¶é—´æˆ³ã€æ­¥éª¤ã€è¿›åº¦ã€é”™è¯¯ã€èµ„æºä½¿ç”¨
- [ ] å‘½ä»¤è¡Œå‚æ•°å¯é€‰ï¼ˆç”¨äºè¦†ç›–é»˜è®¤é…ç½®ï¼‰
- [ ] æœ‰å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—ç³»ç»Ÿ
- [ ] æœ‰ `requirements.txt`ï¼ˆä¸ä½¿ç”¨ config.yamlï¼Œé…ç½®ç›´æ¥å†™åœ¨ py æ–‡ä»¶é‡Œï¼‰
- [ ] æœ‰ `check_environment.py` æ£€æŸ¥è„šæœ¬
- [ ] README åŒ…å«å¿«é€Ÿå¼€å§‹å’Œå¸¸è§é—®é¢˜
- [ ] ä»£ç é€šè¿‡ç±»å‹æ£€æŸ¥ï¼ˆmypyï¼‰
- [ ] æ‰€æœ‰å‡½æ•°æœ‰ä¸­æ–‡æ–‡æ¡£å­—ç¬¦ä¸²
- [ ] å……åˆ†åˆ©ç”¨ 48GB GPU å’Œ 90GB RAM
- [ ] è¾“å‡ºç»“æœæ¸…æ™°æ˜“è¯»

## ğŸ¯ å…³é”®ç‰¹æ€§æ€»ç»“

### **1. ç›´æ¥ç‚¹å‡»è¿è¡Œ**
- âœ… æ¯ä¸ªè„šæœ¬éƒ½æœ‰ `if __name__ == '__main__'` å…¥å£
- âœ… ä½¿ç”¨è„šæœ¬ä¸­çš„é»˜è®¤é…ç½®ï¼ˆé…ç½®ç›´æ¥å†™åœ¨ py æ–‡ä»¶é‡Œï¼‰
- âœ… å‘½ä»¤è¡Œå‚æ•°å¯é€‰ï¼Œç”¨äºè¦†ç›–é…ç½®
- âœ… é€‚åˆåœ¨ IDE ä¸­ç›´æ¥è¿è¡Œ

### **2. å®Œå–„çš„æ—¥å¿—ç³»ç»Ÿ**
- âœ… æ¯æ¬¡è¿è¡Œè‡ªåŠ¨åˆ›å»ºæ–°çš„æ—¥å¿—æ–‡ä»¶
- âœ… æ—¥å¿—æ–‡ä»¶å‘½åï¼š`{script_name}_{YYYYMMDD}_{HHMMSS}.log`
- âœ… åŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°
- âœ… è®°å½•æ—¶é—´æˆ³ã€æ­¥éª¤ã€è¿›åº¦ã€é”™è¯¯ã€èµ„æºä½¿ç”¨
- âœ… æ–¹ä¾¿æ£€æŸ¥å’Œè°ƒè¯•ä»£ç 

---

**æœ€åæ›´æ–°**ï¼š2026-01-23
**ç»´æŠ¤è€…**ï¼šé¡¹ç›®å¼€å‘å›¢é˜Ÿ
